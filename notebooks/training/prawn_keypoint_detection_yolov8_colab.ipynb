{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "->\n",
        "\n",
        "# YOLOv8 Prawn Keypoint Detection Training Pipeline\n",
        "\n",
        "**Author:** Gil Ben-Or  \n",
        "**Purpose:** Train YOLOv8 pose estimation model for prawn keypoint detection  \n",
        "**Environment:** Google Colab with GPU acceleration  \n",
        "**Last Updated:** December 2024  \n",
        "\n",
        "## üéØ Objective\n",
        "Train a YOLOv8 pose estimation model to detect anatomical keypoints on prawns for:\n",
        "- **Morphometric analysis** - Measuring prawn body lengths and carapace dimensions\n",
        "- **Population studies** - Automated analysis of prawn populations\n",
        "- **Research applications** - Supporting marine biology research\n",
        "\n",
        "## üîÑ Training Pipeline Overview\n",
        "\n",
        "1. **üõ†Ô∏è Environment Setup** - Install dependencies and setup Colab environment\n",
        "2. **üìä W&B Integration** - Configure experiment tracking and model versioning  \n",
        "3. **üìÅ Dataset Management** - Download dataset from Roboflow workspace\n",
        "4. **üèóÔ∏è Model Configuration** - Setup YOLOv8 pose model with custom callbacks\n",
        "5. **üöÄ Training Execution** - Train model with optimized hyperparameters\n",
        "6. **üìà Results Logging** - Track metrics and save best checkpoints to W&B\n",
        "\n",
        "## üîß Key Features\n",
        "- **Custom W&B Callback**: Automatically saves best checkpoints during training\n",
        "- **Comprehensive Logging**: Tracks all training metrics, validation results, and model artifacts\n",
        "- **Error Analysis**: Computes counting errors (RMSE, MAE, MRD) for validation\n",
        "- **Visualization**: Logs prediction visualizations and comparison plots\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Install core dependencies for YOLOv8 keypoint detection training.\n",
        "\n",
        "This cell installs:\n",
        "- ultralytics: YOLOv8 implementation with pose estimation capabilities\n",
        "- wandb: Weights & Biases for experiment tracking and model versioning\n",
        "- roboflow: Dataset management and downloading\n",
        "\"\"\"\n",
        "\n",
        "# Install YOLOv8 framework for pose estimation\n",
        "%pip install ultralytics\n",
        "\n",
        "# Install Weights & Biases for experiment tracking\n",
        "%pip install wandb  \n",
        "\n",
        "# Install Roboflow for dataset management\n",
        "%pip install roboflow\n",
        "\n",
        "print(\"‚úÖ All dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#  üîë Secure API Key Configuration\n",
        "This section focuses on securely configuring API keys for integration with external services.\n",
        "\n",
        " ### Key Points:\n",
        "- **Security Best Practices**: Avoid hardcoding API keys directly in the notebook.\n",
        "- **Use Colab Secrets**: Leverage Google Colab's secret management for secure storage.\n",
        "- **Regular Rotation**: Regularly update and rotate API keys to maintain security.\n",
        "### Setup Instructions:\n",
        "1. Click the key icon (üîë) in the Colab sidebar to manage secrets.\n",
        "2. Add the following secrets:\n",
        "   - `WANDB_API_KEY`: Your Weights & Biases API key from wandb.ai/authorize.\n",
        "   - `ROBOFLOW_API_KEY`: Your Roboflow API key from app.roboflow.com.\n",
        "\n",
        "The following cell will attempt to load these keys securely and configure the environment for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Secure API key configuration using Google Colab secrets.\n",
        "\n",
        "IMPORTANT SECURITY NOTES:\n",
        "- Never hardcode API keys in notebooks\n",
        "- Use Colab secrets or environment variables\n",
        "- Rotate API keys regularly for security\n",
        "\n",
        "Setup Instructions:\n",
        "1. In Colab, click the key icon (üîë) in the left sidebar\n",
        "2. Add secrets:\n",
        "   - WANDB_API_KEY: Your W&B API key from wandb.ai/authorize\n",
        "   - ROBOFLOW_API_KEY: Your Roboflow API key from app.roboflow.com\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    # Get API keys from Colab secrets\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "    ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "    \n",
        "    # Set W&B API key as environment variable\n",
        "    os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n",
        "    \n",
        "    print(\"‚úÖ API keys loaded successfully from Colab secrets\")\n",
        "    print(\"üîê W&B API key configured\")\n",
        "    print(\"üîê Roboflow API key configured\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error loading API keys from Colab secrets\")\n",
        "    print(\"Please ensure you've added WANDB_API_KEY and ROBOFLOW_API_KEY to Colab secrets\")\n",
        "    print(f\"Error: {e}\")\n",
        "    \n",
        "    # Fallback: Manual input (less secure, only for testing)\n",
        "    print(\"\\nüö® Fallback: Manual API key input (NOT RECOMMENDED for production)\")\n",
        "    WANDB_API_KEY = input(\"Enter your W&B API key: \")\n",
        "    ROBOFLOW_API_KEY = input(\"Enter your Roboflow API key: \")\n",
        "    os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. üîß Import Core Libraries & Setup Custom Callback\n",
        "\n",
        "Import required libraries and load the custom W&B callback for advanced checkpoint management.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Import libraries and setup custom W&B callback.\n",
        "\n",
        "This cell:\n",
        "1. Downloads the custom W&B callback script from this repository\n",
        "2. Imports all required libraries for training\n",
        "3. Sets up the custom callback for advanced checkpoint management\n",
        "\n",
        "The yolo_wandb_callback module provides:\n",
        "- Automatic saving of best checkpoints to W&B artifacts\n",
        "- Comprehensive logging of training metrics  \n",
        "- Validation result visualization and error analysis\n",
        "- Custom callback integration with YOLOv8 training loop\n",
        "\"\"\"\n",
        "\n",
        "import wandb\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Download the custom W&B callback script from this repository\n",
        "print(\"üì• Setting up custom W&B callback script...\")\n",
        "\n",
        "# Method 1: Download from this GitHub repository\n",
        "try:\n",
        "    !wget -q -O yolo_wandb_callback.py https://raw.githubusercontent.com/gbo999/counting_research_algorithms/main/notebooks/training/yolo_wandb_callback.py\n",
        "    print(\"‚úÖ Downloaded yolo_wandb_callback.py from repository\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Could not download from GitHub, trying alternative methods...\")\n",
        "    \n",
        "    # Method 2: Copy from Google Drive (if you've uploaded the entire repo)\n",
        "    drive_path = \"/content/drive/MyDrive/counting_research_algorithms/notebooks/training/yolo_wandb_callback.py\"\n",
        "    if Path(drive_path).exists():\n",
        "        !cp \"{drive_path}\" .\n",
        "        print(\"‚úÖ Copied yolo_wandb_callback.py from Google Drive\")\n",
        "    else:\n",
        "        # Method 3: Clone the entire repository\n",
        "        print(\"üì¶ Cloning repository to access callback script...\")\n",
        "        !git clone https://github.com/gbo999/counting_research_algorithms.git temp_repo\n",
        "        !cp temp_repo/notebooks/training/yolo_wandb_callback.py .\n",
        "        !rm -rf temp_repo\n",
        "        print(\"‚úÖ Extracted yolo_wandb_callback.py from cloned repository\")\n",
        "\n",
        "# Verify the file exists and import\n",
        "if Path(\"yolo_wandb_callback.py\").exists():\n",
        "    print(\"‚úÖ yolo_wandb_callback.py is available in current directory\")\n",
        "    \n",
        "    # Import the custom W&B callback (using new class name)\n",
        "    from yolo_wandb_callback import YOLOv8WeightsBiasesIntegrationCallback\n",
        "    print(\"‚úÖ Custom W&B callback imported successfully!\")\n",
        "    print(\"üîß Callback features loaded: automatic checkpointing, error analysis, visualization\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå yolo_wandb_callback.py not found!\")\n",
        "    print(\"Please manually upload the file from:\")\n",
        "    print(\"https://github.com/gbo999/counting_research_algorithms/blob/main/notebooks/training/yolo_wandb_callback.py\")\n",
        "\n",
        "print(\"üìù Libraries imported and callback ready for training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. üîó Mount Google Drive & Access Dataset\n",
        "\n",
        "Connect to Google Drive to access training data and configuration files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the dataset in Google Drive\n",
        "dataset_path = '/content/drive/MyDrive/your-dataset-path'\n",
        "\n",
        "# Verify the dataset path exists\n",
        "if Path(dataset_path).exists():\n",
        "    print(f\"‚úÖ Dataset found at: {dataset_path}\")\n",
        "else:\n",
        "    print(\"‚ùå Dataset path not found! Please check the path and try again.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. üìä Initialize Weights & Biases Experiment\n",
        "\n",
        "Setup W&B for experiment tracking and download any pre-trained models from previous runs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Initialize W&B experiment and download pre-trained segmentation model.\n",
        "\n",
        "This cell:\n",
        "1. Initializes a new W&B run for experiment tracking\n",
        "2. Downloads a previous segmentation model checkpoint for transfer learning\n",
        "3. Sets up the experiment environment for keypoint detection training\n",
        "\"\"\"\n",
        "\n",
        "# Initialize Weights & Biases run\n",
        "run = wandb.init(\n",
        "    project=\"your_project_name\",\n",
        "    name=\"your_experiment_name\",\n",
        "    tags=[\"your\", \"tags\", \"here\"],\n",
        "    notes=\"Your experiment notes here\"\n",
        ")\n",
        "\n",
        "# Download pre-trained segmentation model artifact for transfer learning\n",
        "print(\"üì• Downloading pre-trained model checkpoint...\")\n",
        "artifact = run.use_artifact(\n",
        "    'your_artifact_name:version', \n",
        "    type='model'\n",
        ")\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "print(f\"‚úÖ Model artifact downloaded to: {artifact_dir}\")\n",
        "print(\"üîó W&B experiment initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. üìÅ Dataset Management with Roboflow\n",
        "\n",
        "Download the prawn keypoint detection dataset from Roboflow workspace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Download prawn keypoint detection dataset from Roboflow.\n",
        "\n",
        "This cell:\n",
        "1. Authenticates with Roboflow using API key\n",
        "2. Accesses the prawn morphotypes project\n",
        "3. Downloads the dataset in YOLOv5 format (compatible with YOLOv8)\n",
        "4. Provides access to training/validation splits and annotations\n",
        "\"\"\"\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# Initialize Roboflow client with API key\n",
        "# Note: In production, store API key as environment variable\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "\n",
        "# Access the prawn morphotypes project\n",
        "print(\"üîó Connecting to Roboflow workspace...\")\n",
        "project = rf.workspace(\"workspace\").project(\"project\")\n",
        "\n",
        "# Download dataset version 4 in YOLOv5 format\n",
        "print(\"üì• Downloading dataset...\")\n",
        "dataset = project.version(4).download(\"yolov5\")\n",
        "\n",
        "print(\"‚úÖ Dataset downloaded successfully!\")\n",
        "print(f\"üìÇ Dataset location: {dataset.location}\")\n",
        "print(f\"üè∑Ô∏è Classes: {dataset.names}\")\n",
        "print(f\"üìä Dataset stats: {len(dataset)} total samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. üèóÔ∏è Model Configuration & W&B Callback Setup\n",
        "\n",
        "Load YOLOv8 pose estimation model and configure custom W&B logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Initialize YOLOv8 pose estimation model and setup custom W&B callbacks.\n",
        "\n",
        "This cell:\n",
        "1. Loads pre-trained YOLOv8-large pose estimation model\n",
        "2. Configures custom W&B callback for advanced logging\n",
        "3. Sets up automatic checkpoint saving and artifact management\n",
        "4. Enables comprehensive training metrics tracking\n",
        "\"\"\"\n",
        "\n",
        "# Load YOLOv8-large pose estimation model\n",
        "print(\"ü§ñ Loading YOLOv8-large pose estimation model...\")\n",
        "model = YOLO(\"yolov8l-pose.pt\")  # Pre-trained on COCO keypoints\n",
        "\n",
        "# Configure custom W&B callback with project settings\n",
        "print(\"‚öôÔ∏è Setting up W&B callback for advanced logging...\")\n",
        "wandb_logger = YOLOv8WeightsBiasesIntegrationCallback(\n",
        "    model,\n",
        "    project='YOUR_PROJECT_NAME',  # Placeholder for project name\n",
        "    run_name='YOUR_RUN_NAME',  # Placeholder for run name\n",
        "    tags=['YOUR_TAG1', 'YOUR_TAG2', 'YOUR_TAG3']  # Placeholder for tags\n",
        ")\n",
        "\n",
        "# Attach callback events to model\n",
        "print(\"üîó Attaching W&B callbacks to model...\")\n",
        "for event, callback_fn in wandb_logger.callbacks.items():\n",
        "    model.add_callback(event, callback_fn)\n",
        "\n",
        "print(\"‚úÖ Model and callbacks configured successfully!\")\n",
        "print(f\"üìä Model: {model.model_name}\")\n",
        "print(f\"üéØ Task: Pose estimation (keypoint detection)\")\n",
        "print(f\"üìà W&B Project: {wandb_logger.run.project}\")\n",
        "print(f\"üè∑Ô∏è Run Name: {wandb_logger.run.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. üöÄ Training Execution\n",
        "\n",
        "Execute the training process with optimized hyperparameters for prawn keypoint detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Execute YOLOv8 keypoint detection training with optimized hyperparameters.\n",
        "\n",
        "Training Configuration:\n",
        "- Dataset: Google Drive mounted dataset with prawn keypoint annotations  \n",
        "- Epochs: 300 (with early stopping patience=50)\n",
        "- Image Size: 640x640 pixels\n",
        "- Batch Size: 8 (optimized for Colab GPU memory)\n",
        "- Seed: 42 (for reproducible results)\n",
        "\n",
        "The custom W&B callback will automatically:\n",
        "- Log training metrics and validation results\n",
        "- Save best model checkpoints as W&B artifacts\n",
        "- Generate prediction visualizations and error analysis\n",
        "- Track model performance throughout training\n",
        "\"\"\"\n",
        "\n",
        "# Define dataset configuration path\n",
        "dataset_config = \"/content/drive/MyDrive/colab experiments/to colab only 31-12 segment with 76/data.yaml\"\n",
        "\n",
        "# Verify dataset config exists\n",
        "if os.path.exists(dataset_config):\n",
        "    print(f\"‚úÖ Dataset configuration found: {dataset_config}\")\n",
        "else:\n",
        "    print(f\"‚ùå Dataset configuration not found: {dataset_config}\")\n",
        "    print(\"Please verify the Google Drive path is correct\")\n",
        "\n",
        "# Execute training with optimized hyperparameters\n",
        "print(\"üöÄ Starting YOLOv8 keypoint detection training...\")\n",
        "print(\"‚è±Ô∏è This will take several hours depending on GPU availability\")\n",
        "\n",
        "results = model.train(\n",
        "    data=dataset_config,\n",
        "    epochs=300,           # Maximum training epochs\n",
        "    imgsz=640,            # Input image size\n",
        "    seed=42,              # Random seed for reproducibility\n",
        "    batch=8,              # Batch size optimized for Colab\n",
        "    patience=50,          # Early stopping patience\n",
        "    save=True,            # Save checkpoints\n",
        "    save_period=10,       # Save checkpoint every 10 epochs\n",
        "    verbose=True,         # Verbose logging\n",
        "    device='auto'         # Automatically select GPU if available\n",
        ")\n",
        "\n",
        "print(\"üéâ Training completed successfully!\")\n",
        "print(f\"üìä Best mAP50: {results.metrics['metrics/mAP50(B)']:.3f}\")\n",
        "print(f\"üíæ Model saved to: {results.save_dir}\")\n",
        "print(f\"üîó W&B Run: {wandb_logger.run.url}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. üìà Training Results & Model Artifacts\n",
        "\n",
        "Review training results and ensure all model artifacts are properly saved to W&B.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Post-training analysis and artifact management.\n",
        "\n",
        "This cell:\n",
        "1. Displays final training metrics and model performance\n",
        "2. Verifies W&B artifacts were saved correctly\n",
        "3. Provides links to training visualizations and logs\n",
        "4. Summarizes the training session results\n",
        "\"\"\"\n",
        "\n",
        "# Display training summary\n",
        "print(\"üéØ TRAINING SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìä Final Metrics:\")\n",
        "if hasattr(results, 'metrics'):\n",
        "    for metric_name, value in results.metrics.items():\n",
        "        if isinstance(value, (int, float)):\n",
        "            print(f\"   {metric_name}: {value:.4f}\")\n",
        "\n",
        "print(f\"\\nüíæ Model Artifacts:\")\n",
        "print(f\"   Best weights: {results.save_dir}/weights/best.pt\")\n",
        "print(f\"   Last weights: {results.save_dir}/weights/last.pt\")\n",
        "\n",
        "# Check W&B artifacts\n",
        "print(f\"\\nüîó Weights & Biases:\")\n",
        "print(f\"   Project: {wandb_logger.run.project}\")\n",
        "print(f\"   Run ID: {wandb_logger.run.id}\")\n",
        "print(f\"   Run URL: {wandb_logger.run.url}\")\n",
        "\n",
        "# List artifacts in current run\n",
        "artifacts = wandb_logger.run.logged_artifacts()\n",
        "if artifacts:\n",
        "    print(f\"   Logged Artifacts: {len(artifacts)}\")\n",
        "    for artifact in artifacts:\n",
        "        print(f\"     - {artifact.name} ({artifact.type})\")\n",
        "else:\n",
        "    print(\"   No artifacts found (may still be uploading)\")\n",
        "\n",
        "print(f\"\\n‚úÖ Training completed successfully!\")\n",
        "print(f\"üöÄ Best model checkpoint saved and uploaded to W&B\")\n",
        "print(f\"üìà View detailed training logs and visualizations at: {wandb_logger.run.url}\")\n",
        "\n",
        "# Optional: Finish W&B run\n",
        "# wandb.finish()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
