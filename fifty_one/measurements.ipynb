{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. load the keypoints to fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils as fou\n",
    "import os\n",
    "\n",
    "# Assuming you have a list of image paths and corresponding TXT file paths\n",
    "image_paths = [...]  # List of image file paths\n",
    "txt_paths = [...]  # List of corresponding TXT file paths for each image\n",
    "\n",
    "# Create a FiftyOne dataset\n",
    "dataset = fo.Dataset(\"prawn_pose_estimation\")\n",
    "def parse_pose_estimation(txt_file):\n",
    "    \"\"\"\n",
    "    Parse the pose estimation data from a TXT file.\n",
    "\n",
    "    Parameters:\n",
    "    txt_file (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of pose estimation data (each line parsed into a list of values).\n",
    "    \"\"\"\n",
    "    pose_estimations = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f:\n",
    "            pose_estimations.append([float(x) for x in line.strip().split()])\n",
    "    return pose_estimations\n",
    "\n",
    "# Loop over images and corresponding TXT files\n",
    "for img_path, txt_path in zip(image_paths, txt_paths):\n",
    "    # Parse the pose estimation data from the TXT file\n",
    "    pose_estimations = parse_pose_estimation(txt_path)\n",
    "    \n",
    "    # List to hold all detections and keypoints for the current image\n",
    "    detections = []\n",
    "    \n",
    "    for pose in pose_estimations:\n",
    "        # Extract and scale bounding box and keypoints\n",
    "        x_center_scaled = pose[1] * 5312\n",
    "        y_center_scaled = pose[2] * 2988\n",
    "        width_scaled = pose[3] * 5312\n",
    "        height_scaled = pose[4] * 2988\n",
    "\n",
    "        keypoints = []\n",
    "        for i in range(5, len(pose), 3):\n",
    "            x_kp_scaled = pose[i] * 5312\n",
    "            y_kp_scaled = pose[i + 1] * 2988\n",
    "            confidence = pose[i + 2]\n",
    "            keypoints.append(fo.Keypoint(point=[x_kp_scaled, y_kp_scaled], confidence=confidence))\n",
    "\n",
    "        bounding_box = [\n",
    "            (x_center_scaled - width_scaled / 2) / 5312,\n",
    "            (y_center_scaled - height_scaled / 2) / 2988,\n",
    "            width_scaled / 5312,\n",
    "            height_scaled / 2988\n",
    "        ]\n",
    "\n",
    "        # Create a detection object\n",
    "        detection = fo.Detection(label=\"prawn\", bounding_box=bounding_box, keypoints=keypoints)\n",
    "        detections.append(detection)\n",
    "\n",
    "    # Create a sample for FiftyOne\n",
    "    sample = fo.Sample(filepath=img_path)\n",
    "    sample[\"detections\"] = fo.Detections(detections=detections)\n",
    "    dataset.add_sample(sample)\n",
    "\n",
    "# Launch the FiftyOne app to visualize\n",
    "session = fo.launch_app(dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. load metadata from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fiftyone as fo\n",
    "\n",
    "# Read the Excel file\n",
    "file_path = 'your_file_path.xlsx'  # Replace with your actual file path\n",
    "metadata_df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows to ensure it's loaded correctly\n",
    "print(metadata_df.head())\n",
    "\n",
    "\n",
    "# Assuming you have a list of image paths\n",
    "image_paths = [...]  # List of image file paths\n",
    "\n",
    "# Create a FiftyOne dataset\n",
    "dataset = fo.Dataset(\"prawn_metadata\")\n",
    "\n",
    "# Loop through each image and add metadata\n",
    "for img_path in image_paths:\n",
    "    # Extract the filename without extension\n",
    "    filename = img_path.split('/')[-1].replace('.jpg', '')  # Adjust if not .jpg\n",
    "    \n",
    "    # Match the filename with the metadata\n",
    "    metadata_row = metadata_df[metadata_df['file name'] == filename]\n",
    "    \n",
    "    if not metadata_row.empty:\n",
    "        metadata = metadata_row.iloc[0].to_dict()\n",
    "        \n",
    "        # Create a sample and attach metadata\n",
    "        sample = fo.Sample(filepath=img_path)\n",
    "        \n",
    "        # Add each metadata field to the sample\n",
    "        for key, value in metadata.items():\n",
    "            if key != 'file name':  # Exclude the file name itself\n",
    "                sample[key] = value\n",
    "        \n",
    "        # Add the sample to the dataset\n",
    "        dataset.add_sample(sample)\n",
    "\n",
    "# Launch the FiftyOne app to visualize\n",
    "session = fo.launch_app(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.bounding rectangle between detection and imagej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load ImageJ bounding rectangles from a CSV file\n",
    "imagej_bboxes_df = pd.read_csv('imagej_bboxes.csv')\n",
    "\n",
    "# Example structure of `imagej_bboxes_df`:\n",
    "# Columns: ['file name', 'x1', 'y1', 'x2', 'y2']\n",
    "def calculate_bbox_distance(detection_bbox, imagej_bbox):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between the centers of two bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    detection_bbox (tuple): (x1, y1, x2, y2) coordinates of the detection bounding box.\n",
    "    imagej_bbox (tuple): (x1, y1, x2, y2) coordinates of the ImageJ bounding box.\n",
    "\n",
    "    Returns:\n",
    "    float: Euclidean distance between the centers of the bounding boxes.\n",
    "    \"\"\"\n",
    "    # Calculate centers\n",
    "    detection_center = ((detection_bbox[0] + detection_bbox[2]) / 2, (detection_bbox[1] + detection_bbox[3]) / 2)\n",
    "    imagej_center = ((imagej_bbox[0] + imagej_bbox[2]) / 2, (imagej_bbox[1] + imagej_bbox[3]) / 2)\n",
    "    \n",
    "    # Calculate Euclidean distance between centers\n",
    "    distance = np.sqrt((detection_center[0] - imagej_center[0])**2 + (detection_center[1] - imagej_center[1])**2)\n",
    "    return distance\n",
    "for img_path in image_paths:\n",
    "    filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    # Assume `detections` is a list of bounding boxes from the model\n",
    "    detection_bboxes = [...]  # Replace with actual detection bounding boxes\n",
    "    \n",
    "    # Match with ImageJ bounding box\n",
    "    imagej_bbox = imagej_bboxes_df[imagej_bboxes_df['file name'] == filename].iloc[0]\n",
    "    imagej_bbox = (imagej_bbox['x1'], imagej_bbox['y1'], imagej_bbox['x2'], imagej_bbox['y2'])\n",
    "    \n",
    "    distances = []\n",
    "    for detection_bbox in detection_bboxes:\n",
    "        distance = calculate_bbox_distance(detection_bbox, imagej_bbox)\n",
    "        distances.append(distance)\n",
    "    \n",
    "    # Create a FiftyOne sample and add metadata\n",
    "    sample = fo.Sample(filepath=img_path)\n",
    "    sample['bbox_distances'] = distances  # Store all distances for this image\n",
    "    \n",
    "    dataset.add_sample(sample)\n",
    "\n",
    "# Launch FiftyOne app to visualize\n",
    "session = fo.launch_app(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. calculate length based on pinhole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_real_width(focal_length, distance_to_object, width_in_pixels, pixel_size):\n",
    "    \"\"\"\n",
    "    Calculate the real-life width of an object.\n",
    "\n",
    "    Parameters:\n",
    "    focal_length (float): Focal length of the camera lens in millimeters (mm).\n",
    "    distance_to_object (float): Distance from the camera to the object in millimeters (mm).\n",
    "    width_in_pixels (int): Width of the object in pixels on the image sensor.\n",
    "    pixel_size (float): Size of a pixel on the image sensor in millimeters (mm).\n",
    "\n",
    "    Returns:\n",
    "    float: Real-life width of the object in centimeters (cm).\n",
    "    \"\"\"\n",
    "    # Calculate the width of the object in the image sensor plane in millimeters\n",
    "    width_in_sensor = width_in_pixels * pixel_size\n",
    "\n",
    "    # Calculate the real-life width of the object using the similar triangles principle\n",
    "    real_width_mm = (width_in_sensor * distance_to_object) / focal_length\n",
    "\n",
    "    # Convert the width from millimeters to centimeters\n",
    "    real_width_cm = real_width_mm / 10.0\n",
    "\n",
    "    return real_width_cm\n",
    "\n",
    "def calculate_euclidean_distance(keypoint1, keypoint2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two keypoints.\n",
    "\n",
    "    Parameters:\n",
    "    keypoint1, keypoint2: Tuples of (x, y) coordinates of the keypoints in pixels.\n",
    "\n",
    "    Returns:\n",
    "    float: Euclidean distance between the keypoints in pixels.\n",
    "    \"\"\"\n",
    "    return np.sqrt((keypoint1[0] - keypoint2[0])**2 + (keypoint1[1] - keypoint2[1])**2)\n",
    "\n",
    "# Example of how to integrate this with your FiftyOne dataset\n",
    "for img_path in image_paths:\n",
    "    filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    metadata_row = metadata_df[metadata_df['file name'] == filename]\n",
    "    \n",
    "    if not metadata_row.empty:\n",
    "        metadata = metadata_row.iloc[0].to_dict()\n",
    "        sample = fo.Sample(filepath=img_path)\n",
    "        \n",
    "        # Add metadata\n",
    "        for key, value in metadata.items():\n",
    "            if key != 'file name':\n",
    "                sample[key] = value\n",
    "        \n",
    "        # Calculate the real height or width if keypoints and necessary metadata are available\n",
    "        if 'height(mm)' in metadata:\n",
    "            height_mm = metadata['height(mm)']\n",
    "            focal_length = 6.82  # Example focal length in mm\n",
    "            pixel_size = 0.0014  # Example pixel size in mm\n",
    "            keypoints = [...]  # Replace with actual keypoints from your data\n",
    "            \n",
    "            if len(keypoints) >= 2:\n",
    "                # Calculate the Euclidean distance in pixels\n",
    "                euclidean_distance_pixels = calculate_euclidean_distance(keypoints[0], keypoints[1])\n",
    "                \n",
    "                # Calculate the real width/height in centimeters\n",
    "                real_width_cm = calculate_real_width(focal_length, height_mm, euclidean_distance_pixels, pixel_size)\n",
    "                \n",
    "                # Attach the calculated real width/height to the sample\n",
    "                sample[\"real_width_cm\"] = real_width_cm\n",
    "        \n",
    "        dataset.add_sample(sample)\n",
    "\n",
    "session = fo.launch_app(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complete maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = fo.list_datasets()\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    if dataset_name.startswith('prawn_combined_dataset'):\n",
    "        fo.delete_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "# Load the existing filtered data with PrawnIDs\n",
    "filtered_data_file_path = r'C:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\src\\measurement\\ImageJ\\Filtered_Data.csv'  # Replace with your actual file path\n",
    "filtered_df = pd.read_csv(filtered_data_file_path)\n",
    "\n",
    "# Load the additional metadata from another Excel file\n",
    "metadata_file_path = r\"C:\\Users\\gbo10\\OneDrive\\research\\thesis and paper\\test images.xlsx\"  # Replace with your actual file path\n",
    "metadata_df = pd.read_excel(metadata_file_path)\n",
    "\n",
    "# Function to parse pose estimation data from a TXT file\n",
    "def parse_pose_estimation(txt_file):\n",
    "    pose_estimations = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f:\n",
    "            pose_estimations.append([float(x) for x in line.strip().split()])\n",
    "    return pose_estimations\n",
    "\n",
    "# Function to calculate Euclidean distance between keypoints\n",
    "def calculate_euclidean_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "\n",
    "# Function to calculate the real-life width/height\n",
    "def calculate_real_width(focal_length, distance_to_object, width_in_pixels, pixel_size):\n",
    "    width_in_sensor = width_in_pixels * pixel_size\n",
    "    real_width_mm = (width_in_sensor * distance_to_object) / focal_length\n",
    "    return real_width_mm\n",
    "def extract_identifier_from_gt(filename):\n",
    "    return filename.split('-')[0]\n",
    "\n",
    "folder_path = r'C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\images used for imageJ\\check\\stabilized\\shai\\measurements/1\\carapace\\car'  # Replace with the folder containing the images and TXT files\n",
    "\n",
    "# Assuming you have the following lists\n",
    "image_paths = [os.path.join(folder_path, image) for image in os.listdir(folder_path) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "\n",
    "prediction_folder_path=r\"C:\\Users\\gbo10\\Videos\\data-science\\Research-counting-algorithms\\runs\\pose\\predict19\\labels\"\n",
    "\n",
    "txt_paths = [os.path.join(prediction_folder_path, txt) for txt in os.listdir(prediction_folder_path) if txt.endswith('.txt')]\n",
    "# Create a FiftyOne dataset\n",
    "ground_truth_paths = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\car to compare\\tester_choise\\test\\labels\"  # Replace with the folder containing the ground truth TXT files\n",
    "\n",
    "ground_truth_paths_text = [os.path.join(ground_truth_paths, txt) for txt in os.listdir(ground_truth_paths) if txt.endswith('.txt')]\n",
    "\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "# List all datasets in FiftyOne\n",
    "\n",
    "# Loop through the list and delete datasets that match the condition\n",
    "\n",
    "\n",
    "#delete all datasets\n",
    "\n",
    "\n",
    "# Create a new dataset\n",
    "\n",
    "dataset = fo.Dataset(\"prawn_combined_dataset22\", overwrite=True)\n",
    "\n",
    "dataset.default_skeleton = fo.KeypointSkeleton(\n",
    "    labels=[\n",
    "        \"start_carapace\",\n",
    "        \"eyes\",\n",
    "    ],\n",
    "    edges=[\n",
    "        [0, 1],  # Connect keypoint 0 to keypoint 1  # Connect keypoint 1 to keypoint 2\n",
    "        # Add more connections as needed\n",
    "    ],\n",
    ")\n",
    "# Loop over images and corresponding TXT files\n",
    "for img_path in image_paths:\n",
    "\n",
    "    # Extract the relevant part for matching\n",
    "    filename = os.path.splitext(os.path.basename(img_path))[0] \n",
    "    parts = filename.split('_')\n",
    "    relevant_part = f\"{parts[1][-3:]}_{parts[3].split('.')[0]}\"\n",
    "     # e.g., undistorted_GX010152_36_378.jpg_gamma\n",
    "    identifier = filename.replace('undistorted_', '').replace('.jpg_gamma', '')  # Extract the identifier from the filename\n",
    "\n",
    "\n",
    "    # Construct the paths to the prediction and ground truth files\n",
    "    prediction_txt_path = os.path.join(prediction_folder_path, f\"{filename}.txt\")\n",
    "\n",
    "    # Match ground truth based on the extracted identifier\n",
    "    ground_truth_txt_path = None\n",
    "    for gt_file in ground_truth_paths_text:\n",
    "        b= extract_identifier_from_gt(os.path.basename(gt_file))\n",
    "        if b == identifier:\n",
    "            ground_truth_txt_path = gt_file\n",
    "\n",
    "            break\n",
    "\n",
    "    \n",
    "    # Parse the pose estimation data from the TXT file\n",
    "    pose_estimations = parse_pose_estimation(prediction_txt_path)\n",
    "    \n",
    "    ground_truths = parse_pose_estimation(ground_truth_txt_path)\n",
    "\n",
    "    \n",
    "    keypoints_list = []  # List to store keypoints\n",
    "    detections = []  # List to store detection bounding boxes\n",
    "    ground_truth_keypoints_list = []\n",
    "    ground_truth_detection_list = []\n",
    "\n",
    "    for pose in pose_estimations:\n",
    "        if len(pose)==11:        \n",
    "\n",
    "            x1_rel = pose[1] \n",
    "            y1_rel = pose[2] \n",
    "            width_rel = pose[3] \n",
    "            height_rel = pose[4] \n",
    "\n",
    "            \n",
    "            #center to top left\n",
    "            x1_rel = x1_rel - width_rel/2\n",
    "            y1_rel = y1_rel - height_rel/2\n",
    "        # Calc\n",
    "\n",
    "\n",
    "\n",
    "            keypoints = []\n",
    "            confidences = []\n",
    "            for i in range(5, len(pose), 3):\n",
    "                x_kp_scaled = pose[i] \n",
    "                y_kp_scaled = pose[i + 1] \n",
    "                confidence = pose[i + 2]\n",
    "                keypoints.append([x_kp_scaled, y_kp_scaled])\n",
    "            \n",
    "\n",
    "            confidences = [float(pose[i+2]) for i in range(5, len(pose), 3)]\n",
    "\n",
    "\n",
    "         \n",
    "                \n",
    "            keypoint=fo.Keypoint(points=keypoints, confidence=None)\n",
    "            keypoints_list.append(keypoint)\n",
    "\n",
    "\n",
    "            keypoints_dict= {'point1':keypoints[0],'point2':keypoints[1]}\n",
    "            detections.append(fo.Detection\n",
    "                              (label=\"prawn\", bounding_box=[x1_rel, y1_rel, width_rel, height_rel],\n",
    "                               attributes={'keypoints':keypoints_dict}))\n",
    "            \n",
    "    for gt_pose in ground_truths:\n",
    "            x1_rel = gt_pose[1]\n",
    "            y1_rel = gt_pose[2]\n",
    "            width_rel = gt_pose[3]\n",
    "            height_rel = gt_pose[4]\n",
    "\n",
    "            # Convert center to top-left\n",
    "            x1_rel = x1_rel - width_rel / 2\n",
    "            y1_rel = y1_rel - height_rel / 2\n",
    "\n",
    "            keypoints = []\n",
    "            for i in range(5, len(gt_pose), 3):\n",
    "                x_kp_scaled = gt_pose[i]\n",
    "                y_kp_scaled = gt_pose[i + 1]\n",
    "                keypoints.append([x_kp_scaled, y_kp_scaled])\n",
    "\n",
    "            ground_truth_keypoints_list.append(fo.Keypoint(points=keypoints))\n",
    "            ground_truth_detection_list.append(fo.Detection(label=\"prawn_truth\", bounding_box=[x1_rel, y1_rel, width_rel, height_rel]))\n",
    "\n",
    "    sample = fo.Sample(filepath=img_path)\n",
    "    \n",
    "    sample[\"ground_truth_keypoints\"] = fo.Keypoints(keypoints=ground_truth_keypoints_list)\n",
    "\n",
    "\n",
    "    sample[\"ground_truth_detections\"] = fo.Detections(detections=detections)   \n",
    "    # Add keypoints as a separate field\n",
    "    sample[\"keypoints\"] = fo.Keypoints(keypoints=keypoints_list)\n",
    "   \n",
    "    sample[\"detections_predictions\"] = fo.Detections(detections=detections)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Match the filename with the corresponding rows in the filtered data\n",
    "    matching_rows = filtered_df[filtered_df['Label'] == f'carapace:{filename}']\n",
    "    \n",
    "    # Add metadata from the additional Excel file\n",
    "    metadata_row = metadata_df[metadata_df['file name'] == relevant_part]\n",
    "\n",
    "    if not metadata_row.empty:\n",
    "        metadata = metadata_row.iloc[0].to_dict() \n",
    "        for key, value in metadata.items():\n",
    "            if key != 'file name': \n",
    "                sample[key] = value\n",
    "            \n",
    "                        \n",
    "    else:\n",
    "        print(f\"No metadata found for {relevant_part}\")\n",
    "    true_detections=[]\n",
    "\n",
    "    for _, row in matching_rows.iterrows():\n",
    "        prawn_id = row['PrawnID']\n",
    "        prawn_bbox = ast.literal_eval(row['BoundingBox_1'])  # Replace with the correct column name\n",
    "\n",
    "        # Convert the tuple elements to floats\n",
    "        prawn_bbox = tuple(float(coord) for coord in prawn_bbox)# Replace with correct bounding box columns\n",
    "        \n",
    "        prawn_normalized_bbox=[prawn_bbox[0]/5312, prawn_bbox[1]/2988, prawn_bbox[2]/5312, prawn_bbox[3]/2988]\n",
    "\n",
    "        # Convert PrawnID bounding box to absolute coordinates\n",
    "        \n",
    "        \n",
    "        true_detections.append(fo.Detection(label=\"prawn_true\", bounding_box=prawn_normalized_bbox))\n",
    "\n",
    "        prawn_point=(prawn_bbox[0]/5312, prawn_bbox[1]/2988)\n",
    "        \n",
    "\n",
    "        # Find the closest detection bounding box within the same image (Label)\n",
    "        min_distance = float('inf')\n",
    "        closest_detection = None\n",
    "        \n",
    "        for detection_bbox in sample[\"detections_predictions\"].detections:\n",
    "            detection_bbox_coords = detection_bbox.bounding_box\n",
    "            \n",
    "            det_point=(detection_bbox_coords[0], detection_bbox_coords[1])\n",
    "            \n",
    "            distance = calculate_euclidean_distance(prawn_point, det_point)\n",
    "            \n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_detection = detection_bbox\n",
    "        \n",
    "        if closest_detection is not None:\n",
    "            height_mm = sample['heigtht(mm)']  # Use appropriate column for height in mm\n",
    "            focal_length = 24.22\n",
    "            pixel_size = 0.00716844 \n",
    "\n",
    "                \n",
    "\n",
    "            keypoints_dict2 = closest_detection.attributes[\"keypoints\"]\n",
    "\n",
    "            keypoints1 = [keypoints_dict2['point1'], keypoints_dict2['point2']]    \n",
    "\n",
    "            keypoint1_scaled = [keypoints1[0][0] * 5312, keypoints1[0][1] * 2988]\n",
    "            keypoint2_scaled = [keypoints1[1][0] * 5312, keypoints1[1][1] * 2988]\n",
    "\n",
    "            euclidean_distance_pixels = calculate_euclidean_distance(keypoint1_scaled, keypoint2_scaled)\n",
    "            real_length_cm = calculate_real_width(focal_length, height_mm, euclidean_distance_pixels, pixel_size)\n",
    "            \n",
    "\n",
    "            # Update the filtered_df with the calculated lengths\n",
    "            filtered_df.loc[(filtered_df['Label'] == f'carapace:{filename}') & (filtered_df['PrawnID'] == prawn_id), 'RealLength(cm)'] = real_length_cm\n",
    "            \n",
    "            # Add floating text near the keypoints in FiftyOne\n",
    "\n",
    "            true_length=filtered_df.loc[(filtered_df['Label'] == f'carapace:{filename}') & (filtered_df['PrawnID'] == prawn_id), 'Avg_Length'].values[0]\n",
    "\n",
    "\n",
    "            closest_detection_label =f'MPError: {abs(real_length_cm - true_length) / true_length * 100:.2f}%, true length: {true_length:.2f}cm, pred length: {real_length_cm:.2f}cm'\n",
    "            \n",
    "            closest_detection.label=closest_detection_label\n",
    "\n",
    "\n",
    "            #if mpe>25: tag sample\n",
    "            if abs(real_length_cm - true_length) / true_length * 100 > 25:\n",
    "                if \"MPE>25\" not in sample.tags:\n",
    "                    sample.tags.append(\"MPE>25\")\n",
    "            \n",
    "    # Assuming 'sample' is your FiftyOne sample object\n",
    "        \n",
    "    sample[\"true_detections\"] = fo.Detections(detections=true_detections)            \n",
    "\n",
    "    dataset.add_sample(sample)\n",
    "\n",
    "ground_truth_count=0\n",
    "\n",
    "for sample in dataset:\n",
    "    ground_truth_count+=len(sample[\"ground_truth_detections\"].detections)\n",
    "\n",
    "print('gt',ground_truth_count)\n",
    "\n",
    "detections_predictions_count=0\n",
    "\n",
    "for sample in dataset:\n",
    "    detections_predictions_count+=len(sample[\"detections_predictions\"].detections)\n",
    "\n",
    "print('pred',detections_predictions_count)\n",
    "\n",
    "\n",
    "# Save the updated filtered data with the calculated lengths\n",
    "# filtered_df.to_excel('updated_filtered_data_with_lengths.xlsx', index=False)\n",
    "\n",
    "# Launch the FiftyOne app to visualize\n",
    "\n",
    "# Define a custom view\n",
    "\n",
    "# Configure the view to show your custom attributes\n",
    "\n",
    "\n",
    "session = fo.launch_app(dataset, port=5151)\n",
    "\n",
    "\n",
    "# Launch the app with the custom view\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import SAM\n",
    "from math import sqrt, randint, shuffle\n",
    "import fiftyone as fo\n",
    "import fiftyone.core.labels as fol\n",
    "import os\n",
    "\n",
    "# Helper Classes and Functions for Circle Calculation\n",
    "class Point:\n",
    "    def __init__(self, X=0, Y=0) -> None:\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "class Circle:\n",
    "    def __init__(self, c=Point(), r=0) -> None:    \n",
    "        self.C = c\n",
    "        self.R = r\n",
    "\n",
    "def dist(a, b):\n",
    "    return sqrt((a.X - b.X) ** 2 + (a.Y - b.Y) ** 2)\n",
    "\n",
    "def is_inside(c, p):\n",
    "    return dist(c.C, p) <= c.R\n",
    "\n",
    "def get_circle_center(bx, by, cx, cy):\n",
    "    B = bx * bx + by * by\n",
    "    C = cx * cx + cy * cy\n",
    "    D = bx * cy - by * cx\n",
    "    return Point((cy * B - by * C) / (2 * D), (bx * C - cx * B) / (2 * D))\n",
    "\n",
    "def circle_from1(A, B):\n",
    "    C = Point((A.X + B.X) / 2.0, (A.Y + B.Y) / 2.0)\n",
    "    return Circle(C, dist(A, B) / 2.0)\n",
    "\n",
    "def circle_from2(A, B, C):\n",
    "    I = get_circle_center(B.X - A.X, B.Y - A.Y, C.X - A.X, C.Y - A.Y)\n",
    "    I.X += A.X\n",
    "    I.Y += A.Y\n",
    "    return Circle(I, dist(I, A))\n",
    "\n",
    "def is_valid_circle(c, P):\n",
    "    for p in P:\n",
    "        if not is_inside(c, p):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def min_circle_trivial(P):\n",
    "    assert len(P) <= 3\n",
    "    if not P:\n",
    "        return Circle()\n",
    "    elif len(P) == 1:\n",
    "        return Circle(P[0], 0)\n",
    "    elif len(P) == 2:\n",
    "        return circle_from1(P[0], P[1])\n",
    "    for i in range(3):\n",
    "        for j in range(i + 1, 3):\n",
    "            c = circle_from1(P[i], P[j])\n",
    "            if is_valid_circle(c, P):\n",
    "                return c\n",
    "    return circle_from2(P[0], P[1], P[2])\n",
    "\n",
    "def welzl_helper(P, R, n):\n",
    "    if n == 0 or len(R) == 3:\n",
    "        return min_circle_trivial(R)\n",
    "    idx = randint(0, n - 1)\n",
    "    p = P[idx]\n",
    "    P[idx], P[n - 1] = P[n - 1], P[idx]\n",
    "    d = welzl_helper(P, R.copy(), n - 1)\n",
    "    if is_inside(d, p):\n",
    "        return d\n",
    "    R.append(p)\n",
    "    return welzl_helper(P, R.copy(), n - 1)\n",
    "\n",
    "def welzl(P):\n",
    "    P_copy = P.copy()\n",
    "    shuffle(P_copy)\n",
    "    return welzl_helper(P_copy, [], len(P_copy))\n",
    "def yolo_key_to_box(yolo_line, img_width=640, img_height=640):\n",
    "    # YOLO format: class x_center y_center width height (normalized)\n",
    "    yolo_data = yolo_line.strip().split()\n",
    "    x_center, y_center, width, height = map(float, yolo_data[1:5])\n",
    "\n",
    "\n",
    "    x_center *= img_width\n",
    "    y_center *= img_height\n",
    "    width *= img_width\n",
    "    height *= img_height\n",
    "\n",
    "    # Calculate top-left and bottom-right coordinates\n",
    "    x_min = int(x_center - width / 2)\n",
    "    y_min = int(y_center - height / 2)\n",
    "    x_max = int(x_center + width / 2)\n",
    "    y_max = int(y_center + height / 2)\n",
    "\n",
    "    return np.array([ x_min, y_min, x_max, y_max])\n",
    "\n",
    "def convert_yolo_key_to_boxes(yolo_file):\n",
    "    boxes = []\n",
    "    with open(yolo_file, 'r') as file:\n",
    "        for line in file:\n",
    "            box = yolo_key_to_box(line)\n",
    "            boxes.append(box)\n",
    "    return boxes\n",
    "\n",
    "# Initialize FiftyOne dataset\n",
    "dataset = fo.Dataset(\"prawn_segmentation\")\n",
    "\n",
    "# Load SAM model\n",
    "model = SAM(r'mobile_sam.pt')\n",
    "\n",
    "# Image directory and YOLO annotation files\n",
    "image_dir = \"path_to_images\"\n",
    "yolo_dir = \"path_to_yolo_annotations\"\n",
    "\n",
    "# Iterate over images\n",
    "for image_name in os.listdir(image_dir):\n",
    "    if image_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        yolo_file = os.path.join(yolo_dir, f\"{os.path.splitext(image_name)[0]}.txt\")\n",
    "        \n",
    "        # Convert YOLO annotations to bounding boxes\n",
    "        boxes = convert_yolo_key_to_boxes(yolo_file)\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Perform segmentation\n",
    "        results = model(image, imgsz=640, bboxes=np.array(boxes))\n",
    "        \n",
    "        # Initialize list to store segmentations\n",
    "        segmentations = []\n",
    "        \n",
    "        # Process each mask individually\n",
    "        for mask, score in zip(results[0].masks.xy, results[0].scores):\n",
    "            # Find contours in the mask\n",
    "            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            for contour in contours:\n",
    "                # Convert the contour to a list of Point objects\n",
    "                points = [Point(p[0][0], p[0][1]) for p in contour]\n",
    "                \n",
    "                # Apply Welzl's algorithm to find the minimum enclosing circle\n",
    "                mec = welzl(points)\n",
    "                diameter = mec.R * 2  # Diameter is twice the radius\n",
    "                \n",
    "                # Convert contour to a format suitable for FiftyOne\n",
    "                segmentation = fol.Polyline(\n",
    "                    label=\"prawn_segment\",\n",
    "                    points=[[(float(p[0][0])/image.shape[1], float(p[0][1])/image.shape[0]) for p in contour]],\n",
    "                    filled=True,\n",
    "                    confidence=float(score),\n",
    "                    attributes={\"diameter\": diameter}\n",
    "                )\n",
    "                segmentations.append(segmentation)\n",
    "        \n",
    "        # Add image and segmentation to FiftyOne dataset\n",
    "        sample = fo.Sample(filepath=image_path)\n",
    "        sample[\"segmentations\"] = fol.Polylines(polylines=segmentations)\n",
    "        dataset.add_sample(sample)\n",
    "\n",
    "# Save dataset\n",
    "dataset.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "import fiftyone as fo\n",
    "import os\n",
    "from measurements.data_loader import load_data, create_dataset, process_images\n",
    "\n",
    "# Paths to data files\n",
    "filtered_data_file_path = r'C:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\src\\measurement\\ImageJ\\Filtered_Data.csv'\n",
    "metadata_file_path = r\"C:\\Users\\gbo10\\OneDrive\\research\\thesis and paper\\test images.xlsx\"\n",
    "folder_path = r'C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\images used for imageJ\\check\\stabilized\\shai\\measurements/1\\carapace\\car'\n",
    "prediction_folder_path = r\"C:\\Users\\gbo10\\Videos\\data-science\\Research-counting-algorithms\\runs\\pose\\predict19\\labels\"\n",
    "ground_truth_folder_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\car to compare\\tester_choise\\test\\labels\"\n",
    "\n",
    "# Load data and metadata\n",
    "filtered_df, metadata_df = load_data(filtered_data_file_path, metadata_file_path)\n",
    "\n",
    "# Create FiftyOne dataset\n",
    "dataset = create_dataset()\n",
    "\n",
    "# List all images and corresponding TXT files\n",
    "image_paths = [os.path.join(folder_path, image) for image in os.listdir(folder_path) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "ground_truth_paths_text = [os.path.join(ground_truth_folder_path, txt) for txt in os.listdir(ground_truth_folder_path) if txt.endswith('.txt')]\n",
    "\n",
    "# Process images and predictions\n",
    "process_images(image_paths, prediction_folder_path, ground_truth_paths_text, filtered_df, metadata_df, dataset)\n",
    "\n",
    "# Start the FiftyOne session\n",
    "session = fo.launch_app(dataset, port=5151)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
