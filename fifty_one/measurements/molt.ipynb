{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEC import Circle, Point, welzl\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def calculate_minimum_enclosing_circle(points):\n",
    "    \"\"\"\n",
    "    Calculate the minimum enclosing circle for a set of points using Welzl's algorithm.\n",
    "    Returns the center and radius of the circle.\n",
    "    \"\"\"\n",
    "    mec = welzl(points)  \n",
    "    center=[]\n",
    "    center.append(mec.C.X)\n",
    "    center.append(mec.C.Y)\n",
    "    return center, mec.R\n",
    "\n",
    "def _rotation_matrix(theta):\n",
    "    \"\"\"Creates a 2D rotation matrix for a given angle in radians.\"\"\"\n",
    "    return np.array([\n",
    "        [math.cos(theta), -math.sin(theta)],\n",
    "        [math.sin(theta), math.cos(theta)]\n",
    "    ])\n",
    "\n",
    "def from_rotated_box(xc, yc, w, h, theta, frame_size=None):\n",
    "    \"\"\"\n",
    "    Constructs a rotated bounding box from its center, dimensions, and rotation.\n",
    "\n",
    "    Args:\n",
    "        xc (float): x-center coordinate\n",
    "        yc (float): y-center coordinate\n",
    "        w (float): box width\n",
    "        h (float): box height\n",
    "        theta (float): rotation angle in radians\n",
    "        frame_size (tuple or None): (width, height) of the frame. If provided, points are normalized.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Normalized (x, y) coordinates of the rotated bounding box corners\n",
    "    \"\"\"\n",
    "    # Define the rotation matrix\n",
    "    R = _rotation_matrix(theta)\n",
    "    \n",
    "    # Define the local coordinates of the bounding box corners\n",
    "    local_points = np.array([\n",
    "        [ w / 2,  h / 2],\n",
    "        [-w / 2,  h / 2],\n",
    "        [-w / 2, -h / 2],\n",
    "        [ w / 2, -h / 2]\n",
    "    ])  # shape (4, 2)\n",
    "    \n",
    "    # Apply rotation\n",
    "    rotated_points = R.dot(local_points.T).T  # shape (4, 2)\n",
    "    \n",
    "    # Apply translation to the center\n",
    "    rotated_translated_points = rotated_points + np.array([xc, yc])  # shape (4,2)\n",
    "    \n",
    "    # If frame_size is provided, normalize the points\n",
    "    if frame_size is not None:\n",
    "        rotated_translated_points = rotated_translated_points / np.array(frame_size)\n",
    "    \n",
    "    # Convert to list of tuples\n",
    "    normalized_points = rotated_translated_points.tolist()\n",
    "    \n",
    "    return normalized_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calculate_euclidean_distance, calculate_real_width\n",
    "from skeletonization import skeletonize_mask,create_filled_binary_mask, skeletonize_mask, find_longest_path\n",
    "import cv2\n",
    "import fiftyone as fo\n",
    "import numpy as np\n",
    "\n",
    "def process_segmentations(segmentation_path):\n",
    "    \"\"\"\n",
    "    Process the segmentations from the TXT file, calculate the minimum enclosing circle for each prawn.\n",
    "    \"\"\"\n",
    "    segmentations = []\n",
    "    skeletons=[]\n",
    "    hulls=[]\n",
    "    skeletons_straight=[]\n",
    "    skeletons_straight_2=[]\n",
    "    seg_closeds=[]\n",
    "    skeletons_2=[]\n",
    "    box_diagonal=[] \n",
    "    boxes=[]\n",
    "    masks=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Open the segmentation file and process each line\n",
    "    with open(segmentation_path, 'r') as file:\n",
    "        for line in file:\n",
    "            coords = [float(x) for x in line.strip().split()]\n",
    "            coords_array = np.array(coords).reshape(-1, 2)\n",
    "            \n",
    "\n",
    "            \n",
    "            binary_mask_no = create_filled_binary_mask(coords_array, 360, 640, gaussian_blur=False) \n",
    "            \n",
    "            if np.sum(binary_mask_no) == 0:   \n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            binary_dilated = cv2.dilate(binary_mask_no, np.ones((15, 15), np.uint8), iterations=1)     \n",
    "\n",
    "\n",
    "            #contour dilated\n",
    "            contures_dil, _ = cv2.findContours(binary_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "\n",
    "\n",
    "\n",
    "            prawn_conture_dil = max(contures_dil, key=cv2.contourArea)\n",
    "\n",
    "            coords_contour_dil = np.column_stack(prawn_conture_dil).flatten()\n",
    "\n",
    "            normalized_coords_bin=[(coords_contour_dil[i]/640, coords_contour_dil[i+1]/360) for i in range(0, len(coords_contour_dil), 2)]  # Extract points (x, y)\n",
    "\n",
    "\n",
    "            masks.append(fo.Polyline(\n",
    "                points=[normalized_coords_bin],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "            ))\n",
    "\n",
    "\n",
    "            \n",
    "            thinned_2=skeletonize_mask(binary_mask_no)\n",
    "\n",
    "            # skeleton = skeletonize_mask(binary_mask)\n",
    "            skeleton_2 = thinned_2\n",
    "            skeleton_coords_2 = np.column_stack(np.nonzero(skeleton_2))\n",
    "            normalized_coords_2,max_length_2 = find_longest_path(skeleton_coords_2,(360,640),(2988,5312))\n",
    "\n",
    "            normalized_coords_2 = [(x, y) for y, x in normalized_coords_2]  # Convert to (y, x) format\n",
    "\n",
    "            #only the first and last points of the skeleton\n",
    "            normalized_coords_straight_2 = [normalized_coords_2[0], normalized_coords_2[-1]]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "             \n",
    "            #convex hull diameter\n",
    "            contures, _ = cv2.findContours(binary_mask_no, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            \n",
    "            prawn_conture = max(contures, key=cv2.contourArea)  \n",
    "\n",
    "            # Compute the minimum area rectangle enclosing the shrimp\n",
    "            rect = cv2.minAreaRect(prawn_conture)\n",
    "            box_points = cv2.boxPoints(rect)\n",
    "            box_points = np.int0(box_points)\n",
    "\n",
    "            original_size = (640, 360)\n",
    "            new_size = (5312, 2988)\n",
    "\n",
    "            # Scaling factors\n",
    "            scale_x = new_size[0] / original_size[0]  # 5312 / 640\n",
    "            scale_y = new_size[1] / original_size[1]  # 2988 / 640\n",
    "\n",
    "            box_points_scaled = np.array([(point[0] * scale_x, point[1] * scale_y) for point in box_points])\n",
    "\n",
    "            width= calculate_euclidean_distance(box_points_scaled[0], box_points_scaled[1])\n",
    "            height= calculate_euclidean_distance(box_points_scaled[1], box_points_scaled[2])\n",
    "\n",
    "            max_length_box=max(width,height)\n",
    "\n",
    "\n",
    "        \n",
    "            # Convert theta from degrees to radians for FiftyOne\n",
    "            theta_radians = np.deg2rad(rect[2])\n",
    "            # normalized_bounding_box = [(box_points[i][0]/640, box_points[i][1]/640) for i in range(0, len(box_points))] \n",
    "            \n",
    "            # image_center_x = 640 / 2\n",
    "\n",
    "            # xc_adjusted = rect[0][0] - image_center_x\n",
    "\n",
    "            # Extract points (x, y) \n",
    "            box=fo.Polyline.from_rotated_box(\n",
    "                xc=rect[0][0] ,\n",
    "                yc=rect[0][1],\n",
    "                w=rect[1][0],\n",
    "                h=rect[1][1],\n",
    "                theta =theta_radians,\n",
    "                frame_size=(640, 360)\n",
    "\n",
    "            )\n",
    "\n",
    "\n",
    "            boxes.append(box)\n",
    "\n",
    "\n",
    "            hull_points = cv2.convexHull(prawn_conture, returnPoints=True)\n",
    "\n",
    "\n",
    "            \n",
    "# Scaling factors to convert from 640x640 to 5312x2988\n",
    "            scale_x = 5312 / 640\n",
    "            scale_y = 2988 / 360\n",
    "\n",
    "        # Scale the points to the new resolution\n",
    "            scaled_hull_points = []\n",
    "            for point in hull_points:\n",
    "                x, y = point[0]\n",
    "                scaled_x = x * scale_x\n",
    "                scaled_y = y * scale_y\n",
    "                scaled_hull_points.append([scaled_x, scaled_y])\n",
    "\n",
    "            # Convert to numpy array for easier handling\n",
    "            scaled_hull_points = np.array(scaled_hull_points, dtype=np.float32)\n",
    "\n",
    "            # Now, find the maximum Euclidean distance (convex hull diameter) using the scaled points\n",
    "            max_distance = 0\n",
    "            point1 = None\n",
    "            point2 = None\n",
    "\n",
    "            # Loop through all pairs of scaled points to find the maximum distance\n",
    "            for i in range(len(scaled_hull_points)):\n",
    "                for j in range(i + 1, len(scaled_hull_points)):\n",
    "                    distance = calculate_euclidean_distance(scaled_hull_points[i], scaled_hull_points[j])\n",
    "                    if distance > max_distance:\n",
    "                        max_distance = distance\n",
    "                        point1 = scaled_hull_points[i]\n",
    "                        point2 = scaled_hull_points[j]\n",
    "\n",
    "            # The result is max_distance (in pixels) in the 5312x2988 image\n",
    "\n",
    "\n",
    "            normalzied_points_hull = [(point1[0]/5312, point1[1]/2988), (point2[0]/5312, point2[1]/2988)]  # Extract points (x, y)\n",
    "\n",
    "            hull=fo.Polyline(\n",
    "                points=[normalzied_points_hull],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_distance\n",
    "            )\n",
    "\n",
    "        # skeleton_straight=fo.Polyline(\n",
    "        #     points=[normalized_coords_straight],\n",
    "        #     closed=False,\n",
    "        #     filled=False,\n",
    "        #     max_length=max_length\n",
    "        # )\n",
    "        # skeletons_straight.append(skeleton_straight)\n",
    "\n",
    "            skeleton_straight_2=fo.Polyline(\n",
    "                points=[normalized_coords_straight_2],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_length_2,\n",
    "                \n",
    "            )\n",
    "            skeletons_straight_2.append(skeleton_straight_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            hulls.append(hull)\n",
    "\n",
    "            # skeleton=fo.Polyline(\n",
    "            #     points=[normalized_coords],\n",
    "            #     closed=False,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "\n",
    "            # skeletons.append(skeleton)\n",
    "            \n",
    "            skeleton_2=fo.Polyline( \n",
    "                points=[normalized_coords_2],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_length_2)\n",
    "            skeletons_2.append(skeleton_2)\n",
    "              # Convert the line to a list of floats\n",
    "            normalzied_points = [(coords[i]/640, coords[i + 1]/360) for i in range(0, len(coords), 2)]  # Extract points (x, y)\n",
    "            # points = [Point(x*5312, y*2988) for x, y in normalzied_points] \n",
    "            \n",
    "\n",
    "            scaled_contour = []\n",
    "            for point in prawn_conture:\n",
    "                scaled_x = int(point[0][0] * scale_x)\n",
    "                scaled_y = int(point[0][1] * scale_y)\n",
    "                scaled_contour.append([[scaled_x, scaled_y]])\n",
    "\n",
    "            scaled_contour = np.array(scaled_contour, dtype=np.int32)\n",
    "\n",
    "             # Convert to Point objects    \n",
    "            # Calculate the minimum enclosing circle (center and radius)\n",
    "            center, radius = cv2.minEnclosingCircle(scaled_contour)\n",
    "\n",
    "\n",
    "\n",
    "            diameter = radius * 2\n",
    "\n",
    "\n",
    "            #center in 640x360\n",
    "            center_640 = (center[0] / scale_x, center[1] / scale_y)\n",
    "        \n",
    "\n",
    "            segmentation = fo.Polyline(\n",
    "                points=[normalzied_points],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "                diameter=diameter,\n",
    "                center=center_640,\n",
    "                max_length_skeleton=max_length_2,\n",
    "                max_length_hull=max_distance,\n",
    "                max_length_box=max_length_box\n",
    "            )\n",
    "\n",
    "            #smooth segmentation  wirh closing\n",
    "            # seg_closed=fo.Polyline(\n",
    "            #     points=[normalized_coords_bin],\n",
    "            #     closed=True,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "\n",
    "            # seg_closeds.append(seg_closed)                \n",
    "\n",
    "\n",
    "            segmentations.append(segmentation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                     # Store the segmentation information (center, radius, and diameter)\n",
    "\n",
    "    return segmentations,skeletons,hulls, skeletons_straight,seg_closeds,skeletons_2,skeletons_straight_2,boxes,masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.core.labels as fol\n",
    "from tqdm import tqdm\n",
    "import fiftyone as fo\n",
    "import os\n",
    "\n",
    "def process_images(image_paths, prediction_folder_path, dataset,tag):\n",
    "    print(\"Processing images...\")\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes images by matching segmentation with bounding boxes and calculating prawn sizes.\n",
    "    \"\"\"\n",
    "    for image_path in tqdm(image_paths):\n",
    "        # filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        \n",
    "\n",
    "           \n",
    "        # prediction_txt_path = os.path.join(prediction_folder_path, f\"{os.path.basename(image_path).split('.')[0]}_segmentations.txt\")\n",
    "\n",
    "        core_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "        # Construct the path to the corresponding segmentation file\n",
    "\n",
    "\n",
    "\n",
    "        #check if txt exist\n",
    "\n",
    "        if not os.path.exists(os.path.join(prediction_folder_path, f\"{core_name}_segmentations.txt\")):\n",
    "            print(f\"No segmentation file found for {core_name}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        prediction_txt_path = os.path.join(prediction_folder_path, f\"{core_name}_segmentations.txt\")\n",
    "\n",
    "        # core_name=filename.split('.')[0]\n",
    "        # # Construct the path to the prediction (segmentation) file\n",
    "        # prediction_txt_path = os.path.join(prediction_folder_path, f\"{core_name}_segmentations.txt\")\n",
    "        # if not os.path.exists(prediction_txt_path):\n",
    "        #     print(f\"No segmentation file found for {filename}\")\n",
    "        #     continue\n",
    "\n",
    "\n",
    "        # Parse the segmentations to get the minimum enclosing circles\n",
    "        segmentations,skeletons,hulls,skeletons_straight,seg_closeds,skeletons_2,skeletons_straight_2,boxes,masks = process_segmentations(prediction_txt_path)\n",
    "\n",
    "        # Save the modified image (with circles drawn)\n",
    "\n",
    "        # Create a new sample for FiftyOne\n",
    "        sample = fo.Sample(filepath=image_path)\n",
    "\n",
    "        # Iterate over each bounding box in the filtered data\n",
    "        sample[\"segmentations\"] = fol.Polylines(polylines=segmentations)\n",
    "\n",
    "        # sample[\"skeletons\"] = fol.Polylines(polylines=skeletons)\n",
    "\n",
    "        sample[\"hulls\"] = fol.Polylines(polylines=hulls)    \n",
    "\n",
    "        # sample[\"skeletons_straight\"] = fol.Polylines(polylines=skeletons_straight)\n",
    "\n",
    "        # sample['seg_closeds']=fol.Polylines(polylines=seg_closeds)\n",
    "        \n",
    "        sample['skeletons_no_smooth']=fol.Polylines(polylines=skeletons_2)\n",
    "\n",
    "        sample[\"skeletons_straight_no_smooth\"] = fol.Polylines(polylines=skeletons_straight_2)\n",
    "\n",
    "        sample['boxes']=fol.Polylines(polylines=boxes)\n",
    "\n",
    "        sample['masks']=fol.Polylines(polylines=masks)\n",
    "        # Add the processed sample to the FiftyOne dataset\n",
    "        sample.tags.append(tag)\n",
    "        dataset.add_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def process_detection_by_circle(segmentation, sample,i,dataframe):\n",
    "    \"\"\"\n",
    "    Process the prawn detection based on the enclosing circle's diameter.\n",
    "    Update the filtered dataframe with the real-world size of the prawn.\n",
    "    \"\"\"\n",
    "    poly=segmentation\n",
    "\n",
    "    if 'right' in str(sample.tags[0]):\n",
    "        height_mm =700-30\n",
    "        focal_length = 23.64    \n",
    "    else:\n",
    "        height_mm=410-30\n",
    "        focal_length=24.72\n",
    "\n",
    "    fov=75\n",
    "    predicted_hull_length=poly['max_length_hull']\n",
    "    \n",
    "    FOV_width = 2 * height_mm * math.tan(math.radians(fov / 2))\n",
    "    hull_length_fov = FOV_width * predicted_hull_length / 5312\n",
    "\n",
    "    if hull_length_fov < 120 or hull_length_fov > 220:\n",
    "\n",
    "        return poly\n",
    "\n",
    "    \n",
    "\n",
    "    if hull_length_fov < 175:\n",
    "        best_true_length = 143\n",
    "        if hull_length_fov < 143 and 'smaller than 143mm' not in sample.tags:\n",
    "            sample.tags.append('smaller than 143mm')\n",
    "            dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'true_length'] = '<143mm'\n",
    "\n",
    "\n",
    "    else:\n",
    "        best_true_length = 180\n",
    "        if hull_length_fov < 180 and 'smaller than 180mm' not in sample.tags:\n",
    "            sample.tags.append('smaller than 180mm')\n",
    "            dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'true_length'] = '<180mm'\n",
    "\n",
    "    # for true_length in [143, 180]:\n",
    "        \n",
    "    \n",
    "\n",
    "       \n",
    "    #     error_percentage_hull_fov = abs(hull_length_fov - true_length) / true_length * 100\n",
    "        \n",
    "\n",
    "\n",
    "    #     if error_percentage_hull_fov < min_error_percentage:\n",
    "    #         min_error_percentage = error_percentage_hull_fov\n",
    "    #         best_true_length = true_length\n",
    "\n",
    "    if best_true_length == 143:\n",
    "        height_mm = height_mm\n",
    "    else:\n",
    "        height_mm = height_mm - 15\n",
    "\n",
    "\n",
    "  \n",
    "    # print(f\"height_mm: {height_mm}, tag: {tag}\")\n",
    "\n",
    "    # focal_length = 24.22  # Camera focal length\n",
    "    pixel_size = 0.00716844  # Pixel size in mm\n",
    "\n",
    "    \n",
    "\n",
    "    fov=75\n",
    "    FOV_width=2*height_mm*math.tan(math.radians(fov/2))\n",
    "\n",
    "\n",
    "    # Get the diameter of the circle in pixels\n",
    "    predicted_diameter_pixels = poly['diameter']\n",
    "\n",
    "\n",
    "    predicted_skeleton_length=poly['max_length_skeleton']  \n",
    "\n",
    "    predicted_hull_length=poly['max_length_hull']\n",
    "\n",
    "     \n",
    "    predicted_box_length=poly['max_length_box']\n",
    "\n",
    "    center=poly['center']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #add true lenght to datafram\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'true_length'] = best_true_length\n",
    "\n",
    "\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'center'] = str(center)\n",
    "\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Hull_Length_pixels'] = predicted_hull_length\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Diameter_pixels'] = predicted_diameter_pixels\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Skeleton_Length_pixels'] = predicted_skeleton_length\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Box_Length_pixels'] = predicted_box_length\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate the real-world prawn size using the box\n",
    "    focal_box = calculate_real_width(focal_length, height_mm, predicted_box_length, pixel_size) \n",
    "\n",
    "\n",
    "    focal_hull = calculate_real_width(focal_length, height_mm, predicted_hull_length, pixel_size)    \n",
    "    # Calculate the real-world prawn size using the enclosing circle's diameter\n",
    "    focal_MEC = calculate_real_width(focal_length, height_mm, predicted_diameter_pixels, pixel_size)\n",
    "\n",
    "    focal_ske = calculate_real_width(focal_length, height_mm, predicted_skeleton_length, pixel_size)    \n",
    "\n",
    "\n",
    "    # Update the filtered dataframe with the real-world size of the prawn\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Focal_Box'] = focal_box\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Focal_Hull'] = focal_hull\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Focal_MEC'] = focal_MEC\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Focal_Skeleton'] = focal_ske\n",
    "\n",
    "\n",
    "\n",
    "    hull_length_fov=FOV_width*predicted_hull_length/5312\n",
    "    diameter_length_fov=FOV_width*predicted_diameter_pixels/5312\n",
    "    skeleton_length_fov=FOV_width*predicted_skeleton_length/5312\n",
    "\n",
    "    box_length_fov=FOV_width*predicted_box_length/5312\n",
    "\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Hull_Length_fov'] = hull_length_fov\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Diameter_fov'] = diameter_length_fov\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Skeleton_Length_fov'] = skeleton_length_fov\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Box_Length_fov'] = box_length_fov\n",
    "\n",
    "\n",
    "\n",
    "    error_percentage_hull_fov = abs(hull_length_fov - best_true_length) / best_true_length * 100\n",
    "\n",
    "    error_percentage_skeleton_fov = abs(skeleton_length_fov - best_true_length) / best_true_length * 100  \n",
    "\n",
    "\n",
    "    error_percentage_box_fov = abs(box_length_fov - best_true_length) / best_true_length * 100\n",
    "\n",
    "\n",
    "    error_percentage_MEC_fov = abs(diameter_length_fov - best_true_length) / best_true_length * 100\n",
    "\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Error_percentage_Hull_fov'] = error_percentage_hull_fov\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Error_percentage_Skeleton_fov'] = error_percentage_skeleton_fov\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Error_percentage_Box_fov'] = error_percentage_box_fov\n",
    "\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Error_percentage_MEC_fov'] = error_percentage_MEC_fov\n",
    "\n",
    "    error_percentage_hull_focal = abs(focal_hull - best_true_length) / best_true_length * 100\n",
    "\n",
    "    error_percentage_skeleton_focal = abs(focal_ske - best_true_length) / best_true_length * 100\n",
    "\n",
    "    error_percentage_box_focal = abs(focal_box - best_true_length) / best_true_length * 100\n",
    "\n",
    "    error_percentage_MEC_focal = abs(focal_MEC - best_true_length) / best_true_length * 100\n",
    "\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Error_percentage_Hull_focal'] = error_percentage_hull_focal\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Error_percentage_Skeleton_focal'] = error_percentage_skeleton_focal\n",
    "\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Error_percentage_Box_focal'] = error_percentage_box_focal\n",
    "\n",
    "    dataframe.loc[(dataframe['index'] == i) & (dataframe['image_path'] == sample.filepath), 'Error_percentage_MEC_focal'] = error_percentage_MEC_focal  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    closest_detection_label = f'index:{i} ,true length: {best_true_length:.2f}mm, MPError_hull: {error_percentage_hull_fov:.2f}%, pred length: {hull_length_fov:.2f}mm ,error percentage MEC{error_percentage_MEC_fov:.2f}% ,pred MEC {diameter_length_fov:.2f} ,error percentage skeleton: {error_percentage_skeleton_fov:.2f}%, , pred length: {skeleton_length_fov:.2f}cm, error percentage box: {error_percentage_box_fov:.2f}%, pred length: {box_length_fov:.2f}mm, '\n",
    "    # Update the filtered dataframe with the real-world size of the prawn\n",
    "\n",
    "\n",
    "\n",
    "    if error_percentage_hull_fov > 25 and f'>25% error' not in sample.tags:\n",
    "\n",
    "        sample.tags.append(f'>25% error')\n",
    "\n",
    "    elif error_percentage_hull_fov > 15 and f'15-25% error' not in sample.tags:\n",
    "\n",
    "        sample.tags.append(f'15-25% error')\n",
    "\n",
    "    elif error_percentage_hull_fov > 10  and f'10-15% error' not in sample.tags:\n",
    "\n",
    "        sample.tags.append(f'10-15% error')\n",
    "\n",
    "    elif error_percentage_hull_fov < 10 and f'5-10% error' not in sample.tags:\n",
    "\n",
    "        sample.tags.append(f'5-10% error')\n",
    "    \n",
    "    elif error_percentage_hull_fov < 5 and f'<5% error' not in sample.tags:\n",
    "\n",
    "            \n",
    "        sample.tags.append(f'<5% error')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    poly.label = closest_detection_label \n",
    "    return poly\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/66 [00:00<?, ?it/s]C:\\Users\\gbo10\\AppData\\Local\\Temp\\ipykernel_6608\\3297858279.py:94: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box_points = np.int0(box_points)\n",
      "100%|██████████| 66/66 [00:07<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:05<00:00,  9.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5152/?notebook=True&subscription=35a40ebf-abd3-4825-948d-1179f182ea48\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x259876df490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "molt_right_image_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\image processed\\good\\640360\\right\\color_images\"\n",
    "\n",
    "molt_square_image_path=r\"c:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\image processed\\good\\640360\\square\\color_images\"\n",
    "\n",
    "molt_prediction_right=r'C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\image processed\\good\\640360\\right\\segmentations'\n",
    "\n",
    "molt_prediction_sqaure=r'c:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\image processed\\good\\640360\\square\\segmentations'\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import fiftyone as fo\n",
    "dataset = fo.Dataset(\"molt\", overwrite=True)\n",
    "\n",
    "# Load the dataset\n",
    "right_image_paths = [os.path.join(molt_right_image_path, image) for image in os.listdir(molt_right_image_path) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "\n",
    "square_image_paths = [os.path.join(molt_square_image_path, image) for image in os.listdir(molt_square_image_path) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "\n",
    "for molt_prediction in [molt_prediction_right,molt_prediction_sqaure]:\n",
    "    prediction_paths_text = [os.path.join(molt_prediction, txt) for txt in os.listdir(molt_prediction) if txt.endswith('.txt')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tag=molt_prediction.split('\\\\')[-2]\n",
    "    \n",
    "  \n",
    "    if 'right' in molt_prediction:\n",
    "        image_paths=right_image_paths\n",
    "        process_images(image_paths, molt_prediction, dataset,tag)\n",
    "    else:\n",
    "        image_paths=square_image_paths\n",
    "        process_images(image_paths, molt_prediction, dataset,tag)\n",
    "    # Process segmentations\n",
    "\n",
    "dataframe=pd.DataFrame(columns= ['image_path','index','pond'])\n",
    "\n",
    "for sample in dataset:\n",
    "    # Access the polylines for each sample\n",
    "    for i, segmentation in enumerate(sample[\"segmentations\"].polylines):\n",
    "        \n",
    "        dataframe=dataframe._append({'image_path':sample.filepath,'index':i,'pond':tag},ignore_index=True)\n",
    "        # Process and modify the segmentation\n",
    "        updated_segmentation = process_detection_by_circle(segmentation,sample,i,dataframe)\n",
    "\n",
    "        # Save the updated segmentation back into the sample\n",
    "        sample[\"segmentations\"].polylines[i] = updated_segmentation\n",
    "\n",
    "        sample.save()\n",
    "\n",
    "\n",
    "dataframe.to_csv('molt.csv')\n",
    "session = fo.launch_app(dataset,port=5152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Access the polylines for each sample\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, segmentation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegmentations\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mpolylines):\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m# Process and modify the segmentation\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         updated_segmentation \u001b[38;5;241m=\u001b[39m process_detection_by_circle(segmentation,sample)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\dataset.py:2258\u001b[0m, in \u001b[0;36mDataset.iter_samples\u001b[1;34m(self, progress, autosave, batch_size, batching_strategy)\u001b[0m\n\u001b[0;32m   2251\u001b[0m     save_context \u001b[38;5;241m=\u001b[39m foc\u001b[38;5;241m.\u001b[39mSaveContext(\n\u001b[0;32m   2252\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2253\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2254\u001b[0m         batching_strategy\u001b[38;5;241m=\u001b[39mbatching_strategy,\n\u001b[0;32m   2255\u001b[0m     )\n\u001b[0;32m   2256\u001b[0m     exit_context\u001b[38;5;241m.\u001b[39menter_context(save_context)\n\u001b[1;32m-> 2258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples:\n\u001b[0;32m   2259\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m sample\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m autosave:\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\eta\\core\\utils.py:1718\u001b[0m, in \u001b[0;36mProgressBar.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1718\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1720\u001b[0m         \u001b[38;5;66;03m# Update once more so progress reaches 100%\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(draw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\dataset.py:2269\u001b[0m, in \u001b[0;36mDataset._iter_samples\u001b[1;34m(self, pipeline)\u001b[0m\n\u001b[0;32m   2266\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2269\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetach_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetach_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   2274\u001b[0m         sample \u001b[38;5;241m=\u001b[39m make_sample(d)\n\u001b[0;32m   2275\u001b[0m         index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\dataset.py:6962\u001b[0m, in \u001b[0;36mDataset._aggregate\u001b[1;34m(self, pipeline, media_type, attach_frames, detach_frames, frames_only, support, group_slice, group_slices, detach_groups, groups_only, manual_group_select, post_pipeline)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_aggregate\u001b[39m(\n\u001b[0;32m   6933\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   6934\u001b[0m     pipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6945\u001b[0m     post_pipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6946\u001b[0m ):\n\u001b[0;32m   6947\u001b[0m     _pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline(\n\u001b[0;32m   6948\u001b[0m         pipeline\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[0;32m   6949\u001b[0m         media_type\u001b[38;5;241m=\u001b[39mmedia_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6959\u001b[0m         post_pipeline\u001b[38;5;241m=\u001b[39mpost_pipeline,\n\u001b[0;32m   6960\u001b[0m     )\n\u001b[1;32m-> 6962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfoo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_collection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pipeline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\odm\\database.py:347\u001b[0m, in \u001b[0;36maggregate\u001b[1;34m(collection, pipelines)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _do_async_pooled_aggregate(collection, pipelines)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_pipelines \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipelines\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowDiskUse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [result] \u001b[38;5;28;01mif\u001b[39;00m is_list \u001b[38;5;28;01melse\u001b[39;00m result\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _do_pooled_aggregate(collection, pipelines)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\collection.py:2696\u001b[0m, in \u001b[0;36mCollection.aggregate\u001b[1;34m(self, pipeline, session, let, comment, **kwargs)\u001b[0m\n\u001b[0;32m   2620\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Perform an aggregation using the aggregation framework on this\u001b[39;00m\n\u001b[0;32m   2621\u001b[0m \u001b[38;5;124;03mcollection.\u001b[39;00m\n\u001b[0;32m   2622\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2693\u001b[0m \u001b[38;5;124;03m    https://mongodb.com/docs/manual/reference/command/aggregate\u001b[39;00m\n\u001b[0;32m   2694\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2695\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__database\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39m_tmp_session(session, close\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[1;32m-> 2696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate(\n\u001b[0;32m   2697\u001b[0m         _CollectionAggregationCommand,\n\u001b[0;32m   2698\u001b[0m         pipeline,\n\u001b[0;32m   2699\u001b[0m         CommandCursor,\n\u001b[0;32m   2700\u001b[0m         session\u001b[38;5;241m=\u001b[39ms,\n\u001b[0;32m   2701\u001b[0m         explicit_session\u001b[38;5;241m=\u001b[39msession \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2702\u001b[0m         let\u001b[38;5;241m=\u001b[39mlet,\n\u001b[0;32m   2703\u001b[0m         comment\u001b[38;5;241m=\u001b[39mcomment,\n\u001b[0;32m   2704\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2705\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\_csot.py:108\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\collection.py:2604\u001b[0m, in \u001b[0;36mCollection._aggregate\u001b[1;34m(self, aggregation_command, pipeline, cursor_class, session, explicit_session, let, comment, **kwargs)\u001b[0m\n\u001b[0;32m   2593\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m comment\n\u001b[0;32m   2594\u001b[0m cmd \u001b[38;5;241m=\u001b[39m aggregation_command(\n\u001b[0;32m   2595\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2596\u001b[0m     cursor_class,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2601\u001b[0m     user_fields\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcursor\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirstBatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}},\n\u001b[0;32m   2602\u001b[0m )\n\u001b[1;32m-> 2604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__database\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retryable_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_read_preference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   2607\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_performs_write\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2609\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_Op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAGGREGATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\mongo_client.py:1540\u001b[0m, in \u001b[0;36mMongoClient._retryable_read\u001b[1;34m(self, func, read_pref, session, operation, address, retryable, operation_id)\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;66;03m# Ensure that the client supports retrying on reads and there is no session in\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# transaction, otherwise, we will not support retry behavior for this call.\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m retryable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\n\u001b[0;32m   1538\u001b[0m     retryable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mretry_reads \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (session \u001b[38;5;129;01mand\u001b[39;00m session\u001b[38;5;241m.\u001b[39min_transaction)\n\u001b[0;32m   1539\u001b[0m )\n\u001b[1;32m-> 1540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_read\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_pref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1550\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\_csot.py:108\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\mongo_client.py:1496\u001b[0m, in \u001b[0;36mMongoClient._retry_internal\u001b[1;34m(self, func, session, bulk, operation, is_read, address, read_pref, retryable, operation_id)\u001b[0m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;129m@_csot\u001b[39m\u001b[38;5;241m.\u001b[39mapply\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retry_internal\u001b[39m(\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1481\u001b[0m     operation_id: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1482\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Internal retryable helper for all client transactions.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m \n\u001b[0;32m   1485\u001b[0m \u001b[38;5;124;03m    :param func: Callback function we want to retry\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;124;03m    :return: Output of the calling func()\u001b[39;00m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ClientConnectionRetryable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmongo_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbulk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_read\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_read\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_pref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\mongo_client.py:2353\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error(check_csot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_read \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write()\n\u001b[0;32m   2354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ServerSelectionTimeoutError:\n\u001b[0;32m   2355\u001b[0m     \u001b[38;5;66;03m# The application may think the write was never attempted\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m     \u001b[38;5;66;03m# if we raise ServerSelectionTimeoutError on the retry\u001b[39;00m\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;66;03m# attempt. Raise the original exception instead.\u001b[39;00m\n\u001b[0;32m   2358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error()\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\mongo_client.py:2483\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable._read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper method for read-type retryable client executions\u001b[39;00m\n\u001b[0;32m   2480\u001b[0m \n\u001b[0;32m   2481\u001b[0m \u001b[38;5;124;03m    :return: Output for func()'s call\u001b[39;00m\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2484\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_pref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead Preference required on read calls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_conn_from_server(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_pref, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[0;32m   2486\u001b[0m         conn,\n\u001b[0;32m   2487\u001b[0m         read_pref,\n\u001b[0;32m   2488\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\mongo_client.py:2439\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable._get_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_server\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Server:\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves a server object based on provided object context\u001b[39;00m\n\u001b[0;32m   2436\u001b[0m \n\u001b[0;32m   2437\u001b[0m \u001b[38;5;124;03m    :return: Abstraction to connect to server\u001b[39;00m\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2441\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2442\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2443\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeprioritized_servers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deprioritized_servers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2445\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\mongo_client.py:1322\u001b[0m, in \u001b[0;36mMongoClient._select_server\u001b[1;34m(self, server_selector, session, operation, address, deprioritized_servers, operation_id)\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m AutoReconnect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m no longer available\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m address)  \u001b[38;5;66;03m# noqa: UP031\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1322\u001b[0m         server \u001b[38;5;241m=\u001b[39m \u001b[43mtopology\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m            \u001b[49m\u001b[43mserver_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m            \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdeprioritized_servers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeprioritized_servers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m            \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m server\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PyMongoError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Server selection errors in a transaction are transient.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\topology.py:368\u001b[0m, in \u001b[0;36mTopology.select_server\u001b[1;34m(self, selector, operation, server_selection_timeout, address, deprioritized_servers, operation_id)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_server\u001b[39m(\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    360\u001b[0m     selector: Callable[[Selection], Selection],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     operation_id: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Server:\n\u001b[0;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Like select_servers, but choose a random server if several match.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_selection_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeprioritized_servers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _csot\u001b[38;5;241m.\u001b[39mget_timeout():\n\u001b[0;32m    377\u001b[0m         _csot\u001b[38;5;241m.\u001b[39mset_rtt(server\u001b[38;5;241m.\u001b[39mdescription\u001b[38;5;241m.\u001b[39mmin_round_trip_time)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\topology.py:346\u001b[0m, in \u001b[0;36mTopology._select_server\u001b[1;34m(self, selector, operation, server_selection_timeout, address, deprioritized_servers, operation_id)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_select_server\u001b[39m(\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    339\u001b[0m     selector: Callable[[Selection], Selection],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m     operation_id: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Server:\n\u001b[1;32m--> 346\u001b[0m     servers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_servers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_selection_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_id\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m     servers \u001b[38;5;241m=\u001b[39m _filter_servers(servers, deprioritized_servers)\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(servers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\topology.py:253\u001b[0m, in \u001b[0;36mTopology.select_servers\u001b[1;34m(self, selector, operation, server_selection_timeout, address, operation_id)\u001b[0m\n\u001b[0;32m    250\u001b[0m     server_timeout \u001b[38;5;241m=\u001b[39m server_selection_timeout\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 253\u001b[0m     server_descriptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_servers_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddress\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    258\u001b[0m         cast(Server, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_server_by_address(sd\u001b[38;5;241m.\u001b[39maddress)) \u001b[38;5;28;01mfor\u001b[39;00m sd \u001b[38;5;129;01min\u001b[39;00m server_descriptions\n\u001b[0;32m    259\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\pymongo\\topology.py:327\u001b[0m, in \u001b[0;36mTopology._select_servers_loop\u001b[1;34m(self, selector, timeout, operation, operation_id, address)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_check_all()\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# Release the lock and wait for the topology description to\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# change, or for a timeout. We won't miss any changes that\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# came after our most recent apply_selector call, since we've\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# held the lock until now.\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMIN_HEARTBEAT_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description\u001b[38;5;241m.\u001b[39mcheck_compatible()\n\u001b[0;32m    329\u001b[0m now \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:     molt\n",
      "View name:   molt\n",
      "Media type:  image\n",
      "Num samples: 122\n",
      "Sample fields:\n",
      "    id:                           fiftyone.core.fields.ObjectIdField\n",
      "    filepath:                     fiftyone.core.fields.StringField\n",
      "    tags:                         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:                     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    segmentations:                fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Polylines)\n",
      "    hulls:                        fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Polylines)\n",
      "    skeletons_no_smooth:          fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Polylines)\n",
      "    skeletons_straight_no_smooth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Polylines)\n",
      "    boxes:                        fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Polylines)\n",
      "    masks:                        fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Polylines)\n",
      "View stages:\n",
      "    ---\n"
     ]
    }
   ],
   "source": [
    "#print workspace\n",
    "\n",
    "print (session.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 122/122 [510.6ms elapsed, 0s remaining, 238.9 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Export the view to CSV\n",
    "export_path = \"saved_view_data.csv\"\n",
    "session.view.export(\n",
    "    export_path,\n",
    "    dataset_type=fo.types.CSVDataset,\n",
    "    fields=[\"id\", \"filepath\", \"tags\", \"metadata\"]  # Adjust fields as needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "image_paths=r'C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\image processed\\unditorted'\n",
    "\n",
    "output_path=r'C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\image processed\\unditorted\\undistorted_resized'\n",
    "\n",
    "image_paths = [os.path.join(image_paths, image) for image in os.listdir(image_paths) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "\n",
    "for image_path in tqdm(image_paths):\n",
    "    #resize the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (640, 640))\n",
    "    cv2.imwrite(os.path.join(output_path, os.path.basename(image_path)), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [03:31<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "molt_image_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\all molt\\undistorted\"\n",
    "\n",
    "\n",
    "output_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\all molt\\undistorted\\first_process\"\n",
    "\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# do the code below on entire folder\n",
    "image_paths = [os.path.join(molt_image_path, image) for image in os.listdir(molt_image_path) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "\n",
    "for image_path in tqdm(image_paths):\n",
    "\n",
    "# Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Step 1: Convert to grayscale\n",
    "    # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    white_mask=cv2.inRange(image, (60, 60, 60), (255, 255, 255))\n",
    "\n",
    "    # cv2.imwrite(\"white_mask.png\", white_mask)    \n",
    "\n",
    "\n",
    "\n",
    "    very_white_mask = cv2.inRange(image, (150, 150, 150), (255, 255, 255))\n",
    "\n",
    "\n",
    "    image[very_white_mask == 255] = [0, 0, 0]  # Change white to gray\n",
    "\n",
    "\n",
    "    # cv2.imwrite(\"very_white_mask.png\", image)\n",
    "\n",
    "\n",
    "    gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    # _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Save the result\n",
    "    # cv2.imwrite(\"binary_image.png\", binary)\n",
    "\n",
    "\n",
    "    # cv2.imwrite(\"gray.png\", gray)\n",
    "\n",
    "\n",
    "    # white_mask_from_binary = cv2.bitwise_not(binary)  # Invert the binary mask to get white areas\n",
    "\n",
    "    # cv2.imwrite(\"white_mask_from_binary.png\", white_mask_from_binary)\n",
    "\n",
    "\n",
    "    gray_color = np.array([52, 66, 79])  # RGB value for gray\n",
    "    # image[white_mask == 255] = gray_color\n",
    "\n",
    "    # Step 2: Threshold the image to isolate black areas (under prawns)\n",
    "    # Adjust threshold values depending on how black the segments are\n",
    "    _, black_mask = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)  # Isolating black areas (threshold of 50)\n",
    "\n",
    "\n",
    "    # cv2.imwrite(\"black_mask.png\", black_mask)\n",
    "\n",
    "    # Step 3: Create a bluish image to apply to black areas\n",
    "    bluish_image = image.copy()\n",
    "    bluish_image[:] = [212, 156, 31]  # BGR for blue\n",
    "\n",
    "\n",
    "    #white mask on the black segments\n",
    "    # white_on_black = cv2.bitwise_and(white_mask_from_binary, black_mask)  # Isolate white areas on the black segments\n",
    "\n",
    "    # cv2.imwrite(\"white_on_black.png\", white_on_black)\n",
    "\n",
    "\n",
    "    # # Step 6: Convert white to gray in those areas\n",
    "    # # gray_color = np.array([128, 128, 128])  # RGB value for gray\n",
    "    # image[white_on_black==0] = gray_color  # Change white on black to gray\n",
    "\n",
    "\n",
    "    image[white_mask == 255] = gray_color\n",
    "\n",
    "    # Step 4: Apply bluish color to the black regions\n",
    "    image[black_mask == 255] = bluish_image[black_mask == 255]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Step 5: Isolate white areas (likely prawns) within the black segments\n",
    "    # Detect white pixels in the original image (on the black segments only)\n",
    "    # white_on_black = cv2.bitwise_and(white_mask, black_mask)  # Isolate white areas on the black segments\n",
    "\n",
    "    # Step 6: Convert white to gray in those areas\n",
    "    # gray_color = np.array([128, 128, 128])  # RGB value for gray\n",
    "    # image[white_on_black == 255] = gray_color  # Change white on black to gray\n",
    "\n",
    "    # Step 7: Display the final image\n",
    "    # cv2.imshow(\"Result\", image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the result\n",
    "\n",
    "\n",
    "    #resize the image\n",
    "    resized_image = cv2.resize(image, (640, 360))\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imwrite(os.path.join(output_path, os.path.basename(image_path)), resized_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "image = cv2.imread(r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\image processed\\vlcsnap-2024-09-21-02h23m31s263.png\")\n",
    "\n",
    "    # Step 1: Convert to grayscale\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "white_mask=cv2.inRange(image, (60, 60, 60), (255, 255, 255))\n",
    "\n",
    "# cv2.imwrite(\"white_mask.png\", white_mask)    \n",
    "\n",
    "\n",
    "\n",
    "very_white_mask = cv2.inRange(image, (150, 150, 150), (255, 255, 255))\n",
    "\n",
    "\n",
    "image[very_white_mask == 255] = [0, 0, 0]  # Change white to gray\n",
    "\n",
    "\n",
    "# cv2.imwrite(\"very_white_mask.png\", image)\n",
    "\n",
    "\n",
    "gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Save the result\n",
    "# cv2.imwrite(\"binary_image.png\", binary)\n",
    "\n",
    "\n",
    "# cv2.imwrite(\"gray.png\", gray)\n",
    "\n",
    "\n",
    "# white_mask_from_binary = cv2.bitwise_not(binary)  # Invert the binary mask to get white areas\n",
    "\n",
    "# cv2.imwrite(\"white_mask_from_binary.png\", white_mask_from_binary)\n",
    "\n",
    "\n",
    "gray_color = np.array([132, 129, 122])  # RGB value for gray\n",
    "# image[white_mask == 255] = gray_color\n",
    "\n",
    "# Step 2: Threshold the image to isolate black areas (under prawns)\n",
    "# Adjust threshold values depending on how black the segments are\n",
    "_, black_mask = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)  # Isolating black areas (threshold of 50)\n",
    "\n",
    "\n",
    "# cv2.imwrite(\"black_mask.png\", black_mask)\n",
    "\n",
    "# Step 3: Create a bluish image to apply to black areas\n",
    "bluish_image = image.copy()\n",
    "bluish_image[:] = [212, 156, 31]  # BGR for blue\n",
    "\n",
    "\n",
    "#white mask on the black segments\n",
    "# white_on_black = cv2.bitwise_and(white_mask_from_binary, black_mask)  # Isolate white areas on the black segments\n",
    "\n",
    "# cv2.imwrite(\"white_on_black.png\", white_on_black)\n",
    "\n",
    "\n",
    "# # Step 6: Convert white to gray in those areas\n",
    "# # gray_color = np.array([128, 128, 128])  # RGB value for gray\n",
    "# image[white_on_black==0] = gray_color  # Change white on black to gray\n",
    "\n",
    "\n",
    "image[white_mask == 255] = gray_color\n",
    "\n",
    "# Step 4: Apply bluish color to the black regions\n",
    "image[black_mask == 255] = bluish_image[black_mask == 255]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Isolate white areas (likely prawns) within the black segments\n",
    "# Detect white pixels in the original image (on the black segments only)\n",
    "# white_on_black = cv2.bitwise_and(white_mask, black_mask)  # Isolate white areas on the black segments\n",
    "\n",
    "# Step 6: Convert white to gray in those areas\n",
    "# gray_color = np.array([128, 128, 128])  # RGB value for gray\n",
    "# image[white_on_black == 255] = gray_color  # Change white on black to gray\n",
    "\n",
    "# Step 7: Display the final image\n",
    "# cv2.imshow(\"Result\", image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# Save the result\n",
    "\n",
    "#resize the image\n",
    "cv2.imwrite(r\"vlcsnap-2024-09-21-02h23m31s263.png\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1824 contours\n",
      "Contour 0: Area: 579477.00\n",
      "Contour 1: Area: 544803.50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load a binary image\n",
    "\n",
    "image = cv2.imread(r'C:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\fifty_one\\measurements\\vlcsnap-2024-09-21-02h23m31s263.png')\n",
    "\n",
    "# # Convert to grayscale\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# #save the gray image\n",
    "# cv2.imwrite(\"gray_image.png\", gray)\n",
    "gray_color = np.array([122, 129, 132])  # RGB value for gray\n",
    "\n",
    "lower_bound = gray_color -100 # Allow a small tolerance\n",
    "upper_bound = gray_color + 100\n",
    "\n",
    "# Create a mask where the pixels are within the range of the gray color\n",
    "mask = cv2.inRange(image, lower_bound, upper_bound)\n",
    "\n",
    "# Invert the mask to get the pixels that are NOT the gray color\n",
    "\n",
    "cv2.imwrite(\"mask.png\", mask)\n",
    "\n",
    "# # Make the non-gray pixels black by applying the inverted mask\n",
    "# result = image.copy()\n",
    "# # result[mask_inv == 255] = [0, 0, 0] \n",
    "\n",
    "\n",
    "#thershold the image using gray_color = np.array([132, 129, 122])  # RGB value for gray\n",
    "\n",
    "\n",
    "# cv2.imwrite(\"result.png\", result)\n",
    "\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(f\"Found {len(contours)} contours\")\n",
    "\n",
    "conutres1=[]\n",
    "\n",
    "i=0\n",
    "# Iterate through contours\n",
    "for contour in contours:\n",
    "    # Calculate area and perimeter (arc length)\n",
    "    area = cv2.contourArea(contour)\n",
    "    # perimeter = cv2.arcLength(contour, True)\n",
    "   \n",
    "    if area > 90000:\n",
    "        \n",
    "\n",
    "        conutres1.append(contour)\n",
    "\n",
    "        print(f\"Contour {i}: Area: {area:.2f}\")\n",
    "        cv2.drawContours(image, [contour], -1, (0, 255, 0), 2)\n",
    "        i+=1\n",
    "\n",
    "\n",
    "#     #Draw the contour\n",
    "\n",
    "#what is not in the contures1 paint in azure   \n",
    "    \n",
    "   \n",
    "# # Save the output image\n",
    "cv2.imwrite('ellipses_output.png', image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find contours\n",
    "# contours, hierarchy = cv2.findContours(binary_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Draw contours on the original image\n",
    "# output_image = cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR)  # Convert grayscale to BGR for color drawing\n",
    "# cv2.drawContours(output_image, contours, -1, (0, 255, 0), 2)  # Draw all contours in green\n",
    "\n",
    "# Save the output image\n",
    "# cv2.imwrite('contours_output.png', output_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589.5\n",
      "32496.5\n",
      "12145.0\n",
      "3556.5\n",
      "1674.5\n",
      "638.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\all molt\\undistorted\\first_process\\right\\azure\\undistorted_GX010191_37_392.jpg\")\n",
    "\n",
    "# Define the color to paint the background (Azure color in BGR format)\n",
    "azure_color = [212, 156, 31]  # Azure in BGR (Blue, Green, Red)\n",
    "\n",
    "# Define gray color and tolerance\n",
    "gray_color = np.array([52, 66, 79])  # RGB value for gray\n",
    "lower_bound = gray_color - 50\n",
    "upper_bound = gray_color + 50\n",
    "\n",
    "\n",
    "# Create a mask for the gray color\n",
    "mask = cv2.inRange(image, lower_bound, upper_bound)\n",
    "\n",
    "# Find contours in the mask\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter contours based on area and create a new mask for the contours\n",
    "contours_mask = np.zeros_like(mask)  # A black mask of the same size as the original image\n",
    "\n",
    "# Iterate through contours and draw only the ones with sufficient area\n",
    "for contour in contours:\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area > 500: \n",
    "        print (area)\n",
    "        # Draw the contours on the black mask\n",
    "        cv2.drawContours(contours_mask, [contour], -1, 255, thickness=cv2.FILLED)  # Fill the contours in white\n",
    "\n",
    "# Invert the contours mask (make contours black and the rest white)\n",
    "contours_mask_inv = cv2.bitwise_not(contours_mask)\n",
    "\n",
    "# Create a background image filled with the azure color\n",
    "azure_background = np.full_like(image, azure_color, dtype=np.uint8)\n",
    "\n",
    "# Mask out the contour areas and paint the rest azure\n",
    "result = cv2.bitwise_and(image, image, mask=contours_mask)  # Keep the original image inside the contours\n",
    "azure_areas = cv2.bitwise_and(azure_background, azure_background, mask=contours_mask_inv)  # Paint everything else azure\n",
    "\n",
    "# Combine the original image (inside contours) with the azure background (outside contours)\n",
    "final_result = cv2.add(result, azure_areas)\n",
    "\n",
    "# Save and display the final result\n",
    "cv2.imwrite(\"result_azure_background.png\", final_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/93 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:02<00:00, 41.29it/s]\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "molt_image_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\all molt\\undistorted\\first_process\\square\"\n",
    "\n",
    "\n",
    "output_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\all molt\\undistorted\\first_process\\square\\azure\"\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True) \n",
    "\n",
    "image_paths = [os.path.join(molt_image_path, image) for image in os.listdir(molt_image_path) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "\n",
    "\n",
    "for image_path in tqdm(image_paths):\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    azure_color = [212, 156, 31]  # Azure in BGR (Blue, Green, Red)\n",
    "\n",
    "    # Define gray color and tolerance\n",
    "    gray_color = np.array([52, 66, 79])  # RGB value for gray\n",
    "    lower_bound = gray_color - 50\n",
    "    upper_bound = gray_color + 50\n",
    "\n",
    "    # Create a mask for the gray color\n",
    "    mask = cv2.inRange(image, lower_bound, upper_bound)\n",
    "\n",
    "    cv2.imwrite(\"mask.png\", mask)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on area and create a new mask for the contours\n",
    "    contours_mask = np.zeros_like(mask)  # A black mask of the same size as the original image\n",
    "\n",
    "    # Iterate through contours and draw only the ones with sufficient area\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area >800:  \n",
    "            \n",
    "     \n",
    "            # Filter by area\n",
    "            # Draw the contours on the black mask\n",
    "            cv2.drawContours(contours_mask, [contour], -1, 255, thickness=cv2.FILLED)  # Fill the contours in white\n",
    "\n",
    "    # Invert the contours mask (make contours black and the rest white)\n",
    "    contours_mask_inv = cv2.bitwise_not(contours_mask)\n",
    "\n",
    "    # Create a background image filled with the azure color\n",
    "    azure_background = np.full_like(image, azure_color, dtype=np.uint8)\n",
    "\n",
    "    # Mask out the contour areas and paint the rest azure\n",
    "    result = cv2.bitwise_and(image, image, mask=contours_mask)  # Keep the original image inside the contours\n",
    "    azure_areas = cv2.bitwise_and(azure_background, azure_background, mask=contours_mask_inv)  # Paint everything else azure\n",
    "\n",
    "    # Combine the original image (inside contours) with the azure background (outside contours)\n",
    "    final_result = cv2.add(result, azure_areas)\n",
    "\n",
    "    #Save the result\n",
    "    cv2.imwrite(os.path.join(output_path, os.path.basename(image_path)), final_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
