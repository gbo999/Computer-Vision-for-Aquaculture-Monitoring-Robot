{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEC import Circle, Point, welzl\n",
    "\n",
    "def calculate_minimum_enclosing_circle(points):\n",
    "    \"\"\"\n",
    "    Calculate the minimum enclosing circle for a set of points using Welzl's algorithm.\n",
    "    Returns the center and radius of the circle.\n",
    "    \"\"\"\n",
    "    mec = welzl(points)  \n",
    "    center=[]\n",
    "    center.append(mec.C.X)\n",
    "    center.append(mec.C.Y)\n",
    "    return center, mec.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calculate_euclidean_distance, calculate_real_width\n",
    "from skeletonization import skeletonize_mask,create_filled_binary_mask, skeletonize_mask, find_longest_path\n",
    "import cv2\n",
    "import fiftyone as fo\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def process_segmentations(segmentation_path):\n",
    "    \"\"\"\n",
    "    Process the segmentations from the TXT file, calculate the minimum enclosing circle for each prawn.\n",
    "    \"\"\"\n",
    "    segmentations = []\n",
    "    skeletons=[]\n",
    "    hulls=[]\n",
    "    skeletons_straight=[]\n",
    "    skeletons_straight_2=[]\n",
    "    seg_closeds=[]\n",
    "    skeletons_2=[]\n",
    "    box_diagonal=[] \n",
    "    boxes=[]\n",
    "    masks=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Open the segmentation file and process each line\n",
    "    with open(segmentation_path, 'r') as file:\n",
    "        for line in file:\n",
    "            coords = list(map(float, line.strip().split()))\n",
    "            binary_mask = create_filled_binary_mask(coords, 640, 640)\n",
    "            \n",
    "            \n",
    "            binary_mask_no= create_filled_binary_mask(coords, 640, 640,gaussian_blur=False) \n",
    "\n",
    "            binary_dilated = cv2.dilate(binary_mask_no, np.ones((15, 15), np.uint8), iterations=1)     \n",
    "\n",
    "\n",
    "            #contour dilated\n",
    "            contures_dil, _ = cv2.findContours(binary_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "\n",
    "            prawn_conture_dil = max(contures_dil, key=cv2.contourArea)\n",
    "\n",
    "            coords_contour_dil = np.column_stack(prawn_conture_dil).flatten()\n",
    "\n",
    "            normalized_coords_bin=[(coords_contour_dil[i]/640, coords_contour_dil[i+1]/640) for i in range(0, len(coords_contour_dil), 2)]  # Extract points (x, y)\n",
    "            # coords_bin = np.column_stack(np.nonzero(binary_dilated)).flatten()\n",
    "\n",
    "            # normalized_coords_bin=[(coords_bin[i+1]/640, coords_bin[i]/640) for i in range(0, len(coords_bin), 2)]  # Extract points (x, y)\n",
    "\n",
    "\n",
    "\n",
    "            masks.append(fo.Polyline(\n",
    "                points=[normalized_coords_bin],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "            ))\n",
    "\n",
    "\n",
    "\n",
    "            # #convert binary mask to normalized coordinates\n",
    "            # binary_mask_smooth = binary_mask.astype(np.uint8)\n",
    "            # #x,y coordinates of the mask\n",
    "            # coords_bin = np.column_stack(np.nonzero(binary_mask_smooth)).flatten()\n",
    "\n",
    "            # normalized_coords_bin=[(coords_bin[i+1]/640, coords_bin[i]/640) for i in range(0, len(coords_bin), 2)]  # Extract points (x, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            # #thin the mask\n",
    "            # thinned=skeletonize_mask(binary_mask)\n",
    "\n",
    "            # # skeleton = skeletonize_mask(binary_mask)\n",
    "            # skeleton = thinned\n",
    "            # skeleton_coords = np.column_stack(np.nonzero(skeleton))\n",
    "            # normalized_coords,max_length = find_longest_path(skeleton_coords,(640,640),(2988,5312))\n",
    "\n",
    "            # normalized_coords = [(x, y) for y, x in normalized_coords]  # Convert to (y, x) format\n",
    "\n",
    "            # #only the first and last points of the skeleton\n",
    "            # normalized_coords_straight = [normalized_coords[0], normalized_coords[-1]]  \n",
    "\n",
    "            \n",
    "            thinned_2=skeletonize_mask(binary_mask_no)\n",
    "\n",
    "            # skeleton = skeletonize_mask(binary_mask)\n",
    "            skeleton_2 = thinned_2\n",
    "            skeleton_coords_2 = np.column_stack(np.nonzero(skeleton_2))\n",
    "            normalized_coords_2,max_length_2 = find_longest_path(skeleton_coords_2,(640,640),(2988,5312))\n",
    "\n",
    "            normalized_coords_2 = [(x, y) for y, x in normalized_coords_2]  # Convert to (y, x) format\n",
    "\n",
    "            #only the first and last points of the skeleton\n",
    "            normalized_coords_straight_2 = [normalized_coords_2[0], normalized_coords_2[-1]]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #convex hull diameter\n",
    "            contures, _ = cv2.findContours(binary_mask_no, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            \n",
    "            prawn_conture = max(contures, key=cv2.contourArea)  \n",
    "\n",
    "            # Compute the minimum area rectangle enclosing the shrimp\n",
    "            rect = cv2.minAreaRect(prawn_conture)\n",
    "            box_points = cv2.boxPoints(rect)\n",
    "            box_points = np.int0(box_points)\n",
    "\n",
    "            original_size = (640, 640)\n",
    "            new_size = (5312, 2988)\n",
    "\n",
    "            # Scaling factors\n",
    "            scale_x = new_size[0] / original_size[0]  # 5312 / 640\n",
    "            scale_y = new_size[1] / original_size[1]  # 2988 / 640\n",
    "\n",
    "            box_points_scaled = np.array([(point[0] * scale_x, point[1] * scale_y) for point in box_points])\n",
    "\n",
    "            width= calculate_euclidean_distance(box_points_scaled[0], box_points_scaled[1])\n",
    "            height= calculate_euclidean_distance(box_points_scaled[1], box_points_scaled[2])\n",
    "\n",
    "            max_length_box=max(width,height)\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "            normalized_bounding_box = [(box_points[i][0]/640, box_points[i][1]/640) for i in range(0, len(box_points))] \n",
    "            \n",
    "            # Extract points (x, y) \n",
    "            box=fo.Polyline(\n",
    "                points=[normalized_bounding_box],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "                max_length=max_length_box\n",
    "            )\n",
    "\n",
    "\n",
    "            boxes.append(box)\n",
    "\n",
    "\n",
    "            hull_points = cv2.convexHull(prawn_conture, returnPoints=True)\n",
    "\n",
    "\n",
    "            \n",
    "# Scaling factors to convert from 640x640 to 5312x2988\n",
    "            scale_x = 5312 / 640\n",
    "            scale_y = 2988 / 640\n",
    "\n",
    "        # Scale the points to the new resolution\n",
    "            scaled_hull_points = []\n",
    "            for point in hull_points:\n",
    "                x, y = point[0]\n",
    "                scaled_x = x * scale_x\n",
    "                scaled_y = y * scale_y\n",
    "                scaled_hull_points.append([scaled_x, scaled_y])\n",
    "\n",
    "            # Convert to numpy array for easier handling\n",
    "            scaled_hull_points = np.array(scaled_hull_points, dtype=np.float32)\n",
    "\n",
    "            # Now, find the maximum Euclidean distance (convex hull diameter) using the scaled points\n",
    "            max_distance = 0\n",
    "            point1 = None\n",
    "            point2 = None\n",
    "\n",
    "            # Loop through all pairs of scaled points to find the maximum distance\n",
    "            for i in range(len(scaled_hull_points)):\n",
    "                for j in range(i + 1, len(scaled_hull_points)):\n",
    "                    distance = calculate_euclidean_distance(scaled_hull_points[i], scaled_hull_points[j])\n",
    "                    if distance > max_distance:\n",
    "                        max_distance = distance\n",
    "                        point1 = scaled_hull_points[i]\n",
    "                        point2 = scaled_hull_points[j]\n",
    "\n",
    "            # The result is max_distance (in pixels) in the 5312x2988 image\n",
    "\n",
    "\n",
    "            normalzied_points_hull = [(point1[0]/5312, point1[1]/2988), (point2[0]/5312, point2[1]/2988)]  # Extract points (x, y)\n",
    "\n",
    "            hull=fo.Polyline(\n",
    "                points=[normalzied_points_hull],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_distance\n",
    "            )\n",
    "\n",
    "            # skeleton_straight=fo.Polyline(\n",
    "            #     points=[normalized_coords_straight],\n",
    "            #     closed=False,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "            # skeletons_straight.append(skeleton_straight)\n",
    "\n",
    "            skeleton_straight_2=fo.Polyline(\n",
    "                points=[normalized_coords_straight_2],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_length_2,\n",
    "                \n",
    "            )\n",
    "            skeletons_straight_2.append(skeleton_straight_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            hulls.append(hull)\n",
    "\n",
    "            # skeleton=fo.Polyline(\n",
    "            #     points=[normalized_coords],\n",
    "            #     closed=False,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "\n",
    "            # skeletons.append(skeleton)\n",
    "            \n",
    "            skeleton_2=fo.Polyline( \n",
    "                points=[normalized_coords_2],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_length_2)\n",
    "            skeletons_2.append(skeleton_2)\n",
    "              # Convert the line to a list of floats\n",
    "            normalzied_points = [(coords[i]/640, coords[i + 1]/640) for i in range(0, len(coords), 2)]  # Extract points (x, y)\n",
    "            points = [Point(x*5312, y*2988) for x, y in normalzied_points] \n",
    "            \n",
    "\n",
    "            \n",
    "             # Convert to Point objects    \n",
    "            # Calculate the minimum enclosing circle (center and radius)\n",
    "            center, radius = calculate_minimum_enclosing_circle(points)\n",
    "            diameter = radius * 2\n",
    "\n",
    "            segmentation = fo.Polyline(\n",
    "                points=[normalzied_points],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "                diameter=diameter,\n",
    "                center=center,\n",
    "                max_length_skeleton=max_length_2,\n",
    "                max_length_hull=max_distance,\n",
    "                max_length_box=max_length_box\n",
    "            )\n",
    "\n",
    "            #smooth segmentation  wirh closing\n",
    "            # seg_closed=fo.Polyline(\n",
    "            #     points=[normalized_coords_bin],\n",
    "            #     closed=True,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "\n",
    "            # seg_closeds.append(seg_closed)                \n",
    "\n",
    "\n",
    "            segmentations.append(segmentation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                     # Store the segmentation information (center, radius, and diameter)\n",
    "\n",
    "    return segmentations,skeletons,hulls, skeletons_straight,seg_closeds,skeletons_2,skeletons_straight_2,boxes,masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.core.labels as fol\n",
    "from tqdm import tqdm\n",
    "import fiftyone as fo\n",
    "import os\n",
    "\n",
    "def process_images(image_paths, prediction_folder_path, dataset):\n",
    "    print(\"Processing images...\")\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes images by matching segmentation with bounding boxes and calculating prawn sizes.\n",
    "    \"\"\"\n",
    "    for image_path in tqdm(image_paths):\n",
    "        # filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        \n",
    "\n",
    "           \n",
    "        # prediction_txt_path = os.path.join(prediction_folder_path, f\"{os.path.basename(image_path).split('.')[0]}_segmentations.txt\")\n",
    "\n",
    "        core_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "        # Construct the path to the corresponding segmentation file\n",
    "        prediction_txt_path = os.path.join(prediction_folder_path, f\"{core_name}_segmentations.txt\")\n",
    "\n",
    "        # core_name=filename.split('.')[0]\n",
    "        # # Construct the path to the prediction (segmentation) file\n",
    "        # prediction_txt_path = os.path.join(prediction_folder_path, f\"{core_name}_segmentations.txt\")\n",
    "        # if not os.path.exists(prediction_txt_path):\n",
    "        #     print(f\"No segmentation file found for {filename}\")\n",
    "        #     continue\n",
    "\n",
    "\n",
    "        # Parse the segmentations to get the minimum enclosing circles\n",
    "        segmentations,skeletons,hulls,skeletons_straight,seg_closeds,skeletons_2,skeletons_straight_2,boxes,masks = process_segmentations(prediction_txt_path)\n",
    "\n",
    "        # Save the modified image (with circles drawn)\n",
    "\n",
    "        # Create a new sample for FiftyOne\n",
    "        sample = fo.Sample(filepath=image_path)\n",
    "\n",
    "        # Iterate over each bounding box in the filtered data\n",
    "        sample[\"segmentations\"] = fol.Polylines(polylines=segmentations)\n",
    "\n",
    "        # sample[\"skeletons\"] = fol.Polylines(polylines=skeletons)\n",
    "\n",
    "        sample[\"hulls\"] = fol.Polylines(polylines=hulls)    \n",
    "\n",
    "        # sample[\"skeletons_straight\"] = fol.Polylines(polylines=skeletons_straight)\n",
    "\n",
    "        # sample['seg_closeds']=fol.Polylines(polylines=seg_closeds)\n",
    "        \n",
    "        sample['skeletons_no_smooth']=fol.Polylines(polylines=skeletons_2)\n",
    "\n",
    "        sample[\"skeletons_straight_no_smooth\"] = fol.Polylines(polylines=skeletons_straight_2)\n",
    "\n",
    "        sample['boxes']=fol.Polylines(polylines=boxes)\n",
    "\n",
    "        sample['masks']=fol.Polylines(polylines=masks)\n",
    "        # Add the processed sample to the FiftyOne dataset\n",
    "        dataset.add_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def process_detection_by_circle(segmentation):\n",
    "    \"\"\"\n",
    "    Process the prawn detection based on the enclosing circle's diameter.\n",
    "    Update the filtered dataframe with the real-world size of the prawn.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch height in mm and other metadata\n",
    "    height_mm =500\n",
    "    #focal length based on pond type\n",
    "    \n",
    "    focal_length = 24.72\n",
    "\n",
    "\n",
    "    # focal_length = 24.22  # Camera focal length\n",
    "    pixel_size = 0.00716844  # Pixel size in mm\n",
    "\n",
    "    poly=segmentation\n",
    "\n",
    "    fov=75\n",
    "    FOV_width=2*height_mm*math.tan(math.radians(fov/2))\n",
    "\n",
    "\n",
    "    # Get the diameter of the circle in pixels\n",
    "    predicted_diameter_pixels = poly['diameter']\n",
    "\n",
    "\n",
    "    predicted_skeleton_length=poly['max_length_skeleton']  \n",
    "\n",
    "    predicted_hull_length=poly['max_length_hull']\n",
    "\n",
    "     \n",
    "    predicted_box_length=poly['max_length_box']\n",
    "\n",
    "    # Calculate the real-world prawn size using the box\n",
    "    real_length_mm_box = calculate_real_width(focal_length, height_mm, predicted_box_length, pixel_size) \n",
    "\n",
    "\n",
    "    hull_length_cm = calculate_real_width(focal_length, height_mm, predicted_hull_length, pixel_size)    \n",
    "\n",
    "    # Calculate the real-world prawn size using the enclosing circle's diameter\n",
    "    real_length_cm = calculate_real_width(focal_length, height_mm, predicted_diameter_pixels, pixel_size)\n",
    "\n",
    "    ske_length_cm = calculate_real_width(focal_length, height_mm, predicted_skeleton_length, pixel_size)    \n",
    "\n",
    "\n",
    "    hull_length_fov=FOV_width*predicted_hull_length/5312\n",
    "    diameter_length_fov=FOV_width*predicted_diameter_pixels/5312\n",
    "    skeleton_length_fov=FOV_width*predicted_skeleton_length/5312\n",
    "\n",
    "    box_length_fov=FOV_width*predicted_box_length/5312\n",
    "\n",
    "    true_length=143\n",
    "    error_percentage_MEC_fov = abs(diameter_length_fov - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_hull_fov = abs(hull_length_fov - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_skeleton_fov = abs(skeleton_length_fov - true_length) / true_length * 100  \n",
    "\n",
    "    error_percentage = abs(real_length_cm - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_skeleton = abs(ske_length_cm - true_length) / true_length * 100    \n",
    "\n",
    "    error_percentage_hull = abs(hull_length_cm - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_box_fov = abs(box_length_fov - true_length) / true_length * 100\n",
    "\n",
    "    closest_detection_label = f'true length: {true_length:.2f}mm, MPError: {error_percentage_hull_fov:.2f}%, , pred length: {hull_length_fov:.2f}mm ,error percentage skeleton: {error_percentage_skeleton_fov:.2f}%, , pred length: {skeleton_length_fov:.2f}cm, error percentage box: {error_percentage_box_fov:.2f}%, pred length: {box_length_fov:.2f}mm, '\n",
    "    poly.label = closest_detection_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: undistorted_vlcsnap-2024-09-19-21h46m36s160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gbo10\\AppData\\Local\\Temp\\ipykernel_44812\\2001072356.py:115: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box_points = np.int0(box_points)\n",
      " 33%|███▎      | 2/6 [00:00<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: undistorted_vlcsnap-2024-09-19-21h46m54s892\n",
      "Processing image: undistorted_vlcsnap-2024-09-19-21h47m01s074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:00<00:00,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: undistorted_vlcsnap-2024-09-19-21h47m15s479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:00<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: undistorted_vlcsnap-2024-09-19-21h49m34s599\n",
      "Processing image: undistorted_vlcsnap-2024-09-19-21h49m47s447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Polyline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m segmentation \u001b[38;5;129;01min\u001b[39;00m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegmentations\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolylines\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 19\u001b[0m         \u001b[43mprocess_detection_by_circle\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Launch FiftyOne session\u001b[39;00m\n\u001b[0;32m     22\u001b[0m session \u001b[38;5;241m=\u001b[39m fo\u001b[38;5;241m.\u001b[39mlaunch_app(dataset)\n",
      "Cell \u001b[1;32mIn[25], line 18\u001b[0m, in \u001b[0;36mprocess_detection_by_circle\u001b[1;34m(segmentation)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# focal_length = 24.22  # Camera focal length\u001b[39;00m\n\u001b[0;32m     16\u001b[0m pixel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00716844\u001b[39m  \u001b[38;5;66;03m# Pixel size in mm\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m poly\u001b[38;5;241m=\u001b[39m\u001b[43msegmentation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPolyline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     20\u001b[0m fov\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m\n\u001b[0;32m     21\u001b[0m FOV_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mheight_mm\u001b[38;5;241m*\u001b[39mmath\u001b[38;5;241m.\u001b[39mtan(math\u001b[38;5;241m.\u001b[39mradians(fov\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\base\\document.py:257\u001b[0m, in \u001b[0;36mBaseDocument.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(name)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Polyline'"
     ]
    }
   ],
   "source": [
    "molt_image_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\molt-19-9\\unditorted\"\n",
    "molt_prediction=r'C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\molt-19-9\\unditorted_resized'\n",
    "\n",
    "import fiftyone as fo\n",
    "dataset = fo.Dataset(\"molt\", overwrite=True)\n",
    "\n",
    "# Load the dataset\n",
    "image_paths = [os.path.join(molt_image_path, image) for image in os.listdir(molt_image_path) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "prediction_paths_text = [os.path.join(molt_prediction, txt) for txt in os.listdir(molt_prediction) if txt.endswith('.txt')]\n",
    "\n",
    "# Process images\n",
    "\n",
    "process_images(image_paths, molt_prediction, dataset)\n",
    "\n",
    "# Process segmentations\n",
    "for sample in dataset:\n",
    "    for segmentation in sample[\"segmentations\"]['polylines']:\n",
    "        \n",
    "        process_detection_by_circle(segmentation)\n",
    "\n",
    "# Launch FiftyOne session\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
