{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEC import Circle, Point, welzl\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def calculate_minimum_enclosing_circle(points):\n",
    "    \"\"\"\n",
    "    Calculate the minimum enclosing circle for a set of points using Welzl's algorithm.\n",
    "    Returns the center and radius of the circle.\n",
    "    \"\"\"\n",
    "    mec = welzl(points)  \n",
    "    center=[]\n",
    "    center.append(mec.C.X)\n",
    "    center.append(mec.C.Y)\n",
    "    return center, mec.R\n",
    "\n",
    "def _rotation_matrix(theta):\n",
    "    \"\"\"Creates a 2D rotation matrix for a given angle in radians.\"\"\"\n",
    "    return np.array([\n",
    "        [math.cos(theta), -math.sin(theta)],\n",
    "        [math.sin(theta), math.cos(theta)]\n",
    "    ])\n",
    "\n",
    "def from_rotated_box(xc, yc, w, h, theta, frame_size=None):\n",
    "    \"\"\"\n",
    "    Constructs a rotated bounding box from its center, dimensions, and rotation.\n",
    "\n",
    "    Args:\n",
    "        xc (float): x-center coordinate\n",
    "        yc (float): y-center coordinate\n",
    "        w (float): box width\n",
    "        h (float): box height\n",
    "        theta (float): rotation angle in radians\n",
    "        frame_size (tuple or None): (width, height) of the frame. If provided, points are normalized.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Normalized (x, y) coordinates of the rotated bounding box corners\n",
    "    \"\"\"\n",
    "    # Define the rotation matrix\n",
    "    R = _rotation_matrix(theta)\n",
    "    \n",
    "    # Define the local coordinates of the bounding box corners\n",
    "    local_points = np.array([\n",
    "        [ w / 2,  h / 2],\n",
    "        [-w / 2,  h / 2],\n",
    "        [-w / 2, -h / 2],\n",
    "        [ w / 2, -h / 2]\n",
    "    ])  # shape (4, 2)\n",
    "    \n",
    "    # Apply rotation\n",
    "    rotated_points = R.dot(local_points.T).T  # shape (4, 2)\n",
    "    \n",
    "    # Apply translation to the center\n",
    "    rotated_translated_points = rotated_points + np.array([xc, yc])  # shape (4,2)\n",
    "    \n",
    "    # If frame_size is provided, normalize the points\n",
    "    if frame_size is not None:\n",
    "        rotated_translated_points = rotated_translated_points / np.array(frame_size)\n",
    "    \n",
    "    # Convert to list of tuples\n",
    "    normalized_points = rotated_translated_points.tolist()\n",
    "    \n",
    "    return normalized_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calculate_euclidean_distance, calculate_real_width\n",
    "from skeletonization import skeletonize_mask,create_filled_binary_mask, skeletonize_mask, find_longest_path\n",
    "import cv2\n",
    "import fiftyone as fo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_segmentations(segmentation_path):\n",
    "    \"\"\"\n",
    "    Process the segmentations from the TXT file, calculate the minimum enclosing circle for each prawn.\n",
    "    \"\"\"\n",
    "    segmentations = []\n",
    "    skeletons=[]\n",
    "    hulls=[]\n",
    "    skeletons_straight=[]\n",
    "    skeletons_straight_2=[]\n",
    "    seg_closeds=[]\n",
    "    skeletons_2=[]\n",
    "    box_diagonal=[] \n",
    "    boxes=[]\n",
    "    masks=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Open the segmentation file and process each line\n",
    "    with open(segmentation_path, 'r') as file:\n",
    "        for line in file:\n",
    "            coords = list(map(float, line.strip().split()))\n",
    "            binary_mask = create_filled_binary_mask(coords, 640, 640)\n",
    "            \n",
    "            \n",
    "            binary_mask_no= create_filled_binary_mask(coords, 640, 640,gaussian_blur=False) \n",
    "\n",
    "            binary_dilated = cv2.dilate(binary_mask_no, np.ones((15, 15), np.uint8), iterations=1)     \n",
    "\n",
    "\n",
    "            #contour dilated\n",
    "            contures_dil, _ = cv2.findContours(binary_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "\n",
    "            prawn_conture_dil = max(contures_dil, key=cv2.contourArea)\n",
    "\n",
    "            coords_contour_dil = np.column_stack(prawn_conture_dil).flatten()\n",
    "\n",
    "            normalized_coords_bin=[(coords_contour_dil[i]/640, coords_contour_dil[i+1]/640) for i in range(0, len(coords_contour_dil), 2)]  # Extract points (x, y)\n",
    "            # coords_bin = np.column_stack(np.nonzero(binary_dilated)).flatten()\n",
    "\n",
    "            # normalized_coords_bin=[(coords_bin[i+1]/640, coords_bin[i]/640) for i in range(0, len(coords_bin), 2)]  # Extract points (x, y)\n",
    "\n",
    "\n",
    "\n",
    "            masks.append(fo.Polyline(\n",
    "                points=[normalized_coords_bin],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "            ))\n",
    "\n",
    "\n",
    "\n",
    "            # #convert binary mask to normalized coordinates\n",
    "            # binary_mask_smooth = binary_mask.astype(np.uint8)\n",
    "            # #x,y coordinates of the mask\n",
    "            # coords_bin = np.column_stack(np.nonzero(binary_mask_smooth)).flatten()\n",
    "\n",
    "            # normalized_coords_bin=[(coords_bin[i+1]/640, coords_bin[i]/640) for i in range(0, len(coords_bin), 2)]  # Extract points (x, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            # #thin the mask\n",
    "            # thinned=skeletonize_mask(binary_mask)\n",
    "\n",
    "            # # skeleton = skeletonize_mask(binary_mask)\n",
    "            # skeleton = thinned\n",
    "            # skeleton_coords = np.column_stack(np.nonzero(skeleton))\n",
    "            # normalized_coords,max_length = find_longest_path(skeleton_coords,(640,640),(2988,5312))\n",
    "\n",
    "            # normalized_coords = [(x, y) for y, x in normalized_coords]  # Convert to (y, x) format\n",
    "\n",
    "            # #only the first and last points of the skeleton\n",
    "            # normalized_coords_straight = [normalized_coords[0], normalized_coords[-1]]  \n",
    "\n",
    "            \n",
    "            thinned_2=skeletonize_mask(binary_mask_no)\n",
    "\n",
    "            # skeleton = skeletonize_mask(binary_mask)\n",
    "            skeleton_2 = thinned_2\n",
    "            skeleton_coords_2 = np.column_stack(np.nonzero(skeleton_2))\n",
    "            normalized_coords_2,max_length_2 = find_longest_path(skeleton_coords_2,(640,640),(2988,5312))\n",
    "\n",
    "            normalized_coords_2 = [(x, y) for y, x in normalized_coords_2]  # Convert to (y, x) format\n",
    "\n",
    "            #only the first and last points of the skeleton\n",
    "            normalized_coords_straight_2 = [normalized_coords_2[0], normalized_coords_2[-1]]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #convex hull diameter\n",
    "            contures, _ = cv2.findContours(binary_mask_no, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            \n",
    "            prawn_conture = max(contures, key=cv2.contourArea)  \n",
    "\n",
    "            # Compute the minimum area rectangle enclosing the shrimp\n",
    "            rect = cv2.minAreaRect(prawn_conture)\n",
    "\n",
    "            (xc, yc), (w, h), theta = rect\n",
    "\n",
    "# # Convert theta from degrees to radians for FiftyOne\n",
    "#             theta_radians = np.deg2rad(theta)\n",
    "\n",
    "            original_size = (640, 640)\n",
    "            # normalized_polyline = create_rotated_polyline_normalized(xc, yc, w, h, theta_radians, original_size)\n",
    "\n",
    "\n",
    "            box_points = cv2.boxPoints(rect)\n",
    "            box_points = np.int0(box_points)\n",
    "\n",
    "            new_size = (5312, 2988)\n",
    "\n",
    "            # Scaling factors\n",
    "            scale_x = new_size[0] / original_size[0]  # 5312 / 640\n",
    "            scale_y = new_size[1] / original_size[1]  # 2988 / 640\n",
    "\n",
    "            scale_x = new_size[0] / original_size[0]  # 5312 / 640 = 8.3\n",
    "            scale_y = new_size[1] / original_size[1]  # 2988 / 640 â‰ˆ 4.66875\n",
    "\n",
    "            # Scale the center coordinates and dimensions\n",
    "            scaled_xc = xc * scale_x\n",
    "            scaled_yc = yc * scale_y\n",
    "            scaled_w = w * scale_x\n",
    "            scaled_h = h * scale_y\n",
    "\n",
    "            # Calculate the rotated bounding box points\n",
    "            theta_radians = np.deg2rad(theta)\n",
    "\n",
    "\n",
    "            uniform_scale = min(scale_x, scale_y)\n",
    "            scaled_w = w * uniform_scale\n",
    "            scaled_h = h * uniform_scale\n",
    "            scaled_xc = xc * uniform_scale\n",
    "            scaled_yc = yc * uniform_scale\n",
    "\n",
    "            # Generate normalized bounding box points\n",
    "            points = from_rotated_box(\n",
    "                scaled_xc, scaled_yc, scaled_w, scaled_h, theta_radians, frame_size=new_size\n",
    "            )\n",
    "\n",
    "            # points=from_rotated_box (scaled_xc, scaled_yc, scaled_w, scaled_h, theta_radians, frame_size=(5312, 2988))\n",
    "\n",
    "\n",
    "\n",
    "            box_points_scaled = np.array([(point[0] * scale_x, point[1] * scale_y) for point in box_points])\n",
    "\n",
    "            width= calculate_euclidean_distance(box_points_scaled[0], box_points_scaled[1])\n",
    "            height= calculate_euclidean_distance(box_points_scaled[1], box_points_scaled[2])\n",
    "\n",
    "            max_length_box=max(width,height)\n",
    "\n",
    "            # print(f\"Original Center: ({xc}, {yc})\")\n",
    "            # print(f\"Scaled Center: ({scaled_xc}, {scaled_yc})\")\n",
    "            # print(f\"Original Dimensions: (w={w}, h={h})\")\n",
    "            # print(f\"Scaled Dimensions: (w={scaled_w}, h={scaled_h})\")\n",
    "            # print(f\"Rotation Angle (radians): {theta_radians}\")\n",
    "            # print(f\"Normalized Bounding Box Points: {points}\")\n",
    "            # print(f\"Max Length Box (pixels): {max_length_box}\")\n",
    "                    \n",
    "\n",
    "            # normalized_bounding_box = [\n",
    "            #         (x / new_size[0], y / new_size[1]) for x, y in box_points_scaled]            \n",
    "            # Extract points (x, y) \n",
    "            box=fo.Polyline(\n",
    "                points=[points],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "                max_length=max_length_box\n",
    "            )\n",
    "            # box=fo.Polyline.from_rotated_box(\n",
    "\n",
    "            #     xc=xc/640,\n",
    "            #     yc=yc/640,\n",
    "            \n",
    "            #     w=w*scale_x,\n",
    "            #     h=h*scale_y,\n",
    "            #     theta =theta_radians,\n",
    "            \n",
    "\n",
    "            # )\n",
    "\n",
    "            boxes.append(box)\n",
    "\n",
    "\n",
    "            hull_points = cv2.convexHull(prawn_conture, returnPoints=True)\n",
    "\n",
    "\n",
    "            \n",
    "# Scaling factors to convert from 640x640 to 5312x2988\n",
    "            scale_x = 5312 / 640\n",
    "            scale_y = 2988 / 640\n",
    "\n",
    "        # Scale the points to the new resolution\n",
    "            scaled_hull_points = []\n",
    "            for point in hull_points:\n",
    "                x, y = point[0]\n",
    "                scaled_x = x * scale_x\n",
    "                scaled_y = y * scale_y\n",
    "                scaled_hull_points.append([scaled_x, scaled_y])\n",
    "\n",
    "            # Convert to numpy array for easier handling\n",
    "            scaled_hull_points = np.array(scaled_hull_points, dtype=np.float32)\n",
    "\n",
    "            # Now, find the maximum Euclidean distance (convex hull diameter) using the scaled points\n",
    "            max_distance = 0\n",
    "            point1 = None\n",
    "            point2 = None\n",
    "\n",
    "            # Loop through all pairs of scaled points to find the maximum distance\n",
    "            for i in range(len(scaled_hull_points)):\n",
    "                for j in range(i + 1, len(scaled_hull_points)):\n",
    "                    distance = calculate_euclidean_distance(scaled_hull_points[i], scaled_hull_points[j])\n",
    "                    if distance > max_distance:\n",
    "                        max_distance = distance\n",
    "                        point1 = scaled_hull_points[i]\n",
    "                        point2 = scaled_hull_points[j]\n",
    "\n",
    "            # The result is max_distance (in pixels) in the 5312x2988 image\n",
    "\n",
    "\n",
    "            normalzied_points_hull = [(point1[0]/5312, point1[1]/2988), (point2[0]/5312, point2[1]/2988)]  # Extract points (x, y)\n",
    "\n",
    "            hull=fo.Polyline(\n",
    "                points=[normalzied_points_hull],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_distance\n",
    "            )\n",
    "\n",
    "            # skeleton_straight=fo.Polyline(\n",
    "            #     points=[normalized_coords_straight],\n",
    "            #     closed=False,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "            # skeletons_straight.append(skeleton_straight)\n",
    "\n",
    "            skeleton_straight_2=fo.Polyline(\n",
    "                points=[normalized_coords_straight_2],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_length_2,\n",
    "                \n",
    "            )\n",
    "            skeletons_straight_2.append(skeleton_straight_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            hulls.append(hull)\n",
    "\n",
    "            # skeleton=fo.Polyline(\n",
    "            #     points=[normalized_coords],\n",
    "            #     closed=False,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "\n",
    "            # skeletons.append(skeleton)\n",
    "            \n",
    "            skeleton_2=fo.Polyline( \n",
    "                points=[normalized_coords_2],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_length_2)\n",
    "            skeletons_2.append(skeleton_2)\n",
    "              # Convert the line to a list of floats\n",
    "            normalzied_points = [(coords[i]/640, coords[i + 1]/640) for i in range(0, len(coords), 2)]  # Extract points (x, y)\n",
    "            points = [Point(x*5312, y*2988) for x, y in normalzied_points] \n",
    "            \n",
    "\n",
    "            \n",
    "             # Convert to Point objects    \n",
    "            # Calculate the minimum enclosing circle (center and radius)\n",
    "            center, radius = calculate_minimum_enclosing_circle(points)\n",
    "            diameter = radius * 2\n",
    "\n",
    "            segmentation = fo.Polyline(\n",
    "                points=[normalzied_points],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "                diameter=diameter,\n",
    "                center=center,\n",
    "                max_length_skeleton=max_length_2,\n",
    "                max_length_hull=max_distance,\n",
    "                max_length_box=max_length_box\n",
    "            )\n",
    "\n",
    "            #smooth segmentation  wirh closing\n",
    "            # seg_closed=fo.Polyline(\n",
    "            #     points=[normalized_coords_bin],\n",
    "            #     closed=True,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "\n",
    "            # seg_closeds.append(seg_closed)                \n",
    "\n",
    "\n",
    "            segmentations.append(segmentation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                     # Store the segmentation information (center, radius, and diameter)\n",
    "\n",
    "    return segmentations,skeletons,hulls, skeletons_straight,seg_closeds,skeletons_2,skeletons_straight_2,boxes,masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calculate_euclidean_distance, calculate_real_width\n",
    "from skeletonization import skeletonize_mask,create_filled_binary_mask, skeletonize_mask, find_longest_path\n",
    "import cv2\n",
    "import fiftyone as fo\n",
    "import numpy as np\n",
    "\n",
    "def process_segmentations(segmentation_path):\n",
    "    \"\"\"\n",
    "    Process the segmentations from the TXT file, calculate the minimum enclosing circle for each prawn.\n",
    "    \"\"\"\n",
    "    segmentations = []\n",
    "    skeletons=[]\n",
    "    hulls=[]\n",
    "    skeletons_straight=[]\n",
    "    skeletons_straight_2=[]\n",
    "    seg_closeds=[]\n",
    "    skeletons_2=[]\n",
    "    box_diagonal=[] \n",
    "    boxes=[]\n",
    "    masks=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Open the segmentation file and process each line\n",
    "    with open(segmentation_path, 'r') as file:\n",
    "        for line in file:\n",
    "            coords = list(map(float, line.strip().split()))\n",
    "            binary_mask = create_filled_binary_mask(coords, 640, 640)\n",
    "            \n",
    "            \n",
    "            binary_mask_no= create_filled_binary_mask(coords, 640, 640,gaussian_blur=False) \n",
    "\n",
    "            binary_dilated = cv2.dilate(binary_mask_no, np.ones((15, 15), np.uint8), iterations=1)     \n",
    "\n",
    "\n",
    "            #contour dilated\n",
    "            contures_dil, _ = cv2.findContours(binary_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "\n",
    "            prawn_conture_dil = max(contures_dil, key=cv2.contourArea)\n",
    "\n",
    "            coords_contour_dil = np.column_stack(prawn_conture_dil).flatten()\n",
    "\n",
    "            normalized_coords_bin=[(coords_contour_dil[i]/640, coords_contour_dil[i+1]/640) for i in range(0, len(coords_contour_dil), 2)]  # Extract points (x, y)\n",
    "            # coords_bin = np.column_stack(np.nonzero(binary_dilated)).flatten()\n",
    "\n",
    "            # normalized_coords_bin=[(coords_bin[i+1]/640, coords_bin[i]/640) for i in range(0, len(coords_bin), 2)]  # Extract points (x, y)\n",
    "\n",
    "\n",
    "\n",
    "            masks.append(fo.Polyline(\n",
    "                points=[normalized_coords_bin],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "            ))\n",
    "\n",
    "\n",
    "\n",
    "            # #convert binary mask to normalized coordinates\n",
    "            # binary_mask_smooth = binary_mask.astype(np.uint8)\n",
    "            # #x,y coordinates of the mask\n",
    "            # coords_bin = np.column_stack(np.nonzero(binary_mask_smooth)).flatten()\n",
    "\n",
    "            # normalized_coords_bin=[(coords_bin[i+1]/640, coords_bin[i]/640) for i in range(0, len(coords_bin), 2)]  # Extract points (x, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            # #thin the mask\n",
    "            # thinned=skeletonize_mask(binary_mask)\n",
    "\n",
    "            # # skeleton = skeletonize_mask(binary_mask)\n",
    "            # skeleton = thinned\n",
    "            # skeleton_coords = np.column_stack(np.nonzero(skeleton))\n",
    "            # normalized_coords,max_length = find_longest_path(skeleton_coords,(640,640),(2988,5312))\n",
    "\n",
    "            # normalized_coords = [(x, y) for y, x in normalized_coords]  # Convert to (y, x) format\n",
    "\n",
    "            # #only the first and last points of the skeleton\n",
    "            # normalized_coords_straight = [normalized_coords[0], normalized_coords[-1]]  \n",
    "\n",
    "            \n",
    "            thinned_2=skeletonize_mask(binary_mask_no)\n",
    "\n",
    "            # skeleton = skeletonize_mask(binary_mask)\n",
    "            skeleton_2 = thinned_2\n",
    "            skeleton_coords_2 = np.column_stack(np.nonzero(skeleton_2))\n",
    "            normalized_coords_2,max_length_2 = find_longest_path(skeleton_coords_2,(640,640),(2988,5312))\n",
    "\n",
    "            normalized_coords_2 = [(x, y) for y, x in normalized_coords_2]  # Convert to (y, x) format\n",
    "\n",
    "            #only the first and last points of the skeleton\n",
    "            normalized_coords_straight_2 = [normalized_coords_2[0], normalized_coords_2[-1]]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #convex hull diameter\n",
    "            contures, _ = cv2.findContours(binary_mask_no, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            \n",
    "            prawn_conture = max(contures, key=cv2.contourArea)  \n",
    "\n",
    "            # Compute the minimum area rectangle enclosing the shrimp\n",
    "            rect = cv2.minAreaRect(prawn_conture)\n",
    "            box_points = cv2.boxPoints(rect)\n",
    "            box_points = np.int0(box_points)\n",
    "\n",
    "            original_size = (640, 640)\n",
    "            new_size = (5312, 2988)\n",
    "\n",
    "            # Scaling factors\n",
    "            scale_x = new_size[0] / original_size[0]  # 5312 / 640\n",
    "            scale_y = new_size[1] / original_size[1]  # 2988 / 640\n",
    "\n",
    "            box_points_scaled = np.array([(point[0] * scale_x, point[1] * scale_y) for point in box_points])\n",
    "\n",
    "            width= calculate_euclidean_distance(box_points_scaled[0], box_points_scaled[1])\n",
    "            height= calculate_euclidean_distance(box_points_scaled[1], box_points_scaled[2])\n",
    "\n",
    "            max_length_box=max(width,height)\n",
    "\n",
    "\n",
    "           \n",
    "            # Convert theta from degrees to radians for FiftyOne\n",
    "            theta_radians = np.deg2rad(rect[2])\n",
    "            # normalized_bounding_box = [(box_points[i][0]/640, box_points[i][1]/640) for i in range(0, len(box_points))] \n",
    "            \n",
    "            image_center_x = 640 / 2\n",
    "\n",
    "            xc_adjusted = rect[0][0] - image_center_x\n",
    "\n",
    "            # Extract points (x, y) \n",
    "            box=fo.Polyline.from_rotated_box(\n",
    "                xc=rect[0][0] ,\n",
    "                yc=rect[0][1],\n",
    "                w=rect[1][0],\n",
    "                h=rect[1][1],\n",
    "                theta =theta_radians,\n",
    "                frame_size=(640, 640)\n",
    "\n",
    "            )\n",
    "\n",
    "\n",
    "            boxes.append(box)\n",
    "\n",
    "\n",
    "            hull_points = cv2.convexHull(prawn_conture, returnPoints=True)\n",
    "\n",
    "\n",
    "            \n",
    "# Scaling factors to convert from 640x640 to 5312x2988\n",
    "            scale_x = 5312 / 640\n",
    "            scale_y = 2988 / 640\n",
    "\n",
    "        # Scale the points to the new resolution\n",
    "            scaled_hull_points = []\n",
    "            for point in hull_points:\n",
    "                x, y = point[0]\n",
    "                scaled_x = x * scale_x\n",
    "                scaled_y = y * scale_y\n",
    "                scaled_hull_points.append([scaled_x, scaled_y])\n",
    "\n",
    "            # Convert to numpy array for easier handling\n",
    "            scaled_hull_points = np.array(scaled_hull_points, dtype=np.float32)\n",
    "\n",
    "            # Now, find the maximum Euclidean distance (convex hull diameter) using the scaled points\n",
    "            max_distance = 0\n",
    "            point1 = None\n",
    "            point2 = None\n",
    "\n",
    "            # Loop through all pairs of scaled points to find the maximum distance\n",
    "            for i in range(len(scaled_hull_points)):\n",
    "                for j in range(i + 1, len(scaled_hull_points)):\n",
    "                    distance = calculate_euclidean_distance(scaled_hull_points[i], scaled_hull_points[j])\n",
    "                    if distance > max_distance:\n",
    "                        max_distance = distance\n",
    "                        point1 = scaled_hull_points[i]\n",
    "                        point2 = scaled_hull_points[j]\n",
    "\n",
    "            # The result is max_distance (in pixels) in the 5312x2988 image\n",
    "\n",
    "\n",
    "            normalzied_points_hull = [(point1[0]/5312, point1[1]/2988), (point2[0]/5312, point2[1]/2988)]  # Extract points (x, y)\n",
    "\n",
    "            hull=fo.Polyline(\n",
    "                points=[normalzied_points_hull],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_distance\n",
    "            )\n",
    "\n",
    "            # skeleton_straight=fo.Polyline(\n",
    "            #     points=[normalized_coords_straight],\n",
    "            #     closed=False,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "            # skeletons_straight.append(skeleton_straight)\n",
    "\n",
    "            skeleton_straight_2=fo.Polyline(\n",
    "                points=[normalized_coords_straight_2],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_length_2,\n",
    "                \n",
    "            )\n",
    "            skeletons_straight_2.append(skeleton_straight_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            hulls.append(hull)\n",
    "\n",
    "            # skeleton=fo.Polyline(\n",
    "            #     points=[normalized_coords],\n",
    "            #     closed=False,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "\n",
    "            # skeletons.append(skeleton)\n",
    "            \n",
    "            skeleton_2=fo.Polyline( \n",
    "                points=[normalized_coords_2],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_length_2)\n",
    "            skeletons_2.append(skeleton_2)\n",
    "              # Convert the line to a list of floats\n",
    "            normalzied_points = [(coords[i]/640, coords[i + 1]/640) for i in range(0, len(coords), 2)]  # Extract points (x, y)\n",
    "            points = [Point(x*5312, y*2988) for x, y in normalzied_points] \n",
    "            \n",
    "\n",
    "            \n",
    "             # Convert to Point objects    \n",
    "            # Calculate the minimum enclosing circle (center and radius)\n",
    "            center, radius = calculate_minimum_enclosing_circle(points)\n",
    "            diameter = radius * 2\n",
    "\n",
    "            segmentation = fo.Polyline(\n",
    "                points=[normalzied_points],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "                diameter=diameter,\n",
    "                center=center,\n",
    "                max_length_skeleton=max_length_2,\n",
    "                max_length_hull=max_distance,\n",
    "                max_length_box=max_length_box\n",
    "            )\n",
    "\n",
    "            #smooth segmentation  wirh closing\n",
    "            # seg_closed=fo.Polyline(\n",
    "            #     points=[normalized_coords_bin],\n",
    "            #     closed=True,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "\n",
    "            # seg_closeds.append(seg_closed)                \n",
    "\n",
    "\n",
    "            segmentations.append(segmentation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                     # Store the segmentation information (center, radius, and diameter)\n",
    "\n",
    "    return segmentations,skeletons,hulls, skeletons_straight,seg_closeds,skeletons_2,skeletons_straight_2,boxes,masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.core.labels as fol\n",
    "from tqdm import tqdm\n",
    "import fiftyone as fo\n",
    "import os\n",
    "\n",
    "def process_images(image_paths, prediction_folder_path, dataset):\n",
    "    print(\"Processing images...\")\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes images by matching segmentation with bounding boxes and calculating prawn sizes.\n",
    "    \"\"\"\n",
    "    for image_path in tqdm(image_paths):\n",
    "        # filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        \n",
    "\n",
    "           \n",
    "        # prediction_txt_path = os.path.join(prediction_folder_path, f\"{os.path.basename(image_path).split('.')[0]}_segmentations.txt\")\n",
    "\n",
    "        core_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "        # Construct the path to the corresponding segmentation file\n",
    "        prediction_txt_path = os.path.join(prediction_folder_path, f\"{core_name}_segmentations.txt\")\n",
    "\n",
    "        # core_name=filename.split('.')[0]\n",
    "        # # Construct the path to the prediction (segmentation) file\n",
    "        # prediction_txt_path = os.path.join(prediction_folder_path, f\"{core_name}_segmentations.txt\")\n",
    "        # if not os.path.exists(prediction_txt_path):\n",
    "        #     print(f\"No segmentation file found for {filename}\")\n",
    "        #     continue\n",
    "\n",
    "\n",
    "        # Parse the segmentations to get the minimum enclosing circles\n",
    "        segmentations,skeletons,hulls,skeletons_straight,seg_closeds,skeletons_2,skeletons_straight_2,boxes,masks = process_segmentations(prediction_txt_path)\n",
    "\n",
    "        # Save the modified image (with circles drawn)\n",
    "\n",
    "        # Create a new sample for FiftyOne\n",
    "        sample = fo.Sample(filepath=image_path)\n",
    "\n",
    "        # Iterate over each bounding box in the filtered data\n",
    "        sample[\"segmentations\"] = fol.Polylines(polylines=segmentations)\n",
    "\n",
    "        # sample[\"skeletons\"] = fol.Polylines(polylines=skeletons)\n",
    "\n",
    "        sample[\"hulls\"] = fol.Polylines(polylines=hulls)    \n",
    "\n",
    "        # sample[\"skeletons_straight\"] = fol.Polylines(polylines=skeletons_straight)\n",
    "\n",
    "        # sample['seg_closeds']=fol.Polylines(polylines=seg_closeds)\n",
    "        \n",
    "        sample['skeletons_no_smooth']=fol.Polylines(polylines=skeletons_2)\n",
    "\n",
    "        sample[\"skeletons_straight_no_smooth\"] = fol.Polylines(polylines=skeletons_straight_2)\n",
    "\n",
    "        sample['boxes']=fol.Polylines(polylines=boxes)\n",
    "\n",
    "        sample['masks']=fol.Polylines(polylines=masks)\n",
    "        # Add the processed sample to the FiftyOne dataset\n",
    "        dataset.add_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def process_detection_by_circle(segmentation):\n",
    "    \"\"\"\n",
    "    Process the prawn detection based on the enclosing circle's diameter.\n",
    "    Update the filtered dataframe with the real-world size of the prawn.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fetch height in mm and other metadata\n",
    "    height_mm =500-30\n",
    "    #focal length based on pond type\n",
    "    \n",
    "    focal_length = 24.72\n",
    "\n",
    "\n",
    "    # focal_length = 24.22  # Camera focal length\n",
    "    pixel_size = 0.00716844  # Pixel size in mm\n",
    "\n",
    "    poly=segmentation\n",
    "\n",
    "    fov=75\n",
    "    FOV_width=2*height_mm*math.tan(math.radians(fov/2))\n",
    "\n",
    "\n",
    "    # Get the diameter of the circle in pixels\n",
    "    predicted_diameter_pixels = poly['diameter']\n",
    "\n",
    "\n",
    "    predicted_skeleton_length=poly['max_length_skeleton']  \n",
    "\n",
    "    predicted_hull_length=poly['max_length_hull']\n",
    "\n",
    "     \n",
    "    predicted_box_length=poly['max_length_box']\n",
    "\n",
    "    # Calculate the real-world prawn size using the box\n",
    "    real_length_mm_box = calculate_real_width(focal_length, height_mm, predicted_box_length, pixel_size) \n",
    "\n",
    "\n",
    "    hull_length_cm = calculate_real_width(focal_length, height_mm, predicted_hull_length, pixel_size)    \n",
    "\n",
    "    # Calculate the real-world prawn size using the enclosing circle's diameter\n",
    "    real_length_cm = calculate_real_width(focal_length, height_mm, predicted_diameter_pixels, pixel_size)\n",
    "\n",
    "    ske_length_cm = calculate_real_width(focal_length, height_mm, predicted_skeleton_length, pixel_size)    \n",
    "\n",
    "\n",
    "    hull_length_fov=FOV_width*predicted_hull_length/5312\n",
    "    diameter_length_fov=FOV_width*predicted_diameter_pixels/5312\n",
    "    skeleton_length_fov=FOV_width*predicted_skeleton_length/5312\n",
    "\n",
    "    box_length_fov=FOV_width*predicted_box_length/5312\n",
    "\n",
    "    true_length=143\n",
    "    error_percentage_MEC_fov = abs(diameter_length_fov - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_hull_fov = abs(hull_length_fov - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_skeleton_fov = abs(skeleton_length_fov - true_length) / true_length * 100  \n",
    "\n",
    "    error_percentage = abs(real_length_cm - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_skeleton = abs(ske_length_cm - true_length) / true_length * 100    \n",
    "\n",
    "    error_percentage_hull = abs(hull_length_cm - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_box_fov = abs(box_length_fov - true_length) / true_length * 100\n",
    "\n",
    "    closest_detection_label = f'true length: {true_length:.2f}mm, MPError_hull: {error_percentage_hull_fov:.2f}%, , pred length: {hull_length_fov:.2f}mm ,error percentage skeleton: {error_percentage_skeleton_fov:.2f}%, , pred length: {skeleton_length_fov:.2f}cm, error percentage box: {error_percentage_box_fov:.2f}%, pred length: {box_length_fov:.2f}mm, '\n",
    "    # Update the filtered dataframe with the real-world size of the prawn\n",
    "\n",
    "    poly.label = closest_detection_label \n",
    "    return poly\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\gbo10\\AppData\\Local\\Temp\\ipykernel_39168\\370280592.py:113: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box_points = np.int0(box_points)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Client is not connected",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m         sample\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Launch FiftyOne session\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[43mfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\session\\session.py:196\u001b[0m, in \u001b[0;36mlaunch_app\u001b[1;34m(dataset, view, spaces, color_scheme, plots, port, address, remote, desktop, browser, height, auto, config)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Launches the FiftyOne App.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mNote that only one App instance can be opened at a time. If this method is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m    a :class:`Session`\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _session  \u001b[38;5;66;03m# pylint: disable=global-statement\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m _session \u001b[38;5;241m=\u001b[39m \u001b[43mSession\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mview\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_scheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_scheme\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesktop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesktop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbrowser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _session\u001b[38;5;241m.\u001b[39mremote:\n\u001b[0;32m    213\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(_REMOTE_INSTRUCTIONS\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mformat(_session\u001b[38;5;241m.\u001b[39mserver_port))\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\session\\session.py:435\u001b[0m, in \u001b[0;36mSession.__init__\u001b[1;34m(self, dataset, view, view_name, spaces, color_scheme, plots, port, address, remote, desktop, browser, height, auto, config)\u001b[0m\n\u001b[0;32m    432\u001b[0m _register_session(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto \u001b[38;5;129;01mand\u001b[39;00m focx\u001b[38;5;241m.\u001b[39mis_notebook_context():\n\u001b[1;32m--> 435\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotebook_height\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbrowser \u001b[38;5;241m=\u001b[39m browser\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremote:\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\session\\session.py:256\u001b[0m, in \u001b[0;36mupdate_state.<locals>.decorator.<locals>.wrapper\u001b[1;34m(session, *args, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_show \u001b[38;5;129;01mand\u001b[39;00m session\u001b[38;5;241m.\u001b[39mauto \u001b[38;5;129;01mand\u001b[39;00m focx\u001b[38;5;241m.\u001b[39mis_notebook_context():\n\u001b[0;32m    255\u001b[0m     session\u001b[38;5;241m.\u001b[39mfreeze()\n\u001b[1;32m--> 256\u001b[0m result \u001b[38;5;241m=\u001b[39m func(session, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    257\u001b[0m session\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend_event(StateUpdate(state\u001b[38;5;241m=\u001b[39msession\u001b[38;5;241m.\u001b[39m_state))\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_show \u001b[38;5;129;01mand\u001b[39;00m session\u001b[38;5;241m.\u001b[39mauto \u001b[38;5;129;01mand\u001b[39;00m focx\u001b[38;5;241m.\u001b[39mis_notebook_context():\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\session\\session.py:1043\u001b[0m, in \u001b[0;36mSession.show\u001b[1;34m(self, height)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m focx\u001b[38;5;241m.\u001b[39mis_notebook_context() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesktop:\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m_reload()\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\session\\session.py:1144\u001b[0m, in \u001b[0;36mSession.freeze\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1141\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly notebook sessions can be frozen\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1144\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDeactivateNotebookCell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplots\u001b[38;5;241m.\u001b[39mfreeze()\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\session\\client.py:152\u001b[0m, in \u001b[0;36mClient.send_event\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient is not connected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_event(event)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_event(event)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Client is not connected"
     ]
    }
   ],
   "source": [
    "molt_image_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\molt-19-9\\unditorted_resized\"\n",
    "molt_prediction=r'C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\molt-19-9\\unditorted_resized'\n",
    "\n",
    "import fiftyone as fo\n",
    "dataset = fo.Dataset(\"molt\", overwrite=True)\n",
    "\n",
    "# Load the dataset\n",
    "image_paths = [os.path.join(molt_image_path, image) for image in os.listdir(molt_image_path) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "prediction_paths_text = [os.path.join(molt_prediction, txt) for txt in os.listdir(molt_prediction) if txt.endswith('.txt')]\n",
    "\n",
    "# Process images\n",
    "\n",
    "process_images(image_paths, molt_prediction, dataset)\n",
    "\n",
    "# Process segmentations\n",
    "for sample in dataset:\n",
    "    # Access the polylines for each sample\n",
    "    for i, segmentation in enumerate(sample[\"segmentations\"].polylines):\n",
    "        # Process and modify the segmentation\n",
    "        updated_segmentation = process_detection_by_circle(segmentation)\n",
    "\n",
    "        # Save the updated segmentation back into the sample\n",
    "        sample[\"segmentations\"].polylines[i] = updated_segmentation\n",
    "\n",
    "        sample.save()\n",
    "# Launch FiftyOne session\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(r\"C:\\Users\\gbo10\\OneDrive\\research\\06.05.2024\\vlcsnap-2024-09-20-23h55m42s785.png\")\n",
    "\n",
    "# Step 1: Convert to grayscale\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "white_mask=cv2.inRange(image, (100, 100, 100), (255, 255, 255))\n",
    "\n",
    "cv2.imwrite(\"white_mask.png\", white_mask)    \n",
    "\n",
    "\n",
    "\n",
    "very_white_mask = cv2.inRange(image, (150, 150, 150), (255, 255, 255))\n",
    "\n",
    "\n",
    "image[very_white_mask == 255] = [0, 0, 0]  # Change white to gray\n",
    "\n",
    "\n",
    "cv2.imwrite(\"very_white_mask.png\", image)\n",
    "\n",
    "\n",
    "gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "_, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Save the result\n",
    "cv2.imwrite(\"binary_image.png\", binary)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"gray.png\", gray)\n",
    "\n",
    "\n",
    "white_mask_from_binary = cv2.bitwise_not(binary)  # Invert the binary mask to get white areas\n",
    "\n",
    "cv2.imwrite(\"white_mask_from_binary.png\", white_mask_from_binary)\n",
    "\n",
    "\n",
    "gray_color = np.array([79, 105, 122])  # RGB value for gray\n",
    "# image[white_mask == 255] = gray_color\n",
    "\n",
    "# Step 2: Threshold the image to isolate black areas (under prawns)\n",
    "# Adjust threshold values depending on how black the segments are\n",
    "_, black_mask = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)  # Isolating black areas (threshold of 50)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"black_mask.png\", black_mask)\n",
    "\n",
    "# Step 3: Create a bluish image to apply to black areas\n",
    "bluish_image = image.copy()\n",
    "bluish_image[:] = [212, 156, 31]  # BGR for blue\n",
    "\n",
    "\n",
    "#white mask on the black segments\n",
    "# white_on_black = cv2.bitwise_and(white_mask_from_binary, black_mask)  # Isolate white areas on the black segments\n",
    "\n",
    "# cv2.imwrite(\"white_on_black.png\", white_on_black)\n",
    "\n",
    "\n",
    "# # Step 6: Convert white to gray in those areas\n",
    "# # gray_color = np.array([128, 128, 128])  # RGB value for gray\n",
    "# image[white_on_black==0] = gray_color  # Change white on black to gray\n",
    "\n",
    "\n",
    "image[white_mask == 255] = gray_color\n",
    "\n",
    "# Step 4: Apply bluish color to the black regions\n",
    "image[black_mask == 255] = bluish_image[black_mask == 255]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Isolate white areas (likely prawns) within the black segments\n",
    "# Detect white pixels in the original image (on the black segments only)\n",
    "# white_on_black = cv2.bitwise_and(white_mask, black_mask)  # Isolate white areas on the black segments\n",
    "\n",
    "# Step 6: Convert white to gray in those areas\n",
    "# gray_color = np.array([128, 128, 128])  # RGB value for gray\n",
    "# image[white_on_black == 255] = gray_color  # Change white on black to gray\n",
    "\n",
    "# Step 7: Display the final image\n",
    "# cv2.imshow(\"Result\", image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# Save the result\n",
    "cv2.imwrite(\"processed_image.png\", image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
