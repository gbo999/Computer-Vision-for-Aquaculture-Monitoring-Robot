{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEC import Circle, Point, welzl\n",
    "\n",
    "def calculate_minimum_enclosing_circle(points):\n",
    "    \"\"\"\n",
    "    Calculate the minimum enclosing circle for a set of points using Welzl's algorithm.\n",
    "    Returns the center and radius of the circle.\n",
    "    \"\"\"\n",
    "    mec = welzl(points)  \n",
    "    center=[]\n",
    "    center.append(mec.C.X)\n",
    "    center.append(mec.C.Y)\n",
    "    return center, mec.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calculate_euclidean_distance, calculate_real_width\n",
    "from skeletonization import skeletonize_mask,create_filled_binary_mask, skeletonize_mask, find_longest_path\n",
    "import cv2\n",
    "import fiftyone as fo\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def process_segmentations(segmentation_path):\n",
    "    \"\"\"\n",
    "    Process the segmentations from the TXT file, calculate the minimum enclosing circle for each prawn.\n",
    "    \"\"\"\n",
    "    segmentations = []\n",
    "    skeletons=[]\n",
    "    hulls=[]\n",
    "    skeletons_straight=[]\n",
    "    skeletons_straight_2=[]\n",
    "    seg_closeds=[]\n",
    "    skeletons_2=[]\n",
    "    box_diagonal=[] \n",
    "    boxes=[]\n",
    "    masks=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Open the segmentation file and process each line\n",
    "    with open(segmentation_path, 'r') as file:\n",
    "        for line in file:\n",
    "            coords = list(map(float, line.strip().split()))\n",
    "            binary_mask = create_filled_binary_mask(coords, 640, 640)\n",
    "            \n",
    "            \n",
    "            binary_mask_no= create_filled_binary_mask(coords, 640, 640,gaussian_blur=False) \n",
    "\n",
    "            binary_dilated = cv2.dilate(binary_mask_no, np.ones((15, 15), np.uint8), iterations=1)     \n",
    "\n",
    "\n",
    "            #contour dilated\n",
    "            contures_dil, _ = cv2.findContours(binary_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "\n",
    "            prawn_conture_dil = max(contures_dil, key=cv2.contourArea)\n",
    "\n",
    "            coords_contour_dil = np.column_stack(prawn_conture_dil).flatten()\n",
    "\n",
    "            normalized_coords_bin=[(coords_contour_dil[i]/640, coords_contour_dil[i+1]/640) for i in range(0, len(coords_contour_dil), 2)]  # Extract points (x, y)\n",
    "            # coords_bin = np.column_stack(np.nonzero(binary_dilated)).flatten()\n",
    "\n",
    "            # normalized_coords_bin=[(coords_bin[i+1]/640, coords_bin[i]/640) for i in range(0, len(coords_bin), 2)]  # Extract points (x, y)\n",
    "\n",
    "\n",
    "\n",
    "            masks.append(fo.Polyline(\n",
    "                points=[normalized_coords_bin],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "            ))\n",
    "\n",
    "\n",
    "\n",
    "            # #convert binary mask to normalized coordinates\n",
    "            # binary_mask_smooth = binary_mask.astype(np.uint8)\n",
    "            # #x,y coordinates of the mask\n",
    "            # coords_bin = np.column_stack(np.nonzero(binary_mask_smooth)).flatten()\n",
    "\n",
    "            # normalized_coords_bin=[(coords_bin[i+1]/640, coords_bin[i]/640) for i in range(0, len(coords_bin), 2)]  # Extract points (x, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            # #thin the mask\n",
    "            # thinned=skeletonize_mask(binary_mask)\n",
    "\n",
    "            # # skeleton = skeletonize_mask(binary_mask)\n",
    "            # skeleton = thinned\n",
    "            # skeleton_coords = np.column_stack(np.nonzero(skeleton))\n",
    "            # normalized_coords,max_length = find_longest_path(skeleton_coords,(640,640),(2988,5312))\n",
    "\n",
    "            # normalized_coords = [(x, y) for y, x in normalized_coords]  # Convert to (y, x) format\n",
    "\n",
    "            # #only the first and last points of the skeleton\n",
    "            # normalized_coords_straight = [normalized_coords[0], normalized_coords[-1]]  \n",
    "\n",
    "            \n",
    "            thinned_2=skeletonize_mask(binary_mask_no)\n",
    "\n",
    "            # skeleton = skeletonize_mask(binary_mask)\n",
    "            skeleton_2 = thinned_2\n",
    "            skeleton_coords_2 = np.column_stack(np.nonzero(skeleton_2))\n",
    "            normalized_coords_2,max_length_2 = find_longest_path(skeleton_coords_2,(640,640),(2988,5312))\n",
    "\n",
    "            normalized_coords_2 = [(x, y) for y, x in normalized_coords_2]  # Convert to (y, x) format\n",
    "\n",
    "            #only the first and last points of the skeleton\n",
    "            normalized_coords_straight_2 = [normalized_coords_2[0], normalized_coords_2[-1]]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #convex hull diameter\n",
    "            contures, _ = cv2.findContours(binary_mask_no, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            \n",
    "            prawn_conture = max(contures, key=cv2.contourArea)  \n",
    "\n",
    "            # Compute the minimum area rectangle enclosing the shrimp\n",
    "            rect = cv2.minAreaRect(prawn_conture)\n",
    "            box_points = cv2.boxPoints(rect)\n",
    "            box_points = np.int0(box_points)\n",
    "\n",
    "            original_size = (640, 640)\n",
    "            new_size = (5312, 2988)\n",
    "\n",
    "            # Scaling factors\n",
    "            scale_x = new_size[0] / original_size[0]  # 5312 / 640\n",
    "            scale_y = new_size[1] / original_size[1]  # 2988 / 640\n",
    "\n",
    "            box_points_scaled = np.array([(point[0] * scale_x, point[1] * scale_y) for point in box_points])\n",
    "\n",
    "            width= calculate_euclidean_distance(box_points_scaled[0], box_points_scaled[1])\n",
    "            height= calculate_euclidean_distance(box_points_scaled[1], box_points_scaled[2])\n",
    "\n",
    "            max_length_box=max(width,height)\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "            normalized_bounding_box = [(box_points[i][0]/640, box_points[i][1]/640) for i in range(0, len(box_points))] \n",
    "            \n",
    "            # Extract points (x, y) \n",
    "            box=fo.Polyline(\n",
    "                points=[normalized_bounding_box],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "                max_length=max_length_box\n",
    "            )\n",
    "\n",
    "\n",
    "            boxes.append(box)\n",
    "\n",
    "\n",
    "            hull_points = cv2.convexHull(prawn_conture, returnPoints=True)\n",
    "\n",
    "\n",
    "            \n",
    "# Scaling factors to convert from 640x640 to 5312x2988\n",
    "            scale_x = 5312 / 640\n",
    "            scale_y = 2988 / 640\n",
    "\n",
    "        # Scale the points to the new resolution\n",
    "            scaled_hull_points = []\n",
    "            for point in hull_points:\n",
    "                x, y = point[0]\n",
    "                scaled_x = x * scale_x\n",
    "                scaled_y = y * scale_y\n",
    "                scaled_hull_points.append([scaled_x, scaled_y])\n",
    "\n",
    "            # Convert to numpy array for easier handling\n",
    "            scaled_hull_points = np.array(scaled_hull_points, dtype=np.float32)\n",
    "\n",
    "            # Now, find the maximum Euclidean distance (convex hull diameter) using the scaled points\n",
    "            max_distance = 0\n",
    "            point1 = None\n",
    "            point2 = None\n",
    "\n",
    "            # Loop through all pairs of scaled points to find the maximum distance\n",
    "            for i in range(len(scaled_hull_points)):\n",
    "                for j in range(i + 1, len(scaled_hull_points)):\n",
    "                    distance = calculate_euclidean_distance(scaled_hull_points[i], scaled_hull_points[j])\n",
    "                    if distance > max_distance:\n",
    "                        max_distance = distance\n",
    "                        point1 = scaled_hull_points[i]\n",
    "                        point2 = scaled_hull_points[j]\n",
    "\n",
    "            # The result is max_distance (in pixels) in the 5312x2988 image\n",
    "\n",
    "\n",
    "            normalzied_points_hull = [(point1[0]/5312, point1[1]/2988), (point2[0]/5312, point2[1]/2988)]  # Extract points (x, y)\n",
    "\n",
    "            hull=fo.Polyline(\n",
    "                points=[normalzied_points_hull],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_distance\n",
    "            )\n",
    "\n",
    "            # skeleton_straight=fo.Polyline(\n",
    "            #     points=[normalized_coords_straight],\n",
    "            #     closed=False,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "            # skeletons_straight.append(skeleton_straight)\n",
    "\n",
    "            skeleton_straight_2=fo.Polyline(\n",
    "                points=[normalized_coords_straight_2],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_length_2,\n",
    "                \n",
    "            )\n",
    "            skeletons_straight_2.append(skeleton_straight_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            hulls.append(hull)\n",
    "\n",
    "            # skeleton=fo.Polyline(\n",
    "            #     points=[normalized_coords],\n",
    "            #     closed=False,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "\n",
    "            # skeletons.append(skeleton)\n",
    "            \n",
    "            skeleton_2=fo.Polyline( \n",
    "                points=[normalized_coords_2],\n",
    "                closed=False,\n",
    "                filled=False,\n",
    "                max_length=max_length_2)\n",
    "            skeletons_2.append(skeleton_2)\n",
    "              # Convert the line to a list of floats\n",
    "            normalzied_points = [(coords[i]/640, coords[i + 1]/640) for i in range(0, len(coords), 2)]  # Extract points (x, y)\n",
    "            points = [Point(x*5312, y*2988) for x, y in normalzied_points] \n",
    "            \n",
    "\n",
    "            \n",
    "             # Convert to Point objects    \n",
    "            # Calculate the minimum enclosing circle (center and radius)\n",
    "            center, radius = calculate_minimum_enclosing_circle(points)\n",
    "            diameter = radius * 2\n",
    "\n",
    "            segmentation = fo.Polyline(\n",
    "                points=[normalzied_points],\n",
    "                closed=True,\n",
    "                filled=False,\n",
    "                diameter=diameter,\n",
    "                center=center,\n",
    "                max_length_skeleton=max_length_2,\n",
    "                max_length_hull=max_distance,\n",
    "                max_length_box=max_length_box\n",
    "            )\n",
    "\n",
    "            #smooth segmentation  wirh closing\n",
    "            # seg_closed=fo.Polyline(\n",
    "            #     points=[normalized_coords_bin],\n",
    "            #     closed=True,\n",
    "            #     filled=False,\n",
    "            #     max_length=max_length\n",
    "            # )\n",
    "\n",
    "            # seg_closeds.append(seg_closed)                \n",
    "\n",
    "\n",
    "            segmentations.append(segmentation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                     # Store the segmentation information (center, radius, and diameter)\n",
    "\n",
    "    return segmentations,skeletons,hulls, skeletons_straight,seg_closeds,skeletons_2,skeletons_straight_2,boxes,masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.core.labels as fol\n",
    "from tqdm import tqdm\n",
    "import fiftyone as fo\n",
    "import os\n",
    "\n",
    "def process_images(image_paths, prediction_folder_path, dataset):\n",
    "    print(\"Processing images...\")\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes images by matching segmentation with bounding boxes and calculating prawn sizes.\n",
    "    \"\"\"\n",
    "    for image_path in tqdm(image_paths):\n",
    "        # filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        \n",
    "\n",
    "           \n",
    "        # prediction_txt_path = os.path.join(prediction_folder_path, f\"{os.path.basename(image_path).split('.')[0]}_segmentations.txt\")\n",
    "\n",
    "        core_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "        # Construct the path to the corresponding segmentation file\n",
    "        prediction_txt_path = os.path.join(prediction_folder_path, f\"{core_name}_segmentations.txt\")\n",
    "\n",
    "        # core_name=filename.split('.')[0]\n",
    "        # # Construct the path to the prediction (segmentation) file\n",
    "        # prediction_txt_path = os.path.join(prediction_folder_path, f\"{core_name}_segmentations.txt\")\n",
    "        # if not os.path.exists(prediction_txt_path):\n",
    "        #     print(f\"No segmentation file found for {filename}\")\n",
    "        #     continue\n",
    "\n",
    "\n",
    "        # Parse the segmentations to get the minimum enclosing circles\n",
    "        segmentations,skeletons,hulls,skeletons_straight,seg_closeds,skeletons_2,skeletons_straight_2,boxes,masks = process_segmentations(prediction_txt_path)\n",
    "\n",
    "        # Save the modified image (with circles drawn)\n",
    "\n",
    "        # Create a new sample for FiftyOne\n",
    "        sample = fo.Sample(filepath=image_path)\n",
    "\n",
    "        # Iterate over each bounding box in the filtered data\n",
    "        sample[\"segmentations\"] = fol.Polylines(polylines=segmentations)\n",
    "\n",
    "        # sample[\"skeletons\"] = fol.Polylines(polylines=skeletons)\n",
    "\n",
    "        sample[\"hulls\"] = fol.Polylines(polylines=hulls)    \n",
    "\n",
    "        # sample[\"skeletons_straight\"] = fol.Polylines(polylines=skeletons_straight)\n",
    "\n",
    "        # sample['seg_closeds']=fol.Polylines(polylines=seg_closeds)\n",
    "        \n",
    "        sample['skeletons_no_smooth']=fol.Polylines(polylines=skeletons_2)\n",
    "\n",
    "        sample[\"skeletons_straight_no_smooth\"] = fol.Polylines(polylines=skeletons_straight_2)\n",
    "\n",
    "        sample['boxes']=fol.Polylines(polylines=boxes)\n",
    "\n",
    "        sample['masks']=fol.Polylines(polylines=masks)\n",
    "        # Add the processed sample to the FiftyOne dataset\n",
    "        dataset.add_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def process_detection_by_circle(segmentation):\n",
    "    \"\"\"\n",
    "    Process the prawn detection based on the enclosing circle's diameter.\n",
    "    Update the filtered dataframe with the real-world size of the prawn.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fetch height in mm and other metadata\n",
    "    height_mm =500\n",
    "    #focal length based on pond type\n",
    "    \n",
    "    focal_length = 24.72\n",
    "\n",
    "\n",
    "    # focal_length = 24.22  # Camera focal length\n",
    "    pixel_size = 0.00716844  # Pixel size in mm\n",
    "\n",
    "    poly=segmentation\n",
    "\n",
    "    fov=75\n",
    "    FOV_width=2*height_mm*math.tan(math.radians(fov/2))\n",
    "\n",
    "\n",
    "    # Get the diameter of the circle in pixels\n",
    "    predicted_diameter_pixels = poly['diameter']\n",
    "\n",
    "\n",
    "    predicted_skeleton_length=poly['max_length_skeleton']  \n",
    "\n",
    "    predicted_hull_length=poly['max_length_hull']\n",
    "\n",
    "     \n",
    "    predicted_box_length=poly['max_length_box']\n",
    "\n",
    "    # Calculate the real-world prawn size using the box\n",
    "    real_length_mm_box = calculate_real_width(focal_length, height_mm, predicted_box_length, pixel_size) \n",
    "\n",
    "\n",
    "    hull_length_cm = calculate_real_width(focal_length, height_mm, predicted_hull_length, pixel_size)    \n",
    "\n",
    "    # Calculate the real-world prawn size using the enclosing circle's diameter\n",
    "    real_length_cm = calculate_real_width(focal_length, height_mm, predicted_diameter_pixels, pixel_size)\n",
    "\n",
    "    ske_length_cm = calculate_real_width(focal_length, height_mm, predicted_skeleton_length, pixel_size)    \n",
    "\n",
    "\n",
    "    hull_length_fov=FOV_width*predicted_hull_length/5312\n",
    "    diameter_length_fov=FOV_width*predicted_diameter_pixels/5312\n",
    "    skeleton_length_fov=FOV_width*predicted_skeleton_length/5312\n",
    "\n",
    "    box_length_fov=FOV_width*predicted_box_length/5312\n",
    "\n",
    "    true_length=143\n",
    "    error_percentage_MEC_fov = abs(diameter_length_fov - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_hull_fov = abs(hull_length_fov - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_skeleton_fov = abs(skeleton_length_fov - true_length) / true_length * 100  \n",
    "\n",
    "    error_percentage = abs(real_length_cm - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_skeleton = abs(ske_length_cm - true_length) / true_length * 100    \n",
    "\n",
    "    error_percentage_hull = abs(hull_length_cm - true_length) / true_length * 100\n",
    "\n",
    "    error_percentage_box_fov = abs(box_length_fov - true_length) / true_length * 100\n",
    "\n",
    "    closest_detection_label = f'true length: {true_length:.2f}mm, MPError_hull: {error_percentage_hull_fov:.2f}%, , pred length: {hull_length_fov:.2f}mm ,error percentage skeleton: {error_percentage_skeleton_fov:.2f}%, , pred length: {skeleton_length_fov:.2f}cm, error percentage box: {error_percentage_box_fov:.2f}%, pred length: {box_length_fov:.2f}mm, '\n",
    "    # Update the filtered dataframe with the real-world size of the prawn\n",
    "\n",
    "    poly.label = closest_detection_label \n",
    "    return poly\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m molt_prediction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgbo10\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmeasurement_paper_images\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmolt\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmolt-19-9\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124munditorted_resized\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfiftyone\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfo\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmolt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m      8\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(molt_image_path, image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(molt_image_path) \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\singletons.py:36\u001b[0m, in \u001b[0;36mDatasetSingleton.__call__\u001b[1;34m(cls, name, _create, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     _create\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mdeleted\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     34\u001b[0m ):\n\u001b[0;32m     35\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m     instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name\u001b[38;5;241m=\u001b[39mname, _create\u001b[38;5;241m=\u001b[39m_create, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     name \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39mname  \u001b[38;5;66;03m# `__init__` may have changed `name`\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\dataset.py:283\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, name, persistent, overwrite, _create, _virtual, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m     name \u001b[38;5;241m=\u001b[39m get_default_dataset_name()\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overwrite \u001b[38;5;129;01mand\u001b[39;00m dataset_exists(name):\n\u001b[1;32m--> 283\u001b[0m     \u001b[43mdelete_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _create:\n\u001b[0;32m    286\u001b[0m     doc, sample_doc_cls, frame_doc_cls \u001b[38;5;241m=\u001b[39m _create_dataset(\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;28mself\u001b[39m, name, persistent\u001b[38;5;241m=\u001b[39mpersistent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    288\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\dataset.py:205\u001b[0m, in \u001b[0;36mdelete_dataset\u001b[1;34m(name, verbose)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Deletes the FiftyOne dataset with the given name.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    name: the name of the dataset\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m    verbose (False): whether to log the name of the deleted dataset\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    204\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(name)\n\u001b[1;32m--> 205\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    207\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m deleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\dataset.py:4407\u001b[0m, in \u001b[0;36mDataset.delete\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   4399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deletes the dataset.\u001b[39;00m\n\u001b[0;32m   4400\u001b[0m \n\u001b[0;32m   4401\u001b[0m \u001b[38;5;124;03m    Once deleted, only the ``name`` and ``deleted`` attributes of a dataset\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4405\u001b[0m \u001b[38;5;124;03m    such that ``sample.in_dataset`` is False.\u001b[39;00m\n\u001b[0;32m   4406\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4407\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\dataset.py:4411\u001b[0m, in \u001b[0;36mDataset._delete\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_delete\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   4410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_collection\u001b[38;5;241m.\u001b[39mdrop()\n\u001b[1;32m-> 4411\u001b[0m     \u001b[43mfos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_collection_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4413\u001b[0m     \u001b[38;5;66;03m# Clips datasets directly inherit frames from source dataset\u001b[39;00m\n\u001b[0;32m   4414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frame_collection_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_clips:\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\singletons.py:229\u001b[0m, in \u001b[0;36mSampleSingleton._reset_docs\u001b[1;34m(cls, collection_name, sample_ids)\u001b[0m\n\u001b[0;32m    227\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39mpop(collection_name)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m--> 229\u001b[0m     \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset_backing_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\document.py:604\u001b[0m, in \u001b[0;36mDocument._reset_backing_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reset_backing_doc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    600\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resets the backing doc for the document.\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \n\u001b[0;32m    602\u001b[0m \u001b[38;5;124;03m    The document will no longer belong to a dataset.\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_doc\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\sample.py:413\u001b[0m, in \u001b[0;36m_SampleMixin.copy\u001b[1;34m(self, fields, omit_fields)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedia_type \u001b[38;5;241m==\u001b[39m fomm\u001b[38;5;241m.\u001b[39mVIDEO:\n\u001b[0;32m    404\u001b[0m     (\n\u001b[0;32m    405\u001b[0m         fields,\n\u001b[0;32m    406\u001b[0m         frame_fields,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m         fields\u001b[38;5;241m=\u001b[39mfields, omit_fields\u001b[38;5;241m=\u001b[39momit_fields\n\u001b[0;32m    411\u001b[0m     )\n\u001b[1;32m--> 413\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momit_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43momit_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedia_type \u001b[38;5;241m==\u001b[39m fomm\u001b[38;5;241m.\u001b[39mVIDEO:\n\u001b[0;32m    416\u001b[0m     sample\u001b[38;5;241m.\u001b[39mframes\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    417\u001b[0m         {\n\u001b[0;32m    418\u001b[0m             frame_number: frame\u001b[38;5;241m.\u001b[39mcopy(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m         }\n\u001b[0;32m    423\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\document.py:499\u001b[0m, in \u001b[0;36mDocument.copy\u001b[1;34m(self, fields, omit_fields)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, omit_fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    497\u001b[0m     fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_fields(fields\u001b[38;5;241m=\u001b[39mfields, omit_fields\u001b[38;5;241m=\u001b[39momit_fields)\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\n\u001b[1;32m--> 499\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{v: deepcopy(\u001b[38;5;28mself\u001b[39m[k]) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m fields\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    500\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\document.py:499\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, omit_fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    497\u001b[0m     fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_fields(fields\u001b[38;5;241m=\u001b[39mfields, omit_fields\u001b[38;5;241m=\u001b[39momit_fields)\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\n\u001b[1;32m--> 499\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{v: \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m fields\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    500\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\odm\\document.py:290\u001b[0m, in \u001b[0;36mMongoEngineBaseDocument.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__deepcopy__\u001b[39m(\u001b[38;5;28mself\u001b[39m, memo):\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# pylint: disable=no-member, unsubscriptable-object\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    291\u001b[0m         f: deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_field(f), memo)\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fields_ordered\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m     }\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\odm\\document.py:291\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__deepcopy__\u001b[39m(\u001b[38;5;28mself\u001b[39m, memo):\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# pylint: disable=no-member, unsubscriptable-object\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 291\u001b[0m         f: \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fields_ordered\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m     }\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\copy.py:287\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m listiter:\n\u001b[1;32m--> 287\u001b[0m         item \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(item)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\odm\\document.py:295\u001b[0m, in \u001b[0;36mMongoEngineBaseDocument.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__deepcopy__\u001b[39m(\u001b[38;5;28mself\u001b[39m, memo):\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# pylint: disable=no-member, unsubscriptable-object\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    291\u001b[0m         f: deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_field(f), memo)\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fields_ordered\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m     }\n\u001b[1;32m--> 295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\odm\\embedded_document.py:48\u001b[0m, in \u001b[0;36mDynamicEmbeddedDocument.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\document.py:90\u001b[0m, in \u001b[0;36mEmbeddedDocument.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_changed_fields \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\base\\document.py:127\u001b[0m, in \u001b[0;36mBaseDocument.__init__\u001b[1;34m(self, *args, **values)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __auto_convert \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m field \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(field, FileField):\n\u001b[1;32m--> 127\u001b[0m             value \u001b[38;5;241m=\u001b[39m \u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\base\\fields.py:367\u001b[0m, in \u001b[0;36mComplexBaseField.to_python\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield:\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield\u001b[38;5;241m.\u001b[39m_auto_dereference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_dereference\n\u001b[1;32m--> 367\u001b[0m     value_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    368\u001b[0m         key: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield\u001b[38;5;241m.\u001b[39mto_python(item) \u001b[38;5;28;01mfor\u001b[39;00m key, item \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    369\u001b[0m     }\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m     Document \u001b[38;5;241m=\u001b[39m _import_class(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\base\\fields.py:368\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield:\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield\u001b[38;5;241m.\u001b[39m_auto_dereference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_dereference\n\u001b[0;32m    367\u001b[0m     value_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 368\u001b[0m         key: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, item \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    369\u001b[0m     }\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m     Document \u001b[38;5;241m=\u001b[39m _import_class(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\fields.py:772\u001b[0m, in \u001b[0;36mEmbeddedDocumentField.to_python\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_python\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocument_type):\n\u001b[1;32m--> 772\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_son\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_auto_dereference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_dereference\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\odm\\document.py:498\u001b[0m, in \u001b[0;36mDynamicMixin._from_son\u001b[1;34m(cls, d, *args, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_son\u001b[39m(\u001b[38;5;28mcls\u001b[39m, d, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;66;03m# We must manually deserialize dynamic fields because MongoEngine\u001b[39;00m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;66;03m# doesn't have a `Field` instance to deserialize them for us\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     rename \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_fields:\n\u001b[0;32m    501\u001b[0m             v \u001b[38;5;241m=\u001b[39m deserialize_value(v)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "molt_image_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\molt-19-9\\unditorted\"\n",
    "molt_prediction=r'C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\molt\\molt-19-9\\unditorted_resized'\n",
    "\n",
    "import fiftyone as fo\n",
    "dataset = fo.Dataset(\"molt\", overwrite=True)\n",
    "\n",
    "# Load the dataset\n",
    "image_paths = [os.path.join(molt_image_path, image) for image in os.listdir(molt_image_path) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "prediction_paths_text = [os.path.join(molt_prediction, txt) for txt in os.listdir(molt_prediction) if txt.endswith('.txt')]\n",
    "\n",
    "# Process images\n",
    "\n",
    "process_images(image_paths, molt_prediction, dataset)\n",
    "\n",
    "# Process segmentations\n",
    "for sample in dataset:\n",
    "    # Access the polylines for each sample\n",
    "    for i, segmentation in enumerate(sample[\"segmentations\"].polylines):\n",
    "        # Process and modify the segmentation\n",
    "        updated_segmentation = process_detection_by_circle(segmentation)\n",
    "\n",
    "        print(f'updated_segmentation.label {updated_segmentation.label}')\n",
    "        # Save the updated segmentation back into the sample\n",
    "        sample[\"segmentations\"].polylines[i] = updated_segmentation\n",
    "\n",
    "        sample.save()\n",
    "# Launch FiftyOne session\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
