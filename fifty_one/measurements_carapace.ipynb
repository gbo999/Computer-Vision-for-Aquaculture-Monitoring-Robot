{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. load the keypoints to fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils as fou\n",
    "import os\n",
    "\n",
    "# Assuming you have a list of image paths and corresponding TXT file paths\n",
    "image_paths = [...]  # List of image file paths\n",
    "txt_paths = [...]  # List of corresponding TXT file paths for each image\n",
    "\n",
    "# Create a FiftyOne dataset\n",
    "dataset = fo.Dataset(\"prawn_pose_estimation\")\n",
    "def parse_pose_estimation(txt_file):\n",
    "    \"\"\"\n",
    "    Parse the pose estimation data from a TXT file.\n",
    "\n",
    "    Parameters:\n",
    "    txt_file (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of pose estimation data (each line parsed into a list of values).\n",
    "    \"\"\"\n",
    "    pose_estimations = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f:\n",
    "            pose_estimations.append([float(x) for x in line.strip().split()])\n",
    "    return pose_estimations\n",
    "\n",
    "# Loop over images and corresponding TXT files\n",
    "for img_path, txt_path in zip(image_paths, txt_paths):\n",
    "    # Parse the pose estimation data from the TXT file\n",
    "    pose_estimations = parse_pose_estimation(txt_path)\n",
    "    \n",
    "    # List to hold all detections and keypoints for the current image\n",
    "    detections = []\n",
    "    \n",
    "    for pose in pose_estimations:\n",
    "        # Extract and scale bounding box and keypoints\n",
    "        x_center_scaled = pose[1] * 5312\n",
    "        y_center_scaled = pose[2] * 2988\n",
    "        width_scaled = pose[3] * 5312\n",
    "        height_scaled = pose[4] * 2988\n",
    "\n",
    "        keypoints = []\n",
    "        for i in range(5, len(pose), 3):\n",
    "            x_kp_scaled = pose[i] * 5312\n",
    "            y_kp_scaled = pose[i + 1] * 2988\n",
    "            confidence = pose[i + 2]\n",
    "            keypoints.append(fo.Keypoint(point=[x_kp_scaled, y_kp_scaled], confidence=confidence))\n",
    "\n",
    "        bounding_box = [\n",
    "            (x_center_scaled - width_scaled / 2) / 5312,\n",
    "            (y_center_scaled - height_scaled / 2) / 2988,\n",
    "            width_scaled / 5312,\n",
    "            height_scaled / 2988\n",
    "        ]\n",
    "\n",
    "        # Create a detection object\n",
    "        detection = fo.Detection(label=\"prawn\", bounding_box=bounding_box, keypoints=keypoints)\n",
    "        detections.append(detection)\n",
    "\n",
    "    # Create a sample for FiftyOne\n",
    "    sample = fo.Sample(filepath=img_path)\n",
    "    sample[\"detections\"] = fo.Detections(detections=detections)\n",
    "    dataset.add_sample(sample)\n",
    "\n",
    "# Launch the FiftyOne app to visualize\n",
    "session = fo.launch_app(dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. load metadata from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fiftyone as fo\n",
    "\n",
    "# Read the Excel file\n",
    "file_path = 'your_file_path.xlsx'  # Replace with your actual file path\n",
    "metadata_df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows to ensure it's loaded correctly\n",
    "print(metadata_df.head())\n",
    "\n",
    "\n",
    "# Assuming you have a list of image paths\n",
    "image_paths = [...]  # List of image file paths\n",
    "\n",
    "# Create a FiftyOne dataset\n",
    "dataset = fo.Dataset(\"prawn_metadata\")\n",
    "\n",
    "# Loop through each image and add metadata\n",
    "for img_path in image_paths:\n",
    "    # Extract the filename without extension\n",
    "    filename = img_path.split('/')[-1].replace('.jpg', '')  # Adjust if not .jpg\n",
    "    \n",
    "    # Match the filename with the metadata\n",
    "    metadata_row = metadata_df[metadata_df['file name'] == filename]\n",
    "    \n",
    "    if not metadata_row.empty:\n",
    "        metadata = metadata_row.iloc[0].to_dict()\n",
    "        \n",
    "        # Create a sample and attach metadata\n",
    "        sample = fo.Sample(filepath=img_path)\n",
    "        \n",
    "        # Add each metadata field to the sample\n",
    "        for key, value in metadata.items():\n",
    "            if key != 'file name':  # Exclude the file name itself\n",
    "                sample[key] = value\n",
    "        \n",
    "        # Add the sample to the dataset\n",
    "        dataset.add_sample(sample)\n",
    "\n",
    "# Launch the FiftyOne app to visualize\n",
    "session = fo.launch_app(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.bounding rectangle between detection and imagej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load ImageJ bounding rectangles from a CSV file\n",
    "imagej_bboxes_df = pd.read_csv('imagej_bboxes.csv')\n",
    "\n",
    "# Example structure of `imagej_bboxes_df`:\n",
    "# Columns: ['file name', 'x1', 'y1', 'x2', 'y2']\n",
    "def calculate_bbox_distance(detection_bbox, imagej_bbox):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between the centers of two bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    detection_bbox (tuple): (x1, y1, x2, y2) coordinates of the detection bounding box.\n",
    "    imagej_bbox (tuple): (x1, y1, x2, y2) coordinates of the ImageJ bounding box.\n",
    "\n",
    "    Returns:\n",
    "    float: Euclidean distance between the centers of the bounding boxes.\n",
    "    \"\"\"\n",
    "    # Calculate centers\n",
    "    detection_center = ((detection_bbox[0] + detection_bbox[2]) / 2, (detection_bbox[1] + detection_bbox[3]) / 2)\n",
    "    imagej_center = ((imagej_bbox[0] + imagej_bbox[2]) / 2, (imagej_bbox[1] + imagej_bbox[3]) / 2)\n",
    "    \n",
    "    # Calculate Euclidean distance between centers\n",
    "    distance = np.sqrt((detection_center[0] - imagej_center[0])**2 + (detection_center[1] - imagej_center[1])**2)\n",
    "    return distance\n",
    "for img_path in image_paths:\n",
    "    filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    # Assume `detections` is a list of bounding boxes from the model\n",
    "    detection_bboxes = [...]  # Replace with actual detection bounding boxes\n",
    "    \n",
    "    # Match with ImageJ bounding box\n",
    "    imagej_bbox = imagej_bboxes_df[imagej_bboxes_df['file name'] == filename].iloc[0]\n",
    "    imagej_bbox = (imagej_bbox['x1'], imagej_bbox['y1'], imagej_bbox['x2'], imagej_bbox['y2'])\n",
    "    \n",
    "    distances = []\n",
    "    for detection_bbox in detection_bboxes:\n",
    "        distance = calculate_bbox_distance(detection_bbox, imagej_bbox)\n",
    "        distances.append(distance)\n",
    "    \n",
    "    # Create a FiftyOne sample and add metadata\n",
    "    sample = fo.Sample(filepath=img_path)\n",
    "    sample['bbox_distances'] = distances  # Store all distances for this image\n",
    "    \n",
    "    dataset.add_sample(sample)\n",
    "\n",
    "# Launch FiftyOne app to visualize\n",
    "session = fo.launch_app(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. calculate length based on pinhole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_real_width(focal_length, distance_to_object, width_in_pixels, pixel_size):\n",
    "    \"\"\"\n",
    "    Calculate the real-life width of an object.\n",
    "\n",
    "    Parameters:\n",
    "    focal_length (float): Focal length of the camera lens in millimeters (mm).\n",
    "    distance_to_object (float): Distance from the camera to the object in millimeters (mm).\n",
    "    width_in_pixels (int): Width of the object in pixels on the image sensor.\n",
    "    pixel_size (float): Size of a pixel on the image sensor in millimeters (mm).\n",
    "\n",
    "    Returns:\n",
    "    float: Real-life width of the object in centimeters (cm).\n",
    "    \"\"\"\n",
    "    # Calculate the width of the object in the image sensor plane in millimeters\n",
    "    width_in_sensor = width_in_pixels * pixel_size\n",
    "\n",
    "    # Calculate the real-life width of the object using the similar triangles principle\n",
    "    real_width_mm = (width_in_sensor * distance_to_object) / focal_length\n",
    "\n",
    "    # Convert the width from millimeters to centimeters\n",
    "    real_width_cm = real_width_mm / 10.0\n",
    "\n",
    "    return real_width_cm\n",
    "\n",
    "def calculate_euclidean_distance(keypoint1, keypoint2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two keypoints.\n",
    "\n",
    "    Parameters:\n",
    "    keypoint1, keypoint2: Tuples of (x, y) coordinates of the keypoints in pixels.\n",
    "\n",
    "    Returns:\n",
    "    float: Euclidean distance between the keypoints in pixels.\n",
    "    \"\"\"\n",
    "    return np.sqrt((keypoint1[0] - keypoint2[0])**2 + (keypoint1[1] - keypoint2[1])**2)\n",
    "\n",
    "# Example of how to integrate this with your FiftyOne dataset\n",
    "for img_path in image_paths:\n",
    "    filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    metadata_row = metadata_df[metadata_df['file name'] == filename]\n",
    "    \n",
    "    if not metadata_row.empty:\n",
    "        metadata = metadata_row.iloc[0].to_dict()\n",
    "        sample = fo.Sample(filepath=img_path)\n",
    "        \n",
    "        # Add metadata\n",
    "        for key, value in metadata.items():\n",
    "            if key != 'file name':\n",
    "                sample[key] = value\n",
    "        \n",
    "        # Calculate the real height or width if keypoints and necessary metadata are available\n",
    "        if 'height(mm)' in metadata:\n",
    "            height_mm = metadata['height(mm)']\n",
    "            focal_length = 6.82  # Example focal length in mm\n",
    "            pixel_size = 0.0014  # Example pixel size in mm\n",
    "            keypoints = [...]  # Replace with actual keypoints from your data\n",
    "            \n",
    "            if len(keypoints) >= 2:\n",
    "                # Calculate the Euclidean distance in pixels\n",
    "                euclidean_distance_pixels = calculate_euclidean_distance(keypoints[0], keypoints[1])\n",
    "                \n",
    "                # Calculate the real width/height in centimeters\n",
    "                real_width_cm = calculate_real_width(focal_length, height_mm, euclidean_distance_pixels, pixel_size)\n",
    "                \n",
    "                # Attach the calculated real width/height to the sample\n",
    "                sample[\"real_width_cm\"] = real_width_cm\n",
    "        \n",
    "        dataset.add_sample(sample)\n",
    "\n",
    "session = fo.launch_app(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complete maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = fo.list_datasets()\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    if dataset_name.startswith('prawn_combined_dataset'):\n",
    "        fo.delete_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 121\u001b[0m\n\u001b[0;32m    115\u001b[0m            keypoint\u001b[38;5;241m=\u001b[39mfo\u001b[38;5;241m.\u001b[39mKeypoint(points\u001b[38;5;241m=\u001b[39mkeypoints, confidence\u001b[38;5;241m=\u001b[39mconfidences)\n\u001b[0;32m    116\u001b[0m            keypoints_list\u001b[38;5;241m.\u001b[39mappend(keypoint)\n\u001b[1;32m--> 121\u001b[0m            detections\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetection\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounding_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mx1_rel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1_rel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_rel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_rel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mattributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeypoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkeypoints\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    126\u001b[0m    sample \u001b[38;5;241m=\u001b[39m fo\u001b[38;5;241m.\u001b[39mSample(filepath\u001b[38;5;241m=\u001b[39mimg_path)\n\u001b[0;32m    128\u001b[0m    \u001b[38;5;66;03m# Add keypoints as a separate field\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\odm\\embedded_document.py:48\u001b[0m, in \u001b[0;36mDynamicEmbeddedDocument.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\document.py:90\u001b[0m, in \u001b[0;36mEmbeddedDocument.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_changed_fields \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\base\\document.py:127\u001b[0m, in \u001b[0;36mBaseDocument.__init__\u001b[1;34m(self, *args, **values)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __auto_convert \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m field \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(field, FileField):\n\u001b[1;32m--> 127\u001b[0m             value \u001b[38;5;241m=\u001b[39m \u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\base\\fields.py:367\u001b[0m, in \u001b[0;36mComplexBaseField.to_python\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield:\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield\u001b[38;5;241m.\u001b[39m_auto_dereference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_dereference\n\u001b[1;32m--> 367\u001b[0m     value_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    368\u001b[0m         key: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield\u001b[38;5;241m.\u001b[39mto_python(item) \u001b[38;5;28;01mfor\u001b[39;00m key, item \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    369\u001b[0m     }\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m     Document \u001b[38;5;241m=\u001b[39m _import_class(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\base\\fields.py:368\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield:\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield\u001b[38;5;241m.\u001b[39m_auto_dereference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_dereference\n\u001b[0;32m    367\u001b[0m     value_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 368\u001b[0m         key: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, item \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    369\u001b[0m     }\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m     Document \u001b[38;5;241m=\u001b[39m _import_class(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\mongoengine\\fields.py:772\u001b[0m, in \u001b[0;36mEmbeddedDocumentField.to_python\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_python\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocument_type):\n\u001b[1;32m--> 772\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_son\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_auto_dereference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_dereference\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\.venv\\lib\\site-packages\\fiftyone\\core\\odm\\document.py:498\u001b[0m, in \u001b[0;36mDynamicMixin._from_son\u001b[1;34m(cls, d, *args, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_son\u001b[39m(\u001b[38;5;28mcls\u001b[39m, d, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;66;03m# We must manually deserialize dynamic fields because MongoEngine\u001b[39;00m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;66;03m# doesn't have a `Field` instance to deserialize them for us\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     rename \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_fields:\n\u001b[0;32m    501\u001b[0m             v \u001b[38;5;241m=\u001b[39m deserialize_value(v)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "# Load the existing filtered data with PrawnIDs\n",
    "filtered_data_file_path = r'C:\\Users\\gbo10\\Videos\\research\\counting_research_algorithms\\src\\measurement\\ImageJ\\Filtered_Data.csv'  # Replace with your actual file path\n",
    "filtered_df = pd.read_csv(filtered_data_file_path)\n",
    "\n",
    "# Load the additional metadata from another Excel file\n",
    "metadata_file_path = r\"C:\\Users\\gbo10\\OneDrive\\research\\thesis and paper\\test images.xlsx\"  # Replace with your actual file path\n",
    "metadata_df = pd.read_excel(metadata_file_path)\n",
    "\n",
    "# Function to parse pose estimation data from a TXT file\n",
    "def parse_pose_estimation(txt_file):\n",
    "    pose_estimations = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f:\n",
    "            pose_estimations.append([float(x) for x in line.strip().split()])\n",
    "    return pose_estimations\n",
    "\n",
    "# Function to calculate Euclidean distance between keypoints\n",
    "def calculate_euclidean_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "\n",
    "# Function to calculate the real-life width/height\n",
    "def calculate_real_width(focal_length, distance_to_object, width_in_pixels, pixel_size):\n",
    "    width_in_sensor = width_in_pixels * pixel_size\n",
    "    real_width_mm = (width_in_sensor * distance_to_object) / focal_length\n",
    "    return real_width_mm\n",
    "\n",
    "\n",
    "folder_path = r'C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\for fiftyone'  # Replace with the folder containing the images and TXT files\n",
    "\n",
    "# Assuming you have the following lists\n",
    "image_paths = [os.path.join(folder_path, image) for image in os.listdir(folder_path) if image.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "\n",
    "label_folder_path=r\"C:\\Users\\gbo10\\Videos\\data-science\\Research-counting-algorithms\\runs\\pose\\predict18\\labels\"\n",
    "\n",
    "txt_paths = [os.path.join(label_folder_path, txt) for txt in os.listdir(label_folder_path) if txt.endswith('.txt')]\n",
    "# Create a FiftyOne dataset\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "# List all datasets in FiftyOne\n",
    "\n",
    "# Loop through the list and delete datasets that match the condition\n",
    "\n",
    "\n",
    "#delete all datasets\n",
    "\n",
    "\n",
    "# Create a new dataset\n",
    "\n",
    "dataset = fo.Dataset(\"prawn_combined_dataset8\")\n",
    "\n",
    "dataset.default_skeleton = fo.KeypointSkeleton(\n",
    "    labels=[\n",
    "        \"start_carapace\",\n",
    "        \"eyes\",\n",
    "    ],\n",
    "    edges=[\n",
    "        [0, 1],  # Connect keypoint 0 to keypoint 1  # Connect keypoint 1 to keypoint 2\n",
    "        # Add more connections as needed\n",
    "    ],\n",
    ")\n",
    "# Loop over images and corresponding TXT files\n",
    "for img_path, txt_path in tqdm(zip(image_paths, txt_paths)):\n",
    "\n",
    "\n",
    "    filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    parts = filename.split('_')\n",
    "    relevant_part = f\"{parts[1][-3:]}_{parts[3].split('.')[0]}\"  # Extract the part like '152_378'\n",
    "    \n",
    "\n",
    "\n",
    "    # Parse the pose estimation data from the TXT file\n",
    "    pose_estimations = parse_pose_estimation(txt_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    keypoints_list = []  # List to store keypoints\n",
    "    detections = []  # List to store detection bounding boxes\n",
    "\n",
    "    for pose in pose_estimations:\n",
    "        if len(pose)==11:        \n",
    "\n",
    "            x1_rel = pose[1] \n",
    "            y1_rel = pose[2] \n",
    "            width_rel = pose[3] \n",
    "            height_rel = pose[4] \n",
    "\n",
    "            \n",
    "            #center to top left\n",
    "            x1_rel = x1_rel - width_rel/2\n",
    "            y1_rel = y1_rel - height_rel/2\n",
    "        # Calc\n",
    "\n",
    "\n",
    "\n",
    "            keypoints = []\n",
    "            confidences = []\n",
    "            for i in range(5, len(pose), 3):\n",
    "                x_kp_scaled = pose[i] \n",
    "                y_kp_scaled = pose[i + 1] \n",
    "                confidence = pose[i + 2]\n",
    "                keypoints.append([x_kp_scaled, y_kp_scaled])\n",
    "                confidences.append(confidence)\n",
    "            \n",
    "            keypoint=fo.Keypoint(points=keypoints, confidence=confidences)\n",
    "            keypoints_list.append(keypoint)\n",
    "\n",
    "\n",
    "            keypoints_dict= {'point1':keypoints[i],'point2':keypoints[i+1]}\n",
    "            detections.append(fo.Detection\n",
    "                              (label=\"prawn\", bounding_box=[x1_rel, y1_rel, width_rel, height_rel],\n",
    "                               attributes={'keypoints':[keypoints_dict]\n",
    " }))\n",
    "\n",
    "    sample = fo.Sample(filepath=img_path)\n",
    "    \n",
    "    # Add keypoints as a separate field\n",
    "    sample[\"keypoints\"] = fo.Keypoints(keypoints=keypoints_list)\n",
    "   \n",
    "    sample[\"detections\"] = fo.Detections(detections=detections)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Match the filename with the corresponding rows in the filtered data\n",
    "    matching_rows = filtered_df[filtered_df['Label'] == f'carapace:{filename}']\n",
    "    \n",
    "    # Add metadata from the additional Excel file\n",
    "    metadata_row = metadata_df[metadata_df['file name'] == relevant_part]\n",
    "\n",
    "    if not metadata_row.empty:\n",
    "        metadata = metadata_row.iloc[0].to_dict() \n",
    "        for key, value in metadata.items():\n",
    "            if key != 'file name': \n",
    "                sample[key] = value\n",
    "            \n",
    "                        \n",
    "    else:\n",
    "        print(f\"No metadata found for {relevant_part}\")\n",
    "    true_detections=[]\n",
    "\n",
    "    for _, row in matching_rows.iterrows():\n",
    "        prawn_id = row['PrawnID']\n",
    "        prawn_bbox = ast.literal_eval(row['BoundingBox_1'])  # Replace with the correct column name\n",
    "\n",
    "        # Convert the tuple elements to floats\n",
    "        prawn_bbox = tuple(float(coord) for coord in prawn_bbox)# Replace with correct bounding box columns\n",
    "        \n",
    "        prawn_normalized_bbox=[prawn_bbox[0]/5312, prawn_bbox[1]/2988, prawn_bbox[2]/5312, prawn_bbox[3]/2988]\n",
    "\n",
    "        # Convert PrawnID bounding box to absolute coordinates\n",
    "        \n",
    "        \n",
    "        true_detections.append(fo.Detection(label=\"prawn_true\", bounding_box=prawn_normalized_bbox))\n",
    "\n",
    "        prawn_point=(prawn_bbox[0], prawn_bbox[1])\n",
    "        \n",
    "\n",
    "        # Find the closest detection bounding box within the same image (Label)\n",
    "        min_distance = float('inf')\n",
    "        closest_detection = None\n",
    "        \n",
    "        for detection_bbox in detections:\n",
    "            detection_bbox_coords = detection_bbox.bounding_box\n",
    "            \n",
    "            det_point=(detection_bbox_coords[0], detection_bbox_coords[1])\n",
    "            \n",
    "            distance = calculate_euclidean_distance(prawn_point, det_point)\n",
    "            \n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_detection = detection_bbox\n",
    "        \n",
    "        if closest_detection is not None:\n",
    "            height_mm = sample['heigtht(mm)']  # Use appropriate column for height in mm\n",
    "            focal_length = 24.22\n",
    "            pixel_size = 0.00716844 \n",
    "\n",
    "                \n",
    "\n",
    "            keypoints_dict2 = closest_detection.get_attribute_value('keypoints')\n",
    "\n",
    "            keypoints = [keypoints_dict2['point1'], keypoints_dict2['point2']]        \n",
    "\n",
    "            keypoint1_scaled = [keypoints[0][0] * 5312, keypoints[0][1] * 2988]\n",
    "            keypoint2_scaled = [keypoints[1][0] * 5312, keypoints[1][1] * 2988]\n",
    "\n",
    "            euclidean_distance_pixels = calculate_euclidean_distance(keypoint1_scaled, keypoint2_scaled)\n",
    "            real_length_cm = calculate_real_width(focal_length, height_mm, euclidean_distance_pixels, pixel_size)\n",
    "            \n",
    "\n",
    "            # Update the filtered_df with the calculated lengths\n",
    "            filtered_df.loc[(filtered_df['Label'] == f'carapace:{filename}') & (filtered_df['PrawnID'] == prawn_id), 'RealLength(cm)'] = real_length_cm\n",
    "            \n",
    "            # Add floating text near the keypoints in FiftyOne\n",
    "\n",
    "            true_length=filtered_df.loc[(filtered_df['Label'] == f'carapace:{filename}') & (filtered_df['PrawnID'] == prawn_id), 'Avg_Length'].values[0]\n",
    "\n",
    "\n",
    "            closest_detection_label =f\"Real: {real_length_cm:.2f} cm, True: {true_length:.2f} cm, MPError: {abs(real_length_cm - true_length) / true_length * 100:.2f}%\"\n",
    "            \n",
    "            closest_detection.label=closest_detection_label\n",
    "\n",
    "\n",
    "            #if mpe>25: tag sample\n",
    "            if abs(real_length_cm - true_length) / true_length * 100 > 25:\n",
    "                if \"MPE>25\" not in sample.tags:\n",
    "                    sample.tags.append(\"MPE>25\")\n",
    "            \n",
    "    # Assuming 'sample' is your FiftyOne sample object\n",
    "        \n",
    "    sample[\"true_detections\"] = fo.Detections(detections=true_detections)            \n",
    "\n",
    "    dataset.add_sample(sample)\n",
    "    \n",
    "\n",
    "# Save the updated filtered data with the calculated lengths\n",
    "# filtered_df.to_excel('updated_filtered_data_with_lengths.xlsx', index=False)\n",
    "\n",
    "# Launch the FiftyOne app to visualize\n",
    "\n",
    "# Define a custom view\n",
    "\n",
    "# Configure the view to show your custom attributes\n",
    "\n",
    "# Launch the app with the custom view\n",
    "session = fo.launch_app(dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
