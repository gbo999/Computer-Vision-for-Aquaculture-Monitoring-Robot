{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0: full length:GX010067_33_625.jpg_gamma_stabilized_00001, bx=2875, by=1822, width=51, height=17, length=10\n",
      "Processing row 1: full length:GX010067_33_625.jpg_gamma_stabilized_00001, bx=2875, by=1822, width=51, height=17, length=53\n",
      "Processing row 2: full length:GX010067_33_625.jpg_gamma_stabilized_00001, bx=2878, by=524, width=489, height=462, length=126\n",
      "Processing row 3: full length:GX010067_33_625.jpg_gamma_stabilized_00001, bx=3643, by=1762, width=344, height=383, length=96\n",
      "Processing row 4: full length:GX010067_33_625.jpg_gamma_stabilized_00001, bx=997, by=1944, width=821, height=225, length=160\n",
      "Processing row 5: full length:GX010067_33_625.jpg_gamma_stabilized_00001, bx=82, by=2094, width=505, height=44, length=95\n",
      "Saved output image to annot.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "# Load the CSV file\n",
    "file_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\images used for imageJ\\check\\excel_examples\\Full_length.xlsx\"\n",
    "data=pd.read_excel(file_path)\n",
    "# Process each row in the CSV\n",
    "\n",
    "\n",
    "# Load the image\n",
    "image_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\images used for imageJ\\check\\stabilized\\shai\\measurements/1/full body\\undistorted_GX010067_33_625.jpg_gamma.jpg\" # Adjust the path as needed\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    # Extract the details from the row\n",
    "    label = row['Label']\n",
    "\n",
    "    bx = int(row['BX']*5.3)\n",
    "    by = int(row['BY']*5.3)\n",
    "    width = int(row['Width']*5.3)\n",
    "    height = int(row['Height']*5.3)\n",
    "    length = int(row['Length'])\n",
    "    angle = row['Angle']\n",
    "\n",
    "\n",
    "    #draw rectangle\n",
    "    color = (0, 255, 0)  # Green color in BGR\n",
    "    thickness = 2\n",
    "    image = cv2.rectangle(image, (bx, by), (bx + width, by + height), color, thickness)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Processing row {index}: {label}, bx={bx}, by={by}, width={width}, height={height}, length={length}\")   \n",
    "\n",
    "    if angle<0 and angle>-90:\n",
    "            start_point = (bx, by+height)\n",
    "            end_point = ( bx+width,by+height )             \n",
    "    elif angle < -90 and angle > -180:\n",
    "             start_point = (bx, by+height)\n",
    "             end_point = ( bx+width,by  )  \n",
    "\n",
    "    elif angle < 180 and angle > 90:\n",
    "             start_point = (bx, by)\n",
    "             end_point = ( bx+width,by+height  )\n",
    "    else:\n",
    "                start_point = (bx, by+height)\n",
    "                end_point = ( bx+width,by+height ) \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "    color = (255, 0, 0)  # Blue color in BGR\n",
    "    thickness = 2\n",
    "    image = cv2.line(image, start_point, end_point, color, thickness)\n",
    "\n",
    "    # Draw a large circle at (bx, by)\n",
    "    circle_radius = 10\n",
    "    circle_color = (0, 0, 255)  # Red color in BGR\n",
    "    image = cv2.circle(image, (bx, by), circle_radius, circle_color, -1)\n",
    "\n",
    "    # Draw circles at the corners of the bounding box\n",
    "    corners = [(bx + width, by), (bx, by + height), (bx + width, by + height)]\n",
    "    for corner in corners:\n",
    "        image = cv2.circle(image, corner, circle_radius, circle_color, -1)\n",
    "\n",
    "    # Add the bx, by text\n",
    "    text_bx_by = f'({bx}, {by})'\n",
    "    org_bx_by = (bx + 15, by + 15)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.6\n",
    "    text_color = (0, 255, 0)  # Green color in BGR\n",
    "    text_thickness = 2\n",
    "    image = cv2.putText(image, text_bx_by, org_bx_by, font, font_scale, text_color, text_thickness, cv2.LINE_AA)\n",
    "\n",
    "    # Add the length text\n",
    "    text_length = f'Length: {length:.2f}'\n",
    "    org_length = (bx+width, by - 10)\n",
    "    image = cv2.putText(image, text_length, org_length, font, font_scale, text_color, text_thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Save or display the image\n",
    "output_path = f'annot.jpg'  # Adjust the path as needed\n",
    "cv2.imwrite(output_path, image)\n",
    "print(f\"Saved output image to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0: GX010082_212_2827.jpg, bx=3004, by=736, width=5, height=441, length=440\n",
      "Processing row 1: GX010082_212_2827.jpg, bx=3276, by=668, width=5, height=493, length=492\n",
      "Processing row 2: GX010082_212_2827.jpg, bx=3456, by=864, width=537, height=21, length=536\n",
      "Processing row 3: GX010082_212_2827.jpg, bx=3448, by=980, width=589, height=17, length=588\n",
      "Processing row 4: GX010082_212_2827.jpg, bx=3888, by=524, width=225, height=225, length=316\n",
      "Processing row 5: GX010082_212_2827.jpg, bx=3788, by=476, width=205, height=205, length=288\n",
      "Processing row 6: GX010082_212_2827.jpg, bx=2476, by=360, width=401, height=369, length=543\n",
      "Processing row 7: GX010082_212_2827.jpg, bx=2424, by=440, width=357, height=329, length=484\n",
      "Processing row 8: GX010082_212_2827.jpg, bx=3560, by=1238, width=200, height=58, length=207\n",
      "Processing row 9: GX010082_212_2827.jpg, bx=3531, by=1193, width=197, height=63, length=205\n",
      "Processing row 10: GX010082_212_2827.jpg, bx=2818, by=1242, width=160, height=42, length=164\n",
      "Processing row 11: GX010082_212_2827.jpg, bx=2810, by=1291, width=168, height=46, length=172\n",
      "Saved output image to annot2.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "# Load the CSV file\n",
    "file_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\each video from research extracted to images\\kalkar - january 2024/1.1/65\\Results.csv\"\n",
    "data=pd.read_csv(file_path)\n",
    "# Process each row in the CSV\n",
    "\n",
    "\n",
    "# Load the image\n",
    "image_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\each video from research extracted to images\\kalkar - january 2024/1.1/65\\GX010082_212_2827.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    # Extract the details from the row\n",
    "    label = row['Label']\n",
    "\n",
    "    bx = int(row['BX'])\n",
    "    by = int(row['BY'])\n",
    "    width = int(row['Width'])\n",
    "    height = int(row['Height'])\n",
    "    length = int(row['Length'])\n",
    "    angle = row['Angle']\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Processing row {index}: {label}, bx={bx}, by={by}, width={width}, height={height}, length={length}\")   \n",
    "\n",
    "    if angle>=0 and angle<45:\n",
    "            start_point =     (bx, by + height)\n",
    "            end_point =    (bx + width, by)  \n",
    "    elif angle >= 45 and angle <=90:\n",
    "            start_point =    (bx, by + height)\n",
    "            end_point =  (bx + width, by)       \n",
    "    elif angle > 90 and angle <=135:\n",
    "             start_point = (bx, by)\n",
    "             end_point = ( bx+width,by+height )\n",
    "\n",
    "    elif angle >135 and angle <=180:\n",
    "                start_point = (bx, by)\n",
    "                end_point = ( bx+width,by+height )           \n",
    "\n",
    "    elif angle >-45  and angle < 0:\n",
    "             start_point = (bx, by)\n",
    "             end_point = ( bx+width,by+height  )\n",
    "\n",
    "    elif angle >-90 and angle < -45:\n",
    "            start_point = (bx, by)\n",
    "            end_point = ( bx+width,by+height  )             \n",
    "    elif angle >= -135 and angle < -90:\n",
    "             start_point =(bx, by + height)\n",
    "             end_point =  (bx + width, by)        \n",
    "\n",
    "    else:\n",
    "            start_point =  (bx, by + height)\n",
    "            end_point = (bx + width, by)\n",
    "          \n",
    "\n",
    "    image = cv2.rectangle(image, (bx, by), (bx + width, by + height), color, thickness)\n",
    "\n",
    "\n",
    "    color = (255, 0, 0)  # Blue color in BGR\n",
    "    thickness = 2\n",
    "    image = cv2.line(image, start_point, end_point, color, thickness)\n",
    "\n",
    "    # Draw a large circle at (bx, by)\n",
    "    circle_radius = 10\n",
    "    circle_color = (0, 0, 255)  # Red color in BGR\n",
    "    image = cv2.circle(image, (bx, by), circle_radius, circle_color, -1)\n",
    "\n",
    "    # Draw circles at the corners of the bounding box\n",
    "    corners = [\n",
    "        (bx, by),                      # Top-left\n",
    "        (bx + width, by),              # Top-right\n",
    "        (bx, by + height),             # Bottom-left\n",
    "        (bx + width, by + height)      # Bottom-right\n",
    "        ]\n",
    "\n",
    "# Define colors for each corner (BGR format)\n",
    "    colors = [\n",
    "(255, 0, 0),   # Blue for Top-left\n",
    "(0, 255, 0),   # Green for Top-right\n",
    "(0, 0, 255),   # Red for Bottom-left\n",
    "(0, 255, 255)  # Yellow for Bottom-right\n",
    "]\n",
    "\n",
    "# Circle radius\n",
    "    circle_radius = 10\n",
    "\n",
    "# Draw circles at each corner with different colors\n",
    "    for corner, color in zip(corners, colors):\n",
    "        image = cv2.circle(image, corner, circle_radius, color, -1)\n",
    "\n",
    "    # Add the bx, by text\n",
    "text_bx_by = f'({bx}, {by})'\n",
    "org_bx_by = (bx + 15, by + 15)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.6\n",
    "text_color = (0, 255, 0)  # Green color in BGR\n",
    "text_thickness = 2\n",
    "image = cv2.putText(image, text_bx_by, org_bx_by, font, font_scale, text_color, text_thickness, cv2.LINE_AA)\n",
    "\n",
    "# Add the length text\n",
    "text_length = f'Length: {length:.2f}'\n",
    "org_length = (bx+width, by - 10)\n",
    "image = cv2.putText(image, text_length, org_length, font, font_scale, text_color, text_thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Save or display the image\n",
    "output_path = f'annot2.jpg'  # Adjust the path as needed\n",
    "cv2.imwrite(output_path, image)\n",
    "print(f\"Saved output image to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the three Excel files into DataFrames\n",
    "file_1_path = \"path_to_first_excel_file.xlsx\"\n",
    "file_2_path = \"path_to_second_excel_file.xlsx\"\n",
    "file_3_path = \"path_to_third_excel_file.xlsx\"\n",
    "\n",
    "data_1 = pd.read_excel(file_1_path)\n",
    "data_2 = pd.read_excel(file_2_path)\n",
    "data_3 = pd.read_excel(file_3_path)\n",
    "\n",
    "# Add a 'File' column to each DataFrame to identify the source file\n",
    "data_1['File'] = 'File 1'\n",
    "data_2['File'] = 'File 2'\n",
    "data_3['File'] = 'File 3'\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "combined_data = pd.concat([data_1, data_2, data_3])\n",
    "\n",
    "# Separate the scale rows (first two rows) from prawn data\n",
    "scales_data = combined_data.groupby('Image_Name').apply(lambda x: x.iloc[:2]).reset_index(drop=True)\n",
    "prawn_data = combined_data.groupby('Image_Name').apply(lambda x: x.iloc[2:]).reset_index(drop=True)\n",
    "\n",
    "# Define a tolerance for bounding box area comparison in the image (percentage tolerance)\n",
    "area_tolerance = 0.1  # 10% tolerance\n",
    "\n",
    "# Calculate the area of the bounding box in the image\n",
    "def calculate_area(row):\n",
    "    return row['Width'] * row['Height']\n",
    "\n",
    "# Function to check if two bounding box areas in the image are within the tolerance\n",
    "def areas_are_within_tolerance(area1, area2, tolerance):\n",
    "    return abs(area1 - area2) <= (tolerance * area1)\n",
    "\n",
    "# Create a unique identifier for each prawn based on the bounding box area in the image with tolerance\n",
    "def create_prawn_id(row, tolerance, prawn_data):\n",
    "    area1 = calculate_area(row)\n",
    "    bx1, by1 = row['BX'], row['BY']\n",
    "    for i, r in prawn_data.iterrows():\n",
    "        if r['Prawn_ID'] is not None:\n",
    "            continue\n",
    "        area2 = calculate_area(r)\n",
    "        bx2, by2 = r['BX'], r['BY']\n",
    "        if areas_are_within_tolerance(area1, area2, tolerance) and (bx1 == bx2 and by1 == by2):\n",
    "            prawn_data.at[i, 'Prawn_ID'] = f\"{row['Image_Name']}_{i}\"\n",
    "            return f\"{row['Image_Name']}_{i}\"\n",
    "    return f\"{row['Image_Name']}_{row.name}\"\n",
    "\n",
    "# Initialize Prawn_ID with None\n",
    "prawn_data['Prawn_ID'] = None\n",
    "\n",
    "# Apply the function to create a unique ID for each prawn based on the bounding box area in the image with tolerance\n",
    "prawn_data['Prawn_ID'] = prawn_data.apply(lambda row: create_prawn_id(row, area_tolerance, prawn_data), axis=1)\n",
    "\n",
    "# Group by the unique identifier (Prawn_ID) to combine measurements of the same prawn within the same image\n",
    "grouped = prawn_data.groupby('Prawn_ID')\n",
    "\n",
    "# Calculate statistics for each group (each prawn within each image)\n",
    "statistics_per_prawn = grouped['Length'].agg(\n",
    "    Avg_Length=np.mean,\n",
    "    Std_Dev=np.std,\n",
    "    Median_Length=np.median,\n",
    "    Measurement_Count='count'\n",
    ")\n",
    "\n",
    "# Calculate the uncertainty (standard deviation of the mean)\n",
    "statistics_per_prawn['Uncertainty'] = statistics_per_prawn['Std_Dev'] / np.sqrt(statistics_per_prawn['Measurement_Count'])\n",
    "\n",
    "# Filter out groups with fewer than 3 measurements (optional)\n",
    "statistics_per_prawn = statistics_per_prawn[statistics_per_prawn['Measurement_Count'] >= 3]\n",
    "\n",
    "# Calculate overall statistics across all prawns in all images\n",
    "overall_statistics = {\n",
    "    \"Overall Avg Length\": np.mean(statistics_per_prawn['Avg_Length']),\n",
    "    \"Overall Std Dev\": np.std(statistics_per_prawn['Avg_Length']),\n",
    "    \"Overall Median Length\": np.median(statistics_per_prawn['Avg_Length']),\n",
    "    \"Overall Uncertainty\": np.std(statistics_per_prawn['Avg_Length']) / np.sqrt(len(statistics_per_prawn))\n",
    "}\n",
    "\n",
    "# Display the scale statistics\n",
    "print(\"Scale Statistics:\")\n",
    "print(scales_data.groupby('Image_Name')['Length'].agg(\n",
    "    Avg_Scale_Length=np.mean,\n",
    "    Std_Scale_Length=np.std,\n",
    "    Median_Scale_Length=np.median\n",
    "))\n",
    "\n",
    "# Display the statistics for each prawn within each image\n",
    "print(\"\\nPrawn Length Statistics:\")\n",
    "print(statistics_per_prawn)\n",
    "\n",
    "# Display overall statistics\n",
    "print(\"\\nOverall Statistics:\")\n",
    "for key, value in overall_statistics.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "# Optionally, save the statistics to a new Excel file\n",
    "statistics_per_prawn.to_excel(\"prawn_length_statistics_per_image.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SN_1', 'Label', 'Area_1', 'Mean_1', 'Min_1', 'Max_1', 'BX_1', 'BY_1',\n",
      "       'Width_1', 'Height_1', 'Angle_1', 'Slice_1', 'Length_1', 'PrawnID',\n",
      "       'SN_2', 'Area_2', 'Mean_2', 'Min_2', 'Max_2', 'BX_2', 'BY_2', 'Width_2',\n",
      "       'Height_2', 'Angle_2', 'Slice_2', 'Length_2', 'SN_3', 'Area_3',\n",
      "       'Mean_3', 'Min_3', 'Max_3', 'BX_3', 'BY_3', 'Width_3', 'Height_3',\n",
      "       'Angle_3', 'Slice_3', 'Length_3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the three Excel files into DataFrames\n",
    "file_1_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\compile 3 files/1_Carapace.xlsx\"\n",
    "file_2_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\compile 3 files/2_Carapace.xlsx\"\n",
    "file_3_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\compile 3 files/3_Carapace.xlsx\"\n",
    "\n",
    "data_1 = pd.read_excel(file_1_path)\n",
    "data_2 = pd.read_excel(file_2_path)\n",
    "data_3 = pd.read_excel(file_3_path)\n",
    "\n",
    "# Function to extract the pixel-to-mm scale from the second row of each image\n",
    "def extract_scale(data):\n",
    "    return data.groupby('Label').apply(lambda x: x.iloc[1]['Length'] / 10).reset_index(name='Scale')\n",
    "\n",
    "# Extract scales for each dataset\n",
    "scale_1 = extract_scale(data_1)\n",
    "scale_2 = extract_scale(data_2)\n",
    "scale_3 = extract_scale(data_3)\n",
    "\n",
    "# Function to adjust bounding box coordinates based on the pixel-to-mm scale\n",
    "def adjust_bounding_box(data, scale):\n",
    "    data = data.copy()\n",
    "    prawn_data = data.groupby('Label').apply(lambda x: x.iloc[2:]).reset_index(drop=True)  # Skip the first two rows\n",
    "    prawn_data['BX'] *= scale\n",
    "    prawn_data['BY'] *= scale\n",
    "    prawn_data['Width'] *= scale\n",
    "    prawn_data['Height'] *= scale\n",
    "    return prawn_data\n",
    "\n",
    "# Adjust bounding boxes in each dataset for each image separately\n",
    "def process_image(image_label, data_1, data_2, data_3, scale_1, scale_2, scale_3, tolerance):\n",
    "    img_data_1 = data_1[data_1['Label'] == image_label]\n",
    "    img_data_2 = data_2[data_2['Label'] == image_label]\n",
    "    img_data_3 = data_3[data_3['Label'] == image_label]\n",
    "\n",
    "    scale_val_1 = scale_1[scale_1['Label'] == image_label]['Scale'].values[0]\n",
    "    scale_val_2 = scale_2[scale_2['Label'] == image_label]['Scale'].values[0]\n",
    "    scale_val_3 = scale_3[scale_3['Label'] == image_label]['Scale'].values[0]\n",
    "\n",
    "    prawn_data_1 = adjust_bounding_box(img_data_1, scale_val_1)\n",
    "    prawn_data_2 = adjust_bounding_box(img_data_2, scale_val_2)\n",
    "    prawn_data_3 = adjust_bounding_box(img_data_3, scale_val_3)\n",
    "\n",
    "    # Assign PrawnID by comparing bounding boxes with tolerance within the same image\n",
    "    prawn_data_1['PrawnID'] = None\n",
    "    prawn_data_2['PrawnID'] = None\n",
    "    prawn_data_3['PrawnID'] = None\n",
    "\n",
    "    for i, row1 in prawn_data_1.iterrows():\n",
    "        bx1, by1, width1, height1 = row1['BX'], row1['BY'], row1['Width'], row1['Height']\n",
    "        area1 = width1 * height1\n",
    "\n",
    "        for j, row2 in prawn_data_2.iterrows():\n",
    "            bx2, by2, width2, height2 = row2['BX'], row2['BY'], row2['Width'], row2['Height']\n",
    "            area2 = width2 * height2\n",
    "\n",
    "            if abs(area1 - area2) <= (tolerance * area1) and abs(bx1 - bx2) <= tolerance and abs(by1 - by2) <= tolerance:\n",
    "                prawn_data_1.at[i, 'PrawnID'] = f\"{image_label}_{i}\"\n",
    "                prawn_data_2.at[j, 'PrawnID'] = f\"{image_label}_{i}\"\n",
    "                break\n",
    "\n",
    "        for k, row3 in prawn_data_3.iterrows():\n",
    "            bx3, by3, width3, height3 = row3['BX'], row3['BY'], row3['Width'], row3['Height']\n",
    "            area3 = width3 * height3\n",
    "\n",
    "            if abs(area1 - area3) <= (tolerance * area1) and abs(bx1 - bx3) <= tolerance and abs(by1 - by3) <= tolerance:\n",
    "                prawn_data_1.at[i, 'PrawnID'] = f\"{image_label}_{i}\"\n",
    "                prawn_data_3.at[k, 'PrawnID'] = f\"{image_label}_{i}\"\n",
    "                break\n",
    "\n",
    "    return prawn_data_1, prawn_data_2, prawn_data_3\n",
    "\n",
    "# Set tolerance for bounding box comparison\n",
    "tolerance = 15 # Adjust based on acceptable variance\n",
    "\n",
    "# Process each image separately\n",
    "processed_data_1 = []\n",
    "processed_data_2 = []\n",
    "processed_data_3 = []\n",
    "\n",
    "for image_label in data_1['Label'].unique():\n",
    "    img_data_1, img_data_2, img_data_3 = process_image(image_label, data_1, data_2, data_3, scale_1, scale_2, scale_3, tolerance)\n",
    "    processed_data_1.append(img_data_1)\n",
    "    processed_data_2.append(img_data_2)\n",
    "    processed_data_3.append(img_data_3)\n",
    "\n",
    "# Combine the processed data into DataFrames\n",
    "final_data_1 = pd.concat(processed_data_1, ignore_index=True)\n",
    "final_data_2 = pd.concat(processed_data_2, ignore_index=True)\n",
    "final_data_3 = pd.concat(processed_data_3, ignore_index=True)\n",
    "\n",
    "# Merge datasets on PrawnID and Label to combine the measurements across the three files\n",
    "# Merge datasets on PrawnID and Label to combine the measurements across the three files\n",
    "merged_data = final_data_1.merge(final_data_2, on=['Label', 'PrawnID'], suffixes=('_1', '_2'))\n",
    "\n",
    "# Rename the columns in final_data_3 to ensure they have a unique suffix\n",
    "final_data_3 = final_data_3.rename(columns={\n",
    "    'SN': 'SN_3',\n",
    "    'Area': 'Area_3',\n",
    "    'Mean': 'Mean_3',\n",
    "    'Min': 'Min_3',\n",
    "    'Max': 'Max_3',\n",
    "    'BX': 'BX_3',\n",
    "    'BY': 'BY_3',\n",
    "    'Width': 'Width_3',\n",
    "    'Height': 'Height_3',\n",
    "    'Angle': 'Angle_3',\n",
    "    'Slice': 'Slice_3',\n",
    "    'Length': 'Length_3'\n",
    "})\n",
    "\n",
    "\n",
    "merged_data = merged_data.merge(final_data_3, on=['Label', 'PrawnID'])\n",
    "# Check if the length columns are present\n",
    "print(merged_data.columns)\n",
    "\n",
    "\n",
    "# Calculate statistics for each prawn\n",
    "def calculate_statistics(merged_data):\n",
    "    # Calculate mean, standard deviation, and uncertainty\n",
    "    merged_data['Mean_Length'] = merged_data[['Length_1', 'Length_2', 'Length_3']].mean(axis=1)\n",
    "    merged_data['Std_Dev_Length'] = merged_data[['Length_1', 'Length_2', 'Length_3']].std(axis=1)\n",
    "    merged_data['Uncertainty'] = merged_data['Std_Dev_Length'] / (3 ** 0.5)\n",
    "    return merged_data\n",
    "\n",
    "# Apply the statistics calculation\n",
    "final_data = calculate_statistics(merged_data)\n",
    "\n",
    "# Concat the bounding box and angle information for verification\n",
    "final_data['BoundingBox_1'] = final_data[['BX_1', 'BY_1', 'Width_1', 'Height_1']].apply(tuple, axis=1)\n",
    "final_data['BoundingBox_2'] = final_data[['BX_2', 'BY_2', 'Width_2', 'Height_2']].apply(tuple, axis=1)\n",
    "final_data['BoundingBox_3'] = final_data[['BX_3', 'BY_3', 'Width_3', 'Height_3']].apply(tuple, axis=1)\n",
    "\n",
    "final_data['Angle_1'] = final_data['Angle_1']\n",
    "final_data['Angle_2'] = final_data['Angle_2']\n",
    "final_data['Angle_3'] = final_data['Angle_3']\n",
    "\n",
    "# Display the final dataframe with PrawnID, calculated statistics, bounding boxes, and angles\n",
    "final_data[['Label', 'PrawnID', 'Mean_Length', 'Std_Dev_Length', 'Uncertainty', \n",
    "            'BoundingBox_1', 'BoundingBox_2', 'BoundingBox_3', \n",
    "            'Angle_1', 'Angle_2', 'Angle_3']]\n",
    "#save the final data to a new Excel file\n",
    "final_data.to_excel(\"final_data.xlsx\", index=False)\n",
    "# Display the final dataframe with PrawnID, calculated statistics, bounding boxes, and angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning ID for prawn 1 in image carapace:undistorted_GX010067_33_625.jpg_gamma\n",
      "C:/Users/gbo10/OneDrive/measurement_paper_images/images used for imageJ/check/stabilized/shai/measurements/1/carapace/undistorted_GX010067_33_625.jpg_gamma.jpg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "\n",
    "# Load the three Excel files into DataFrames\n",
    "file_1_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\compile 3 files/1_Carapace.xlsx\"\n",
    "file_2_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\compile 3 files/2_Carapace.xlsx\"\n",
    "file_3_path = r\"C:\\Users\\gbo10\\OneDrive\\measurement_paper_images\\compile 3 files/3_Carapace.xlsx\"\n",
    "\n",
    "data_1 = pd.read_excel(file_1_path)\n",
    "data_2 = pd.read_excel(file_2_path)\n",
    "data_3 = pd.read_excel(file_3_path)\n",
    "\n",
    "# Function to extract the pixel-to-mm scale from the second row of each image\n",
    "def extract_scale(data):\n",
    "    return data.groupby('Label').apply(lambda x: x.iloc[1]['Length'] / 10).reset_index(name='Scale')\n",
    "\n",
    "# Extract scales for each dataset\n",
    "scale_1 = extract_scale(data_1)\n",
    "scale_2 = extract_scale(data_2)\n",
    "scale_3 = extract_scale(data_3)\n",
    "\n",
    "# Function to adjust bounding box coordinates based on the pixel-to-mm scale\n",
    "def adjust_bounding_box(data, scale):\n",
    "    data = data.copy()\n",
    "    data['BX'] *= scale\n",
    "    data['BY'] *= scale\n",
    "    data['Width'] *= scale\n",
    "    data['Height'] *= scale\n",
    "    return data\n",
    "\n",
    "# Function to draw bounding boxes and lines\n",
    "def draw_bounding_boxes_and_lines(image, prawn_data, color, thickness=2):\n",
    "    bx = int(prawn_data['BX'])\n",
    "    by = int(prawn_data['BY'])\n",
    "    width = int(prawn_data['Width'])\n",
    "    height = int(prawn_data['Height'])\n",
    "    angle = prawn_data['Angle']\n",
    "\n",
    "    if angle >= 0 and angle < 45 or angle >= 135 and angle <= 180:\n",
    "        start_point = (bx, by + height)\n",
    "        end_point = (bx + width, by)\n",
    "    else:\n",
    "        start_point = (bx, by)\n",
    "        end_point = (bx + width, by + height)\n",
    "\n",
    "    # Draw the rectangle (bounding box)\n",
    "    image = cv2.rectangle(image, (bx, by), (bx + width, by + height), color, thickness)\n",
    "    \n",
    "    # Draw the line\n",
    "    image = cv2.line(image, start_point, end_point, color, thickness)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Function to find the closest matching bounding box based on location\n",
    "def find_closest_bbox(bbox, prawn_data):\n",
    "    \"\"\"Finds the closest matching bounding box in prawn_data to the given bbox.\"\"\"\n",
    "    bx1, by1, width1, height1 = bbox\n",
    "\n",
    "    def distance(row):\n",
    "        bx2, by2, width2, height2 = row['BX'], row['BY'], row['Width'], row['Height']\n",
    "        return np.sqrt((bx1 - bx2)**2 + (by1 - by2)**2)\n",
    "\n",
    "    closest_row = prawn_data.iloc[prawn_data.apply(distance, axis=1).argmin()]\n",
    "    return closest_row\n",
    "\n",
    "# Function to manually assign PrawnIDs by visual inspection\n",
    "def assign_prawn_ids_manually(image_label, data_1, data_2, data_3, scale_1, scale_2, scale_3):\n",
    "    img_data_1 = data_1[data_1['Label'] == image_label]\n",
    "    img_data_2 = data_2[data_2['Label'] == image_label]\n",
    "    img_data_3 = data_3[data_3['Label'] == image_label]\n",
    "\n",
    "    scale_val_1 = scale_1[scale_1['Label'] == image_label]['Scale'].values[0]\n",
    "    scale_val_2 = scale_2[scale_2['Label'] == image_label]['Scale'].values[0]\n",
    "    scale_val_3 = scale_3[scale_3['Label'] == image_label]['Scale'].values[0]\n",
    "\n",
    "    # Adjust the bounding boxes according to the scale\n",
    "    img_data_1 = adjust_bounding_box(img_data_1, scale_val_1)\n",
    "    img_data_2 = adjust_bounding_box(img_data_2, scale_val_2)\n",
    "    img_data_3 = adjust_bounding_box(img_data_3, scale_val_3)\n",
    "\n",
    "    prawn_ids = []\n",
    "    prawn_id_counter =0\n",
    "\n",
    "    for i, row1 in img_data_1.iloc[2:].iterrows():\n",
    "        print(f\"Assigning ID for prawn {prawn_id_counter+1} in image {image_label}\")\n",
    "\n",
    "\n",
    "        file_name = image_label.split(\":\")[1] if \":\" in image_label else image_label\n",
    "\n",
    "        file_root, file_ext = os.path.splitext(file_name)\n",
    "      \n",
    "    # Append a .jpg extension if itâ€™s missing\n",
    "      \n",
    "\n",
    "        file_name = f\"{file_root}{file_ext}.jpg\"\n",
    "\n",
    "       # Load the image (assuming you have a way to load it based on the label)\n",
    "        image_path = f\"C:/Users/gbo10/OneDrive/measurement_paper_images/images used for imageJ/check/stabilized/shai/measurements/1/carapace/{file_name}\"  \n",
    "        \n",
    "        print(image_path)   \n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Draw bounding boxes and lines from dataset 1\n",
    "        image = draw_bounding_boxes_and_lines(image, row1, (255, 0, 0))  # Blue for file 1\n",
    "        \n",
    "        # Find the closest matching bounding boxes in the other datasets\n",
    "        closest_bbox_2 = find_closest_bbox((row1['BX'], row1['BY'], row1['Width'], row1['Height']), img_data_2)\n",
    "        closest_bbox_3 = find_closest_bbox((row1['BX'], row1['BY'], row1['Width'], row1['Height']), img_data_3)\n",
    "\n",
    "        # Draw bounding boxes and lines from dataset 2 and 3\n",
    "        image = draw_bounding_boxes_and_lines(image, closest_bbox_2, (0, 255, 0))  # Green for file 2\n",
    "        image = draw_bounding_boxes_and_lines(image, closest_bbox_3, (0, 0, 255))  # Red for file 3\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Display the image using Matplotlib\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')\n",
    "        temp_file_path = temp_file.name\n",
    "        cv2.imwrite(temp_file_path, image)\n",
    "        temp_file.close()\n",
    "\n",
    "        # Open the image using the default image viewer\n",
    "        os.system(f'start {temp_file_path}')\n",
    "\n",
    "        # Manually input the ID\n",
    "        prawn_id = input(f\"Enter PrawnID for prawn {prawn_id_counter+1} in image {image_label}: \")\n",
    "        prawn_ids.append(prawn_id)\n",
    "\n",
    "        # Delete the temporary file\n",
    "        os.remove(temp_file_path)\n",
    "\n",
    "\n",
    "        prawn_id_counter += 1\n",
    "     \n",
    "\n",
    "        # Assign PrawnID to closest matches in all datasets\n",
    "        img_data_1.at[i, 'PrawnID'] = prawn_id\n",
    "        img_data_2.at[closest_bbox_2.name, 'PrawnID'] = prawn_id\n",
    "        img_data_3.at[closest_bbox_3.name, 'PrawnID'] = prawn_id\n",
    "\n",
    "    return img_data_1, img_data_2, img_data_3\n",
    "\n",
    "# Process each image and assign PrawnIDs manually\n",
    "processed_data_1 = []\n",
    "processed_data_2 = []\n",
    "processed_data_3 = []\n",
    "\n",
    "for image_label in data_1['Label'].unique():\n",
    "    img_data_1, img_data_2, img_data_3 = assign_prawn_ids_manually(image_label, data_1, data_2, data_3, scale_1, scale_2, scale_3)\n",
    "    processed_data_1.append(img_data_1)\n",
    "    processed_data_2.append(img_data_2)\n",
    "    processed_data_3.append(img_data_3)\n",
    "\n",
    "# Combine the processed data into DataFrames\n",
    "final_data_1 = pd.concat(processed_data_1, ignore_index=True)\n",
    "final_data_2 = pd.concat(processed_data_2, ignore_index=True)\n",
    "final_data_3 = pd.concat(processed_data_3, ignore_index=True)\n",
    "\n",
    "# Save the final data with manually assigned PrawnIDs\n",
    "final_data_1.to_excel(\"final_data_1_with_prawn_ids.xlsx\", index=False)\n",
    "final_data_2.to_excel(\"final_data_2_with_prawn_ids.xlsx\", index=False)\n",
    "final_data_3.to_excel(\"final_data_3_with_prawn_ids.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
