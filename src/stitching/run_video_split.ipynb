{"cells":[{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing video C:/Users/gbo10/Dropbox/research videos/car-current/april 2024/1.4.2024/56\\GX010147.MP4\n","before stats file\n","after stats file\n","output/stats.csv\n","output/stats.csv\n","[GX010147.MP4][ 89%] Processing frame 1858/2087: \r"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing video \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m Video2Dataset2process \u001b[38;5;241m=\u001b[39m Video2Dataset(Parameters(args))\n\u001b[1;32m---> 35\u001b[0m \u001b[43mVideo2Dataset2process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcessVideo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\Videos\\research\\counting_research_algorithms\\src\\stitching\\video2dataset_mine.py:138\u001b[0m, in \u001b[0;36mVideo2Dataset.ProcessVideo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress \u001b[38;5;241m!=\u001b[39m prev_progress:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m][\u001b[39m\u001b[38;5;132;01m{:3d}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m] Processing frame \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(file_name, progress, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_index \u001b[38;5;241m-\u001b[39m start_frame \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, frames_to_process), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 138\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcessFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrt_parser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mstats_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWriteStats(input_file, stats)\n","File \u001b[1;32m~\\Videos\\research\\counting_research_algorithms\\src\\stitching\\video2dataset_mine.py:165\u001b[0m, in \u001b[0;36mVideo2Dataset.ProcessFrame\u001b[1;34m(self, frame, video_info, srt_parser)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mProcessFrame\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame, video_info, srt_parser):\n\u001b[0;32m    163\u001b[0m     res \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_idx}\n\u001b[1;32m--> 165\u001b[0m     frame_bw \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     h, w \u001b[38;5;241m=\u001b[39m frame_bw\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    168\u001b[0m     resolution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39minternal_resolution\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","\n","from src.video.parameters import Parameters\n","from src.stitching.video2dataset_mine import Video2Dataset\n","import glob\n","work_dir = os.getcwd()\n","\n","args= { \n","\n","    \"input\": f\"C:/Users/gbo10/Dropbox/research videos/31.12/65-31.12/GX010065.MP4\",\n","    \"output\": f\"C:/Users/gbo10/OneDrive/research/italy/torino/computer vision/01.04.2024-splitted videos/56\",\n","    \"start\": 0,\n","    \"end\": None,\n","    \"output_resolution\": None,\n","    \"blur_threshold\":50,\n","    \"distance_threshold\":40,\n","    \"black_ratio_threshold\": None,\n","    \"pixel_black_threshold\": None,\n","    \"use-srt\": None,\n","    \"limit\": None,\n","    \"frame_format\": \"jpg\",\n","    \"stats_file\":\"output/stats.csv\"}\n","\n","\n","video_paths = []  # Initialize an empty list to store the video paths\n","\n","for video_path in glob.glob(\"C:/Users/gbo10/Dropbox/research videos/car-current/april 2024/1.4.2024/56/*.mp4\"):\n","    video_paths.append(video_path)\n","\n","\n","for video_path in video_paths:\n","    args[\"input\"] = video_path\n","    print(f'Processing video {video_path}')\n","    Video2Dataset2process = Video2Dataset(Parameters(args))\n","    Video2Dataset2process.ProcessVideo()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernel_info":{"name":"Untitled"},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
