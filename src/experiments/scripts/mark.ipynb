{"metadata":{"kernel_info":{"name":"Untitled"},"language_info":{"name":"Python","version":"1.0.0."}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{},"source":""},{"cell_type":"code","metadata":{},"source":"import matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport cv2\r\n\r\ndef resize_image_to_screen(image, screen_width, screen_height, keep_aspect_ratio=False):\r\n    img_height, img_width = image.shape[:2]\r\n\r\n    if keep_aspect_ratio:\r\n        # Calculate the ratio of the screen dimensions to the image dimensions\r\n        width_ratio = screen_width / img_width\r\n        height_ratio = screen_height / img_height\r\n\r\n        # Use the smaller ratio to ensure the entire image fits within the screen\r\n        resize_ratio = min(width_ratio, height_ratio)\r\n        new_width = int(img_width * resize_ratio)\r\n        new_height = int(img_height * resize_ratio)\r\n\r\n        resized_image = cv2.resize(image, (new_width, new_height))\r\n    else:\r\n        resized_image = cv2.resize(image, (screen_width, screen_height))\r\n\r\n    return resized_image\r\n\r\n\r\n#\"C:\\Users\\gbo10\\OneDrive\\pictures\\labeling\\65\\65\\test\\images\\GX010094_MP4-0_jpg.rf.dcf3d1515810af1e22925baaf0a60166.jpg\"\r\n# Load the image using OpenCV\r\nimage_path = \"C:\\\\Users\\\\gbo10\\\\OneDrive\\\\pictures\\\\labeling\\\\65\\\\65\\\\test\\\\images\\\\GX010094_MP4-0_jpg.rf.dcf3d1515810af1e22925baaf0a60166.jpg\"\r\nimage = cv2.imread(image_path)\r\nimage_to_show = resize_image_to_screen(image, 1366, 768, keep_aspect_ratio=False)\r\n\r\n# camera_matrix = np.array([[9.03421502e+03, 0.00000000e+00, 1.72545905e+02],\r\n#                           [0.00000000e+00, 1.09758217e+04, 2.33416705e+02],\r\n#                           [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\r\n# distortion_coeffs = np.array([-6.09645602e-01,  1.45423021e-01, -3.64203971e-01, -1.52023397e-02,\r\n#                               1.25904521e-04])\r\n\r\n# # Compute the optimal new camera matrix\r\n# h, w = image.shape[:2]\r\n# new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, distortion_coeffs, (w, h), 1, (w, h))\r\n\r\n# # Undistort the image\r\n# undistorted_image = cv2.undistort(image, camera_matrix, distortion_coeffs, None, new_camera_matrix)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Function to display the image and collect manual input\r\ndef manual_marking(image):\r\n    fig, ax = plt.subplots()\r\n    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\r\n    plt.title('Click once to zoom, then select the 4 corners of the object')\r\n\r\n    points = []  # List to store points\r\n    zoom_point = None  # Variable to store the first click for zoom\r\n\r\n    def onclick(event):\r\n        nonlocal zoom_point\r\n        if not zoom_point:\r\n            # First click - set zoom point\r\n            zoom_point = (event.xdata, event.ydata)\r\n            ax.plot(zoom_point[0], zoom_point[1], 'ro')  # Mark the zoom point\r\n            plt.draw()\r\n        else:\r\n            # Subsequent clicks - add to points list\r\n            if len(points) < 4:\r\n                points.append((event.xdata, event.ydata))\r\n                ax.plot(event.xdata, event.ydata, 'go')  # Mark the point\r\n                plt.draw()\r\n\r\n    # Connect the click event to the onclick function\r\n    cid = fig.canvas.mpl_connect('button_press_event', onclick)\r\n\r\n    # Show the image and wait for the user to click 5 times\r\n    plt.show()\r\n\r\n    # Disconnect the event after 5 clicks\r\n    fig.canvas.mpl_disconnect(cid)\r\n\r\n    # Implement zooming to the selected point (optional)\r\n    # This could be a specific zoom level or a region around the zoom_point\r\n    print(f'points: {points}')\r\n    return np.array(points)\r\n\r\n\r\n# def perspective_warp_correction(image, points,measured_width_px, measured_height_px):\r\n#     # Define points on the image (source points)\r\n#     src_pts = np.array(points, dtype='float32')\r\n    \r\n#     # Define corresponding points where the source points should be mapped to (destination points)\r\n#     # Assuming the object is a square in real life with a given size in millimeters\r\n#     width_px = max(measured_width_px, measured_height_px)\r\n#     height_px = width_px  # Assuming you want a square, make the height equal to the width\r\n\r\n#     dst_pts = np.array([\r\n#         [0, 0],\r\n#         [width_px, 0],\r\n#         [width_px, height_px],\r\n#         [0, height_px]\r\n#     ], dtype='float32')\r\n#     # Compute the perspective transform matrix\r\n#     M = cv2.getPerspectiveTransform(src_pts, dst_pts)\r\n    \r\n#     # Perform the warp perspective\r\n#     warped = cv2.warpPerspective(image, M, (int(width_px),int( width_px)))\r\n#     return warped\r\n\r\n\r\n# Function to calculate and display measurements\r\ndef calculate_and_display(image, points):\r\n  # Assuming points are ordered as follows:\r\n# Top Left, Top Right, Bottom Right, Bottom Left\r\n\r\n\r\n    \r\n\r\n# Width calculation (average of top and bottom side lengths)\r\n    width_px = (np.linalg.norm(np.array(points[0]) - np.array(points[1])) + \r\n                np.linalg.norm(np.array(points[2]) - np.array(points[3]))) / 2\r\n\r\n    # Height calculation (average of left and right side lengths)\r\n    height_px = (np.linalg.norm(np.array(points[0]) - np.array(points[3])) + \r\n                np.linalg.norm(np.array(points[1]) - np.array(points[2]))) / 2\r\n    \r\n    # corrected_image = perspective_warp_correction(image, points,width_px,height_px)\r\n    print(f\"Width: {width_px:.2f}px\")\r\n    print(f\"Height: {height_px:.2f}px\")\r\n    # Width calculation (average of top and bottom side lengths)\r\n    # width_px = (abs(points[0][0] - points[1][0]) + \r\n    #             abs(points[2][0] - points[3][0])) / 2\r\n\r\n    # # Height calculation (average of left and right side lengths)\r\n    # height_px = (abs(points[0][1] - points[3][1]) + \r\n    #             abs(points[1][1] - points[2][1])) / 2\r\n\r\n    # Calculate centroid of the box\r\n    centroid_x, centroid_y = np.mean(points, axis=0)\r\n    \r\n    # Calculate distance from the center of the image\r\n    image_center = (image.shape[1] / 2, image.shape[0] / 2)\r\n    image_plane_coordinates = [(point[0] - centroid_x, point[1] - centroid_y) for point in points] # Print the image plane coordinates\r\n    for i, coord in enumerate(image_plane_coordinates):\r\n        print(f\"Point {i+1} (x', y'):\", coord)\r\n    distance_from_center = np.linalg.norm(np.array([centroid_x, centroid_y]) - np.array(image_center))\r\n    \r\n    # Calculate the angle with respect to the horizontal axis (assuming right side is 0 degrees)\r\n    angle_rad = np.arctan2(centroid_y - image_center[1], centroid_x - image_center[0])\r\n    angle_degrees = np.degrees(angle_rad)\r\n    # Annotate and draw on the image\r\n    cv2.line(image, (int(centroid_x), int(centroid_y)), (int(image_center[0]), int(image_center[1])), (255, 0, 0), 2)\r\n    for point in points:\r\n        cv2.circle(image, (int(point[0]), int(point[1])), 5, (0, 255, 0), -1)\r\n    cv2.putText(image, f'Width: {width_px:.2f}px', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\r\n    cv2.putText(image, f'Height: {height_px:.2f}px', (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\r\n    cv2.putText(image, f'Distance from center: {distance_from_center:.2f}px', (50, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\r\n    cv2.putText(image, f'Angle: {angle_degrees:.2f} degrees', (50, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\r\n    \r\n    # Show the final image\r\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\r\n    plt.title('Marked Top Surface of the Red Box')\r\n    plt.axis('off')\r\n    plt.show()\r\n\r\n# Main workflow\r\npoints = manual_marking(image_to_show)\r\ncalculate_and_display(image_to_show, points)\r\n\r\n\r\n"}]}